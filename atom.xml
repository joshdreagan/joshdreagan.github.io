<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Reagan&#39;s Blog</title>
  
  
  <link href="https://blog.joshdreagan.com/atom.xml" rel="self"/>
  
  <link href="https://blog.joshdreagan.com/"/>
  <updated>2025-06-20T02:14:02.532Z</updated>
  <id>https://blog.joshdreagan.com/</id>
  
  <author>
    <name>Josh Reagan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Bridging Apache Artemis - Part 2</title>
    <link href="https://blog.joshdreagan.com/2025/06/19/bridging_apache_artemis_part_2/"/>
    <id>https://blog.joshdreagan.com/2025/06/19/bridging_apache_artemis_part_2/</id>
    <published>2025-06-19T21:17:51.000Z</published>
    <updated>2025-06-20T02:14:02.532Z</updated>
    
    <content type="html"><![CDATA[<p>In <a href="/2017/08/16/bridging_apache_artemis/" title="a previous post">a previous post</a>, I wrote about setting up a bridge between <a href="https://activemq.apache.org/components/artemis/">Apache Artemis</a> and another JMS broker. Specifically in that case, I used IBM MQ. For part 2, I‚Äôd like to cover something a little more complex. Bridging between <a href="https://activemq.apache.org/components/artemis/">Apache Artemis</a> and <a href="https://kafka.apache.org/">Apache Kafka</a>.<a id="more"></a></p><p>To be clear, bridging from Artemis to Kafka doesn‚Äôt <strong>have</strong> to be difficult. As always, it depends on your use case. Let‚Äôs talk about the simplest one first.</p><p><strong>Uni-directional</strong></p><p>Let‚Äôs say you‚Äôre simply trying to bridge in one direction. For example, imagine you have a bunch of IoT devices spread around various sites. These types of devices typically don‚Äôt run a Kafka client. More commonly, they‚Äôll speak one of the many standardized protocols like <a href="https://mqtt.org/">MQTT</a>. If those devices are simply publishing telemetry data, then the communication is only flowing in one direction. In this case, you‚Äôd only need a couple of components. First, you‚Äôll want to run an Artemis broker since it speaks MQTT. You could run the Artemis instance anywhere really, but most likely you‚Äôd want to run it on each site (close to the devices). This gives you several benefits, such as insulating your sites from network failures and simplifying security. Second, you‚Äôd need a simple Camel bridge application to consume the messages from each of the Artemis edge brokers, and produce them to the centralized Kafka cluster. And finally, you‚Äôll obviously need a Kafka cluster. Take a look at the picture below for an example. Also, you can poke around the code if you want to see it running: <a href="https://github.com/joshdreagan/iot-demo">https://github.com/joshdreagan/iot-demo</a></p><p><img src="uni-simple-architecture.png" alt="Uni-directional Simple Architecture"></p><p><strong>Bi-directional (simple)</strong></p><p>Now let‚Äôs complicate things a bit and try to do bi-directional communication. In this case, let‚Äôs assume that maybe those IoT devices running out on the edge might want to receive command messages in addition to publishing their telemetry data. You‚Äôd of course need all the same components as before. The tricky part is routing the messages where they need to go. You might be tempted to simply use a hierarchical addressing strategy like you would normally do with MQTT. Something like ‚Äúcommands.US.CO.site-1234.device-5678‚Äù (would be ‚Äú/commands/US/CO/site-1234/device-5678‚Äù in MQTT speak) to indicate the region and device you‚Äôd like to issue the command to. That way I can have independent Camel bridges (one for each Artemis/site) that consume from Kafka the topics that they‚Äôre interested in (potentially using wildcards), and produce to their local Artemis broker that‚Äôs colocated with the target device.</p><p>This strategy is not bad if you have a limited number of devices, but issues can arise when you maybe have millions of devices. While Kafka is great with raw throughput, it doesn‚Äôt really like having a ton of topics (and partitions). The move from Zookeeper to KRaft has improved this quite a bit, but you still need to try to keep the number of topics/partitions relatively low. So what do we do? Well, one solution might be to use that same hierarchical address structure, but move some of the information into a header. Using the previous example, maybe something like ‚Äúcommands.US.CO.site-1234‚Äù for the address, and put the ‚Äúdevice-5678‚Äù in a message header. This would allow you to cut down the number of Kafka topics to be equal to the number of sites you have, as opposed to the total number of devices across all sites. And it would still allow the Camel bridge application to easily route messages to the correct broker and target device by concatenating the headers and source topic to rebuild the full address that it would produce to on its local Artemis broker.</p><p>This strategy has its limits though. If you were to move any more of the address into a header, the routing that the Camel bridge application has to do becomes much more complicated. Following the same example, let‚Äôs say I used ‚Äúcommands.US.CO‚Äù for the address, and put both ‚Äúsite-1234‚Äù and ‚Äúdevice-5678‚Äù into headers. Now my site-local Camel bridge applications can no longer assume that all messages on the Kafka topic are of interest to them. And Kafka has no concept like JMS message selectors. So we either have the option of pulling messages we don‚Äôt care about and filtering locally, or we have to move to a more centralized push model. The obvious negative about local filtering is that it potentially greatly increases unnecessary network traffic. In my example, every bridge application in Colorado would pull all messages for every site in that state. Even for sites it‚Äôs not responsible for. Depending on the number of sites, and number of command messages, this could be a lot of wasted bandwidth. And the other option is not much better. If we moved the Camel bridge application up to the hub, and made it responsible for bridging to all sites in Colorado, we would eliminate the wasted bandwidth issue. However, our Camel application now has to be smart enough to know the addresses of all Artemis brokers at all sites in the state, and keep a routing map of which site (ie, ‚Äúsite-1234‚Äù) maps to which Artemis broker URL. So doable, but not ideal.</p><p><img src="bidi-simple-architecture.png" alt="Bi-directional Simple Architecture"></p><p><strong>Bi-directional (complex)</strong></p><p>Now, let‚Äôs cover a really complex case. What if we have bi-directional communication, but it‚Äôs not data that can be broken up by address? What if, instead, I want to have competing consumers, and am using Artemis as more of a proxy to Kafka just so my clients can speak AMQP (or whatever protocol), or be coded to the JMS API?</p><p>Well, much like the previous cases, producing is not a problem. As messages come in to Artemis, I can simply use a bridge to pick them up and push them to a Kafka cluster. I can even be slick about it and use a feature called ‚Äúdiverts‚Äù to redirect all messages that I want to forward onto a single ‚Äúoutbound‚Äù queue. That way my bridge only has to consume from that one queue. All information about the original address a message was produced to is stored in headers. So bridging to the appropriate Kafka topic is easy.</p><p>But what about consuming? That‚Äôs actually the difficult part. Let‚Äôs assume that I have more than one Artemis broker. Let‚Äôs also assume that my consumers are spread across those brokers. If I just used a simple Kafka-&gt;Artemis Camel bridge, it would pull down all messages (as fast as it could) and produce them to whatever Artemis broker it was connected to. That Artemis broker might not actually have a consumer attached to it. The consumer might be attached to one of the other Artemis brokers. So now I‚Äôd need to store-and-forward them around an Artemis cluster. That‚Äôs extra hops to persistence, and more wasted bandwidth.</p><p>What if, instead, I only pulled messages across when a consumer was actually attached and listening on a given queue/topic? That way I could avoid unnecessary hops, and potentially (depending on my use case) avoid clustering the Artemis brokers altogether. In addition, it would reduce the amount of storage I would need on my Artemis brokers as I could now control how many messages I pull across at a time.</p><p>Unfortunately, in order to have hooks into Artemis-internal things like consumers attaching/listening, I won‚Äôt be able to use a simple external Camel application. For that type of insight, I‚Äôd need to implement my bridge as a broker plugin that runs inside the Artemis broker itself. Using this strategy, we can handle both queues and topics. With a few caveats‚Ä¶</p><p>First, for queues, you‚Äôd need all the bridge instances to use the same Kafka consumer group ID. Which limits the number of bridges you can have to be equal to the number of partitions the underlying Kafka topic has. This most likely wouldn‚Äôt be too big of a problem since each Artemis instance can handle thousands of clients. And if I have thousands of partitions, I can have thousands of Artemis brokers/bridges/proxies, with each one handling thousands of clients. So probably good enough. For topics, I would want to configure each bridge instance to have a unique Kafka consumer group ID. So in that case, I wouldn‚Äôt be limited by the number of partitions, but rather by the fact that each of my bridge consumers would effectively be single threaded. Which may or may not be a performance bottleneck.</p><p>The second issue is that Kafka consumers pull messages in batches for performance reasons. So you could potentially run into a case where a consumer attaches to an Artemis broker, then a bridge is fired up and starts pulling messages, but the consumer goes away before it consumes the full batch. In that case, you‚Äôd either have messages that were stuck on a specific Artemis broker waiting for a consumer to come back, or you‚Äôd fail the batch and potentially get duplicates when the consumer reattaches and the batch is pulled again. Which of those you get depends on your ‚Äúack‚Äù strategy for the KafkaConsumer. You could, of course, mitigate this by lowering your batch size on your KafkaConsumer. But doing so would impact your performance. In my opinion, it would be better to make your consumer apps tolerant of duplicates (since duplicates are inevitable in literally any system anyway).</p><p>I did implement an example of this strategy, which can be found here: <a href="https://github.com/joshdreagan/artemis-kafka-bridge/">https://github.com/joshdreagan/artemis-kafka-bridge/</a>. However, it could certainly use some improvement. For example, right now I have the producer and consumer queues separated so that I could use Artemis‚Äôs built-in queue-depth blocking to limit the number of messages I pull at a time. This could be replaced with some custom blocking code, which (when combined with selective diverts) would allow it to then use the same queue name for both producer and consumer. Which would make it completely transparent to clients. Also, right now the queues/topics/diverts have to be manually created. With a little more coding, the diverts could be automatically created and applied by matching a wildcard on the address. Which would greatly simplify the configuration necessary to use it. But all of that is for another day when I maybe get some more free time‚Ä¶ Which is code for ‚Äúprobably never‚Äù. üòÇ</p><p><img src="bidi-complex-architecture.png" alt="Bi-directional Complex Architecture"></p><p><strong>Summary</strong></p><p>So which option is right for you? Easy‚Ä¶ the simplest one that meets your requirements. Whatever they may be.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;In &lt;a href=&quot;/2017/08/16/bridging_apache_artemis/&quot; title=&quot;a previous post&quot;&gt;a previous post&lt;/a&gt;, I wrote about setting up a bridge between &lt;a href=&quot;https://activemq.apache.org/components/artemis/&quot;&gt;Apache Artemis&lt;/a&gt; and another JMS broker. Specifically in that case, I used IBM MQ. For part 2, I‚Äôd like to cover something a little more complex. Bridging between &lt;a href=&quot;https://activemq.apache.org/components/artemis/&quot;&gt;Apache Artemis&lt;/a&gt; and &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Apache Kafka&lt;/a&gt;.</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="artemis" scheme="https://blog.joshdreagan.com/tags/artemis/"/>
    
    <category term="kafka" scheme="https://blog.joshdreagan.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Dropping Dups With Camel</title>
    <link href="https://blog.joshdreagan.com/2020/03/20/dropping_dups_with_camel/"/>
    <id>https://blog.joshdreagan.com/2020/03/20/dropping_dups_with_camel/</id>
    <published>2020-03-20T20:57:20.000Z</published>
    <updated>2021-01-14T22:53:28.910Z</updated>
    
    <content type="html"><![CDATA[<p>In <a href="/2019/10/14/artemis_disaster_recovery/" title="my last post">my last post</a>, I talked about a couple of strategies for setting up disaster recovery for <a href="https://activemq.apache.org/components/artemis/">Apache Artemis</a> brokers. In hindsight though, I thought that the subject of the <a href="https://camel.apache.org/components/latest/eips/idempotentConsumer-eip.html">Idempotent Camel Consumer</a> could have used a little more discussion.<a id="more"></a></p><p>In that blog post, I mirrored data between two Artemis brokers using diverts and bridges, and then used an idempotent Camel consumer to prevent duplicate processing. In the <a href="https://github.com/joshdreagan/artemis-async-dr">code example</a> I provided, I had configured the Camel consumer to use a relational DB as its <code>IdempotentRepository</code> implementation. Specifically, it was this part of the diagram that we‚Äôre talking about:</p><p><img src="artemis_async_dr_snip.png"></p><p>The feedback I got was that people didn‚Äôt want to involve yet another component such as a relational DB into their messaging architecture. But the choice of a DB was really just an implementation detail. And not a terribly important detail at that. In fact, I mentioned that there were several other available implementations that could be swapped in with no change to the architecture or code. Just a simple modification of the bean wiring.</p><blockquote><p>It even gives me the option to plug in whatever idempotent repository implementation I‚Äôd like. There are several to choose from.</p></blockquote><p>So lets talk a little bit about the different available options, and how this all works in general. At the time of this writing, there are well over 10 available options. Unfortunately, not all of which are listed on <a href="https://camel.apache.org/components/latest/eips/enterprise-integration-patterns.html">the main EIP documentation page</a>. No matter which one you choose, the behavior is the same. When a message is passing through your route, its key is checked against the <code>messageIdRepository</code> that you‚Äôve configured. You get to pick what the key is. Technically, the interface allows for any object to be used as a key, but all of the implementations I‚Äôm aware of use a <code>String</code>. Which is the most common choice anyways‚Ä¶ If that key already exists, the message is skipped (or optionally processed, but marked with a ‚ÄúCamelDuplicateMessage‚Äù header). If the key did not exist, the message will be processed and its key added to the repository so that, next time, it will be skipped (or marked). Of course there‚Äôs a bit more to it with exception handling and all, but the end result is that you never process the same message more than once. No matter how many times it is sent to you. This is a super important, but often overlooked feature that most clients really should implement. It‚Äôs currently the best solution that we have to the <a href="https://en.wikipedia.org/wiki/Two_Generals%27_Problem">two generals problem</a> in computer science.</p><p>Some of the implementations are persistent (ie, <code>FileIdempotentRepository</code>, <code>JdbcIdempotentRepository</code>, <code>KafkaIdempotentRepository</code>, ‚Ä¶). Some are not (ie, <code>MemoryIdempotentRepository</code>). Some give you the option (ie, <code>InfinispanIdempotentRepository</code>, <code>HazelcastIdempotentRepository</code>, ‚Ä¶). You can pick the right one based on your requirements for speed vs ability to recover in the case of an application restart.</p><p>Now that we‚Äôve covered the basics, let‚Äôs get back to the original Artemis DR use case‚Ä¶ Given that we wanted persistence, but no additional components (ie, DBs, data grids, ‚Ä¶), my suggestion was the simple <code>FileIdempotentRepository</code>. It basically just uses a flat file to store key entries. Each entry being a single line within the file. So no extra components required. Just a filesystem. Which I‚Äôm going to go ahead and guess that you already had. Unfortunately, upon further inspection of the code, I saw some possible issues that might arise.</p><p>First, it looks like it does handle concurrency, but only within a single JVM. While this is not an issue for the specific case we‚Äôre talking about (because each JVM would have its own store), it might be something to consider for others. The bigger issue though, is around performance. During normal operation, when a key is added to the <code>FileIdempotentRepository</code> the implementation will add it to an internal cache, and then append it to the persistent file store. If the application restarts, it will load its cache from that persistent file, and then business as usual. However, once the store reaches capacity, it will add to its internal cache, and then re-write the whole cache to the file store (squashing the previous file and its entries). So what you will see is that performance seems great until you hit your max file store size. Then it will tank (depending, of course, on how many entries you keep)‚Ä¶ Not ideal.</p><p>At this point, I could just recommend that you use one of the data grid/cache based implementations (of which there are several). They will all handle concurrency, can do persistence, and will perform great. But I‚Äôm stuck at home, and had a bit of free time. So I figured, why not crank out a new, improved file based implementation?</p><p>I call my implementation the <code>DirectoryIdempotentRepository</code>. Basically, instead of writing a single file of idempotent keys, I just use atomic file operations to write keys as individual files within a directory. That way, I don‚Äôt have to worry about concurrent access (even across JVMs) as every operation is atomic. And no need to worry about file-locking since each piece of data is represented as a separate file. Furthermore, I got rid of the internal cache since I can just do a <code>Files.exists(Path path, LinkOption... options)</code> to see if my repo contains a key. Neat! Here‚Äôs a link to the full source: <a href="https://github.com/joshdreagan/camel-directory-idrepo">https://github.com/joshdreagan/camel-directory-idrepo</a>.</p><p>So now I have a fast, concurrency safe, simple implementation that requires no extra components. Just a filesystem. I still have to synchronize it between DCs though. But that can be done using the built-in mechanism that my filesystem provides (like Ceph or Gluster replication), or by using a ‚Äúdecorator‚Äù implementation that publishes the repository commands to a mirrored topic like I did in my previous post.</p><p>This all got me thinking though‚Ä¶ It‚Äôd be really nice if I could just use some native feature of Artemis to persist my idempotent repository. Then, I wouldn‚Äôt have to include any extra components, and I wouldn‚Äôt have to worry about synchronizing my data across DCs. All data (messages and idempotent keys) would be handled via a single persistence mechanism, and all replication would use the same divert/bridge features and follow the same pattern as my normal message queues.</p><p>The problem is that, with a typical queue, messages are only removed via expiration or consumption. And, in the case of consumption, they can only be consumed once. That doesn‚Äôt really fit our requirements. But what about topics? Well, with a typical topic, messages can indeed be consumed by multiple consumers. But only if those consumers are active when the message was produced, or if they registered as a durable subscriber <em>before</em> the message was produced. And only once for each consumer. So that‚Äôs no good either. Ideally, we want a bounded fifo queue (so it won‚Äôt grow endlessly) that supports message expiry (so we can discard old messages), and lets multiple consumers read through both existing messages as well as receive new messages. Luckily, Artemis has a few tricks up its sleeve.</p><p>There‚Äôs a really cool new feature called a <a href="https://activemq.apache.org/components/artemis/documentation/latest/ring-queues.html">‚Äúring queue‚Äù</a>. It operates just like a bounded fifo queue. You set a maximum size, and it will continue to append messages as they are received. Once it reaches its bound, it will keep accepting new messages, dropping off the oldest ones to make room. And like all destination types, it supports message expiry. So that gets us part of the way there. But if you consume a message from a ring queue, it‚Äôs gone. And no one else will get it. So that doesn‚Äôt really do us much good if we‚Äôre trying to use it for persistence. That is, if our application comes back online and tries to rebuild its state, our messages will have already been consumed and we will have no data.</p><p>There is another feature, however, that was intended to be used with <a href="https://activemq.apache.org/components/artemis/documentation/latest/last-value-queues.html">‚Äúlast value queues‚Äù</a>. It‚Äôs called the ‚Äúnon-destructive consumer‚Äù. Basically, it allows a consumer to consume a message from a queue, without Artemis removing said message. So that means that, if I have multiple consumers, they will all receive a copy of every message. If they restart, they will again receive a copy of every message (starting from the beginning of the queue). Perfect!</p><p>So now we have everything we need to build an <code>IdempotentRepository</code> implementation that uses an Artemis ring queue as its persistence mechanism. On startup, we can read through the messages on the queue (in a non-destructive manner) and build an internal cache of keys. As new keys are added, we can simply update our internal cache, and publish a command message to the queue. If we restart, all of our data will still be there and we can rebuild the cache by simply re-reading through the queue. In addition, any additional applications or instances will receive the same data both at startup, and as they are added. And that‚Äôs exactly what I did‚Ä¶ Take a look at the source if you want to see how it all works: <a href="https://github.com/joshdreagan/camel-artemis-idrepo">https://github.com/joshdreagan/camel-artemis-idrepo</a>.</p><p>But how does this help me really? Well, now I have an <code>IdempotentRepository</code> implementation based entirely on Artemis for persistence. No external components required. Also, since my keys are being stored on an Artemis topic, I can simplify my previous DR architecture and remove the extra decorator I had created to publish and replicate my repository command messages to an Artemis topic, as well as the piece that processed said command messages. In the end, my simplified architecture looks like this:</p><p><img src="artemis_async_dr_simplified.png"></p><p>Much better! :)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;In &lt;a href=&quot;/2019/10/14/artemis_disaster_recovery/&quot; title=&quot;my last post&quot;&gt;my last post&lt;/a&gt;, I talked about a couple of strategies for setting up disaster recovery for &lt;a href=&quot;https://activemq.apache.org/components/artemis/&quot;&gt;Apache Artemis&lt;/a&gt; brokers. In hindsight though, I thought that the subject of the &lt;a href=&quot;https://camel.apache.org/components/latest/eips/idempotentConsumer-eip.html&quot;&gt;Idempotent Camel Consumer&lt;/a&gt; could have used a little more discussion.</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="artemis" scheme="https://blog.joshdreagan.com/tags/artemis/"/>
    
  </entry>
  
  <entry>
    <title>Artemis Disaster Recovery</title>
    <link href="https://blog.joshdreagan.com/2019/10/14/artemis_disaster_recovery/"/>
    <id>https://blog.joshdreagan.com/2019/10/14/artemis_disaster_recovery/</id>
    <published>2019-10-15T04:55:40.000Z</published>
    <updated>2025-06-20T02:14:02.523Z</updated>
    
    <content type="html"><![CDATA[<p>A few years back, I wrote a blog about <a href="/2016/07/28/ha_deployments_with_fuse/" title="HA strategies for Fuse&#x2F;AMQ">HA strategies for Fuse&#x2F;AMQ</a>. In it, I talked about a few potential solutions for setting up a DR (Disaster Recovery) configuration for ActiveMQ. The most popular solution, it seems, was to utilize block-level disk replication software. Since it‚Äôs been quite a while, and since we‚Äôve updated our messaging code base to Apache Artemis, I figured I‚Äôd write up a new post with yet another potential architecture.<a id="more"></a></p><p>Before I begin, I‚Äôd like to state that the previous solution that I had outlined, though written for ActiveMQ instead of Artemis, still applies. If you want to guarantee absolutely no loss or duplication of data, you must replicate things synchronously. So if that‚Äôs your requirement, my recommendation would still be to use a block-level disk replication software like <a href="https://www.linbit.com/en/configuring-an-hadr-apache-activemq-cluster/">LINBIT DRBD</a> or <a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html/configuring_amq_broker/configuring-fault-tolerant-system-configuring">Red Hat Ceph</a>. However, because these solutions are fully synchronous, they can <a href="/2017/03/15/activemq_ha_performance_comparison/" title="perform a bit slowly">perform a bit slowly</a>. In addition, there are other issues that you need to account for. For instance, what do you do if the backup site is down? Do you keep the primary site running and have the backup ‚Äúcatch up‚Äù once it comes online? If so, then you risk the loss or duplication of data if you suffer an outage while the two are out-of-sync. If not, then you have two potential points of failure that would cause a total outage as an outage of either DC would mean you‚Äôd have to stop processing.</p><p>But what if I‚Äôm willing to give up a little bit of that ‚Äúabsolute‚Äù guarantee in order to get a solution that performs well? For that, I‚Äôll need to switch over to a solution that‚Äôs asynchronous in nature (or ‚Äúnear real-time‚Äù as Oracle likes to call it). That should take care of my performance issues. But what about the the other scenario where my backup site is down? I‚Äôll need a way to buffer up the data so that, when the backup site comes back online, I can finish sync‚Äôing and not drop anything. Finally, it would also be nice to be able to fail back once the primary comes back online. That means that I‚Äôll need to sync data from primary to backup, but also from backup to primary.</p><p>So what would such a solution look like in Artemis? Well, sort like this:</p><p><img src="artemis_async_dr.png"></p><p>Let‚Äôs break it down‚Ä¶ First, we can use a feature known as ‚Äúdiverts‚Äù to wiretap off a local copy of our messages into one or more buffer queues. Then, we can use something called a ‚Äúcore bridge‚Äù to forward the buffered messages to an address on a secondary site. Technically, using these features, we can have as many backup sites as we‚Äôd like. We‚Äôre only limited by our available bandwidth. So mirroring of data is actually quite simple. At least in concept‚Ä¶</p><p>One issue that we will encounter is that, because we‚Äôre forwarding to/from the same named address on each data center, the messages will continue to divert and forward around in an endless loop. Not ideal. What we really need is some way to selectively divert messages so that we‚Äôll only copy/forward messages that originated at our DC. Any other messages would still be processed, but we would assume that they were sent from another DC and thus we would not need to forward them around. Luckily, diverts include the ability to filter. So we can simply add a header stating the origin DC and then use that to filter out any messages that did not originate in our DC. That means that we just need all of our clients to include that header, and we‚Äôve solved our circular forwarding issue. But what if I don‚Äôt control or can‚Äôt change my clients to add that header? Well, core bridges allow you to specify a message transformer. So we can use that to automatically ‚Äústamp‚Äù the messages as they‚Äôre forwarded. Neat!</p><p>So now we‚Äôve got the mirroring portion done. What‚Äôs next? Ok‚Ä¶ A mirror is just a copy of the data. So that means that when we failover to our backup, we‚Äôll process all the same data again resulting in duplicates. This might be ok if your application code handles it. If so, you can stop here. This is all you need. If, however, your application code does not handle duplicates, we‚Äôll need a solution to filter out messages that we‚Äôve already processed. For that, of course, I‚Äôll use Camel. :)</p><p>Camel has an EIP known as <a href="https://camel.apache.org/components/latest/eips/idempotentConsumer-eip.html">Idempotent Consumer</a> that will keep track of processed IDs and skip them if you try to process them again. Perfect! We‚Äôll just use that‚Ä¶ It even gives me the option to plug in whatever idempotent repository implementation I‚Äôd like. There are several to choose from. Hopefully the next issue is obvious at this point. If I‚Äôve got a local (to my DC) repository keeping track of processed message IDs, how do I get that information over to my other DC. What I really need is a way to add something to my local ID repo, and also mirror it off to my other DC so it‚Äôs added in that DCs local repo as well. There are lots of ways to do this (ie, Oracle GoldenGate, Debezium, Ceph, DRBD, ‚Ä¶), but I‚Äôm already replicating my message data in artemis using diverts and core bridges. So why don‚Äôt I just do that here as well? Basically, I just need to create a custom idempotent repository implementation that updates its local repo, but also sends a notification to an Artemis address. That message will be diverted to a buffer queue, then forwarded across with a core bridge. Then I just need one more component that picks those messages up and adds them to the local ID repo. Easy!</p><p>So now I have a solution that will mirror data between DCs. I can mirror between as many as I‚Äôd like. I can fail over and fail back. I can detect and skip duplicates. So what‚Äôs the catch? Well, because my replication is asynchronous, I can‚Äôt run my consumer in more than one DC at a time. If I do, I will run the risk of processing duplicates since the messages might replicate and get processed before the idempotent ID notification. But since this is a DR solution, that‚Äôs probably not too big of a deal. Technically though, I lied a bit. A more accurate statement would be that I can‚Äôt run a consumer <strong>for a given queue</strong> on more than once DC at a time. That means that, if I have several queues, I can spread my consumers across DCs evenly. If I need to, I can fail them over to another DC, and then fail them back when ready. But I‚Äôm partitioning the processing of my individual queues across my DCs. This is known as ‚Äúpartitioned active/active‚Äù and it means I get to utilize the hardware on all my DCs instead of having them just sit around as backups. Awesome!</p><p>All of this is fine and good. But how about some code? Here‚Äôs a link to a repo where I‚Äôve implemented this solution: [<a href="https://github.com/joshdreagan/artemis-async-dr">https://github.com/joshdreagan/artemis-async-dr</a>]. There are instructions for running it on bare metal (or AWS, or whatever), as well as instructions for running it on OpenShift. Enjoy!</p><blockquote><p><em>Update: Check out <a href="/2020/03/20/dropping_dups_with_camel/" title="my next post">my next post</a> for an updated, simpler architecture.</em></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;A few years back, I wrote a blog about &lt;a href=&quot;/2016/07/28/ha_deployments_with_fuse/&quot; title=&quot;HA strategies for Fuse&amp;#x2F;AMQ&quot;&gt;HA strategies for Fuse&amp;#x2F;AMQ&lt;/a&gt;. In it, I talked about a few potential solutions for setting up a DR (Disaster Recovery) configuration for ActiveMQ. The most popular solution, it seems, was to utilize block-level disk replication software. Since it‚Äôs been quite a while, and since we‚Äôve updated our messaging code base to Apache Artemis, I figured I‚Äôd write up a new post with yet another potential architecture.</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="spring-boot" scheme="https://blog.joshdreagan.com/tags/spring-boot/"/>
    
    <category term="artemis" scheme="https://blog.joshdreagan.com/tags/artemis/"/>
    
  </entry>
  
  <entry>
    <title>Streaming in the Cloud With Camel and Strimzi</title>
    <link href="https://blog.joshdreagan.com/2019/05/30/streaming_in_the_cloud_with_camel_and_strimzi/"/>
    <id>https://blog.joshdreagan.com/2019/05/30/streaming_in_the_cloud_with_camel_and_strimzi/</id>
    <published>2019-05-30T23:23:43.000Z</published>
    <updated>2021-01-14T22:53:29.023Z</updated>
    
    <content type="html"><![CDATA[<p>So I was at one of my favorite customers several months back, and was demo‚Äôing our new <a href="https://access.redhat.com/products/red-hat-amq#streams">AMQ Streams</a> product (aka <a href="https://strimzi.io/">Strimzi</a>). They asked for some example <a href="https://camel.apache.org/">Apache Camel</a> apps to show them how to securely connect to their newly installed Kafka on OpenShift. Not an unreasonable request‚Ä¶ But try as I might, I could not find any existing examples. Sure, I found examples of Camel talking to Kafka, but not doing so securely. I found examples of Camel talking to Kafka <em>with</em> authz, but not running in OpenShift. I even found examples of plain Java clients running in OpenShift <strong>and</strong> doing authz, but not using Camel. So I offered to create a set of examples for them ‚Äúas soon as I got some free time‚Äù. Six months later‚Ä¶ here we go! ;)<a id="more"></a></p><p>For the purpose of this blog, let‚Äôs go ahead and assume that you‚Äôve already installed OpenShift. Let‚Äôs also assume that you‚Äôve installed Strimzi onto your OpenShift environment and have a Kafka cluster running. There‚Äôs no need to cover either of those topics since they‚Äôre both thoroughly outlined in the existing documentation. Instead, let‚Äôs focus a bit on authentication and authorization. And more specifically, how those work in Strimzi. </p><p>At present, there are two mechanisms for authentication (TLS or SCRAM-SHA-512), and one for authorization (simple). So we‚Äôll need to both enable ‚Äúsimple‚Äù authorization on the broker, and choose/enable one of the authorization mechanisms on the listener. It‚Äôs actually really easy! You can just follow the docs <a href="https://strimzi.io/docs/master/#assembly-kafka-authentication-and-authorization-deployment-configuration-kafka">here</a>. So now my brokers expect me to authenticate? Great‚Ä¶ How do I do that? Well, you‚Äôll need to create and apply a ‚ÄúKafkaUser‚Äù definition. In said ‚ÄúKafkaUser‚Äù definition, you‚Äôll specify both the authentication type (which should match the authentication type that you‚Äôve chosen for your listener), and the authorization roles. The authorization roles are what gives permissions to a specific resource. So, for instance, whether or not a user has access to read or write to a topic. They are detailed in the docs <a href="https://strimzi.io/docs/master/#simple_authorization_2">here</a>. Once you‚Äôve applied your ‚ÄúKafkaUser‚Äù definition to OpenShift, the ‚Äú<a href="https://strimzi.io/docs/master/#assembly-user-operator-str">User Operator</a>‚Äú will detect it and generate some resources for you automagically. Neat! But what does it generate? Well that depends on the authentication type you‚Äôve chosen. Let‚Äôs start with SCRAM since it‚Äôs the easiest. </p><p><strong>SCRAM-SHA-512</strong></p><p>When you create a ‚ÄúKafkaUser‚Äù with a ‚Äúscram-sha-512‚Äù authentication type, the ‚ÄúUser Operator‚Äù will generate an OpenShift ‚ÄúSecret‚Äù with the same name. So, if I‚Äôve defined a user named ‚Äúbob‚Äù, I will see a secret named ‚Äúbob‚Äù that has a key called ‚Äúpassword‚Äù. Those are the credentials that I‚Äôll use to connect. Seems straighforward‚Ä¶ But how do I get that into my app? The easiest way is to inject the password into an environment variable in your container. You can do this in your <code>deployment.yml</code> file for your app. Here‚Äôs an example:</p><figure class="highlight yaml"><figcaption><span>deployment.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#...</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">KAFKA_USER_PASSWORD</span></span><br><span class="line">  <span class="attr">valueFrom:</span></span><br><span class="line">    <span class="attr">secretKeyRef:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">bob</span></span><br><span class="line">      <span class="attr">key:</span> <span class="string">password</span></span><br><span class="line"><span class="comment">#...</span></span><br></pre></td></tr></table></figure><p>If I include the above snippet into my <code>deployment.yml</code>, I will have a <code>KAFKA_USER_PASSWORD</code> environment variable (containing my generated password) available to me inside of my container. So I can just reference it in my <code>application.yml</code> file like below.</p><figure class="highlight yaml"><figcaption><span>application.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#...</span></span><br><span class="line"><span class="attr">camel:</span></span><br><span class="line">  <span class="attr">component:</span></span><br><span class="line">    <span class="attr">kafka.configuration:</span></span><br><span class="line">      <span class="attr">security-protocol:</span> <span class="string">SASL_PLAINTEXT</span></span><br><span class="line">      <span class="attr">sasl-mechanism:</span> <span class="string">SCRAM-SHA-512</span></span><br><span class="line">      <span class="attr">sasl-jaas-config:</span> <span class="string">org.apache.kafka.common.security.scram.ScramLoginModule</span> <span class="string">required</span> <span class="string">username=&quot;bob&quot;</span> <span class="string">password=&quot;$&#123;KAFKA_USER_PASSWORD&#125;&quot;;</span></span><br><span class="line"><span class="comment">#...</span></span><br></pre></td></tr></table></figure><p>Now, when my Camel app connects to Kafka, it will connect as my specified user, using the auto-generated password. And, if desired, I can have OpenShift trigger a reload of my app if the password is updated/regenerated. Cool beans! On to a slightly more complex case‚Ä¶</p><p><strong>TLS</strong></p><p>When using ‚Äútls‚Äù as my authentication type, I (as a client) will need both the broker‚Äôs public key, as well as my user‚Äôs public &amp; private keys. Such is the nature of mutual auth‚Ä¶ Similarly though, those will be generated for me by the various operators. But it‚Äôs a little more complicated than the SCRAM case. How so? Well, just like before, I can inject the secret values into environment variables as shown below. So no issues yet.</p><figure class="highlight yaml"><figcaption><span>deployment.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#...</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">KAFKA_CLUSTER_CRT</span></span><br><span class="line">  <span class="attr">valueFrom:</span></span><br><span class="line">    <span class="attr">secretKeyRef:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">my-cluster-cluster-ca-cert</span></span><br><span class="line">      <span class="attr">key:</span> <span class="string">ca.crt</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">KAFKA_USER_CRT</span></span><br><span class="line">  <span class="attr">valueFrom:</span></span><br><span class="line">    <span class="attr">secretKeyRef:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">alice</span></span><br><span class="line">      <span class="attr">key:</span> <span class="string">user.crt</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">KAFKA_USER_KEY</span></span><br><span class="line">  <span class="attr">valueFrom:</span></span><br><span class="line">    <span class="attr">secretKeyRef:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">alice</span></span><br><span class="line">      <span class="attr">key:</span> <span class="string">user.key</span></span><br><span class="line"><span class="comment">#...</span></span><br></pre></td></tr></table></figure><p>But I can‚Äôt just use those key/cert values directly. I actually need to create a keystore &amp; truststore, and then import those keys into their appropriate stores. Well, how do I go about that? One solution would be to use a custom container image and start script as per <a href="https://github.com/strimzi/client-examples">Jakub‚Äôs example</a>. While this solution is very clever (as is Jakub :)), I wondered if there was a way to do it all within my app code. A quick Google search and, lo and behold, I find <a href="https://github.com/heroku/env-keystore">env-keystore</a>! This handy little library will let me easily create Java keystores using arbitrary keys/certs from string values. So now I can actually use those injected environment variable values. What‚Äôs more, it can write the stores out to a file once I‚Äôve created them. And since it uses <a href="https://www.bouncycastle.org/">Bouncy Castle</a>, it can handle both Java formatted keys/certs as well as OpenSSL formatted ones (which is what Strimzi will generate for you). Good stuff! So if I include the below dependency‚Ä¶</p><figure class="highlight xml"><figcaption><span>pom.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.heroku.sdk<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>env-keystore<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>x.x.x<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>And add a little bit of initialization code‚Ä¶</p><figure class="highlight java"><figcaption><span>KafkaComponentCustomizer.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.camel.examples;</span><br><span class="line"></span><br><span class="line"><span class="comment">//import ...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaComponentCustomizer</span> <span class="keyword">implements</span> <span class="title">ComponentCustomizer</span>&lt;<span class="title">KafkaComponent</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Autowired</span> <span class="keyword">private</span> KafkaComponentConfiguration kafkaConfiguration;</span><br><span class="line">  <span class="meta">@Value(&quot;#&#123;systemEnvironment[&#x27;KAFKA_CLUSTER_CRT&#x27;]&#125;&quot;)</span> <span class="keyword">private</span> String kafkaClusterCrt;</span><br><span class="line">  <span class="meta">@Value(&quot;#&#123;systemEnvironment[&#x27;KAFKA_USER_KEY&#x27;]&#125;&quot;)</span> <span class="keyword">private</span> String kafkaUserKey;</span><br><span class="line">  <span class="meta">@Value(&quot;#&#123;systemEnvironment[&#x27;KAFKA_USER_CRT&#x27;]&#125;&quot;)</span> <span class="keyword">private</span> String kafkaUserCrt;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">customize</span><span class="params">(KafkaComponent component)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        BasicKeyStore truststore = <span class="keyword">new</span> BasicKeyStore(kafkaClusterCrt, kafkaConfiguration.getConfiguration().getSslTruststorePassword());</span><br><span class="line">        truststore.store(Paths.get(kafkaConfiguration.getConfiguration().getSslTruststoreLocation()));</span><br><span class="line"></span><br><span class="line">        BasicKeyStore keystore = <span class="keyword">new</span> BasicKeyStore(kafkaUserKey, kafkaUserCrt, kafkaConfiguration.getConfiguration().getSslKeystorePassword());</span><br><span class="line">        keystore.store(Paths.get(kafkaConfiguration.getConfiguration().getSslKeystoreLocation()));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException | GeneralSecurityException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>My app can now grab those generated keys/certs from the OpenShift secrets, inject them into env variables, use those values to generate the client keystore/trustore, then reference those stores when it makes its connection to the brokers. More difficult than SCRAM, but still not too bad. Although‚Ä¶</p><p><strong>Syncing the secrets</strong></p><p>When the various operators generate secrets for you, they will do so in the namespace where the resources live. That‚Äôs all fine and good if my apps are colocated alongside my Kafka cluster. But what if I want to put my cluster in one namespace (let‚Äôs say one called ‚Äústrimzi‚Äù), and my client apps in another (let‚Äôs say it‚Äôs called ‚Äúfuse‚Äù)? Unfortunately, OpenShift currently won‚Äôt allow me to access secrets between namespaces. So I‚Äôd have to copy the values from the generated secrets in my ‚Äústrimzi‚Äù namespace into manually created secrets in my ‚Äúfuse‚Äù namespace where my client apps live. That sounds super error prone. What do I do if those secrets update/regenerate? Certificates do expire right? I‚Äôll have to make sure that when they update, I‚Äôll go update all the copies. That‚Äôs a recipe for disaster! If only there was a way to syncronize those secrets between namespaces automatically. A little bit of searching and you‚Äôll likely stumble across <a href="https://github.com/appscode/kubed">AppsCode Kubed</a>. </p><p>Kubed is an operator that, once installed, will monitor and sync any secrets you specify (among other things). It will keep them updated if the source secret changes, and even remove the copies if the source secret is deleted. And it can do this across as many namespaces as you need. So no need to worry if you have multiple apps in multiple namespaces. Perfect right!? Well, one minor hitch‚Ä¶</p><p>The way Kubed works, you have to apply an OpenShift annotation to the secret that you want sync‚Äôd. It will then find and monitor any secrets with said annotation, and then sync them to namespaces that have the appropriate label. Unfortunately, if the Strimzi operators see that the secret has been changed in any way (like say, adding an annotation), they will squash those changes and get things back in sync with their configs. Which really <strong>is</strong> what they should do in that case‚Ä¶ There‚Äôs currently a JIRA issue open for adding the ability to specify annotations on the generated secrets via the Strimzi configs. And once that enhancement is made, Kubed will definitely be the way to go. But what can we do in the meantime?</p><p>It‚Äôs not great, but one option is to use a ‚ÄúCronJob‚Äù that will simply execute some bash commands to sync the secrets. Clunky? Yes. Ideal? No. Works? Yes. Here‚Äôs an example one that I wrote to sync the broker‚Äôs public key. I installed it into the ‚Äúfuse‚Äù namespace, and it sync‚Äôd my secret from the ‚Äústrimzi‚Äù namespace, as needed, every second.</p><figure class="highlight yaml"><figcaption><span>secret-sync-cronjob.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">camel-kafka-authz-secret-sync</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&quot;* * * * *&quot;</span></span><br><span class="line">  <span class="attr">concurrencyPolicy:</span> <span class="string">Forbid</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">serviceAccountName:</span> <span class="string">camel-kafka-authz-sa</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cluster-ca-cert-sync</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">openshift/origin-cli</span></span><br><span class="line">            <span class="attr">command:</span> [<span class="string">&quot;bash&quot;</span>,  <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;export SRC=\&quot;$(oc extract -n strimzi secrets/my-cluster-cluster-ca-cert --keys=ca.crt --to=-)\&quot;; export DST=\&quot;$(oc extract -n fuse secrets/my-cluster-cluster-ca-cert --keys=ca.crt --to=-)\&quot;; if [ -n \&quot;$SRC\&quot; ] &amp;&amp; [ \&quot;$DST\&quot; != \&quot;$SRC\&quot; ]; then echo &#x27;Values differ. Syncing...&#x27;; oc create secret generic -n fuse --dry-run -o yaml my-cluster-cluster-ca-cert --from-literal=\&quot;ca.crt=$SRC\&quot; | oc apply -f -; fi;&quot;</span>]</span><br></pre></td></tr></table></figure><p>So once again, we‚Äôve managed to solve all the worlds problems. Or maybe none of them‚Ä¶ :) Either way, if you‚Äôre looking for more than just snippets, take a look at the full source code for this example: <a href="https://github.com/joshdreagan/camel-kafka-authz">https://github.com/joshdreagan/camel-kafka-authz</a>.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;So I was at one of my favorite customers several months back, and was demo‚Äôing our new &lt;a href=&quot;https://access.redhat.com/products/red-hat-amq#streams&quot;&gt;AMQ Streams&lt;/a&gt; product (aka &lt;a href=&quot;https://strimzi.io/&quot;&gt;Strimzi&lt;/a&gt;). They asked for some example &lt;a href=&quot;https://camel.apache.org/&quot;&gt;Apache Camel&lt;/a&gt; apps to show them how to securely connect to their newly installed Kafka on OpenShift. Not an unreasonable request‚Ä¶ But try as I might, I could not find any existing examples. Sure, I found examples of Camel talking to Kafka, but not doing so securely. I found examples of Camel talking to Kafka &lt;em&gt;with&lt;/em&gt; authz, but not running in OpenShift. I even found examples of plain Java clients running in OpenShift &lt;strong&gt;and&lt;/strong&gt; doing authz, but not using Camel. So I offered to create a set of examples for them ‚Äúas soon as I got some free time‚Äù. Six months later‚Ä¶ here we go! ;)</summary>
    
    
    
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="spring-boot" scheme="https://blog.joshdreagan.com/tags/spring-boot/"/>
    
    <category term="kafka" scheme="https://blog.joshdreagan.com/tags/kafka/"/>
    
    <category term="openshift" scheme="https://blog.joshdreagan.com/tags/openshift/"/>
    
    <category term="strimzi" scheme="https://blog.joshdreagan.com/tags/strimzi/"/>
    
  </entry>
  
  <entry>
    <title>Camel Aggregation Strategies</title>
    <link href="https://blog.joshdreagan.com/2018/08/30/camel_aggregation_strategies/"/>
    <id>https://blog.joshdreagan.com/2018/08/30/camel_aggregation_strategies/</id>
    <published>2018-08-31T04:43:34.000Z</published>
    <updated>2021-01-14T22:53:28.839Z</updated>
    
    <content type="html"><![CDATA[<p>One of the many (many many many) extension points inside <a href="http://camel.apache.org/">Apache Camel</a> is the <code>org.apache.camel.processor.aggregate.AggregationStrategy</code>. These are used in everything from <a href="http://camel.apache.org/content-enricher.html">Content Enrichers</a> to <a href="http://camel.apache.org/splitter.html">Splitters</a> to <a href="http://camel.apache.org/aggregator2.html">Aggregators</a> and more. Since their use is so prevalent, I figured that I‚Äôd dedicate a whole blog post just for them. So here goes‚Ä¶<a id="more"></a></p><p>So what are AggregationStrategy‚Äôs anyway? Simple‚Ä¶ they‚Äôre implementations of the <code>org.apache.camel.processor.aggregate.AggregationStrategy</code> that allow you to specify exactly how two exchanges will be merged. This specification can be as simple or as complex as you require for your use case. Maybe you just want to take the first response and ignore all others. Maybe you want to combine the XML bodies into a list and then merge a select few headers. The limit really is your imagination. But what do I mean by ‚Äúmerging exchanges‚Äù? Let‚Äôs take a look at a few concrete examples.</p><h2 id="Out-of-the-Box"><a href="#Out-of-the-Box" class="headerlink" title="Out of the Box"></a>Out of the Box</h2><p>For starters, there are several implementations that are included out of the box. You can use them ‚Äúas-is‚Äù without writing any custom code at all. Let‚Äôs talk through a few of them with some potential use cases.</p><p>The first is the <code>org.apache.camel.processor.aggregate.UseLatestAggregationStrategy</code> implementation. It‚Äôs the default strategy for most Camel EIPs that accept aggregation strategies. So if you don‚Äôt specify any strategy, this is likely the one you‚Äôre using. Basically, it takes the last exchange it receives and just uses that (ignoring any others that may have been aggregated prior). One example use case for this would be when doing an <a href="http://camel.apache.org/aggregator2.html">Aggregator</a>. Perhaps you‚Äôre receiving many messages as input, but you want to buffer them (giving the user time to send in corrections/updates), and then only send the latest message to the backend after some period of inactivity. That might look like below:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;useLatest&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.apache.camel.processor.aggregate.UseLatestAggregationStrategy&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">camelContext</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://activemq.apache.org/camel/schema/spring&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">route</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">from</span> <span class="attr">uri</span>=<span class="string">&quot;direct:acceptUpdateableRequest&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aggregator</span> <span class="attr">strategyRef</span>=<span class="string">&quot;useLatest&quot;</span> <span class="attr">completionTimeout</span>=<span class="string">&quot;5000&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">correlationExpression</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">header</span>&gt;</span>UniqueRequestID<span class="tag">&lt;/<span class="name">header</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">correlationExpression</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">to</span> <span class="attr">uri</span>=<span class="string">&quot;direct:bufferedSendToBackend&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">aggregator</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">route</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">camelContext</span>&gt;</span></span><br></pre></td></tr></table></figure><p>For the next use case, we‚Äôll cover the (very similar) <code>org.apache.camel.processor.aggregate.UseOriginalAggregationStrategy</code> implementation. As the name would suggest, it ‚Äúmerges‚Äù two exchanges together by completely ignoring the new exchange and just taking the original. One example of where this might be useful is when doing a <a href="http://camel.apache.org/multicast.html">Multicast</a>. Lets say I wanted to send a copy of a message off to multiple recipients, but really don‚Äôt care about their response. After the multicast is completed, I want to perform some transformation on the original message, and then return the result. Instead of rolling my own implementation, I could simply use the one provided. Something like this:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;useOriginal&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.apache.camel.processor.aggregate.UseOriginalAggregationStrategy&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">camelContext</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://activemq.apache.org/camel/schema/spring&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">route</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">from</span> <span class="attr">uri</span>=<span class="string">&quot;direct:acceptRequest&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">multicast</span> <span class="attr">strategyRef</span>=<span class="string">&quot;useOriginal&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">to</span> <span class="attr">uri</span>=<span class="string">&quot;direct:recipient1&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">to</span> <span class="attr">uri</span>=<span class="string">&quot;direct:recipient2&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">multicast</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">to</span> <span class="attr">uri</span>=<span class="string">&quot;xslt:transformOriginal.xsl&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">route</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">camelContext</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The next set of implementations, I‚Äôll cover as a group. They are the <code>org.apache.camel.processor.aggregate.GroupedExchangeAggregationStrategy</code>, <code>org.apache.camel.processor.aggregate.GroupedMessageAggregationStrategy</code>, and <code>org.apache.camel.processor.aggregate.GroupedBodyAggregationStrategy</code> strategies. They will combine the exchanges into a list and then pass the list itself along to the next processor. They only differ by what they put in the list (ie, <code>List&lt;Exchange&gt;</code>, <code>List&lt;Message&gt;</code>, or <code>List&lt;Object&gt;</code>). So, for instance, if you wanted to split a message, process each individual part, and then combine the individual results back into a list, you could do so easily using a <a href="http://camel.apache.org/splitter.html">Splitter</a> like below:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;listOfBody&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.apache.camel.processor.aggregate.GroupedBodyAggregationStrategy&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">camelContext</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://activemq.apache.org/camel/schema/spring&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">route</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">from</span> <span class="attr">uri</span>=<span class="string">&quot;direct:acceptListRequestExpectingListResponse&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">split</span> <span class="attr">strategyRef</span>=<span class="string">&quot;listOfBody&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">simple</span>&gt;</span>$&#123;body&#125;<span class="tag">&lt;/<span class="name">simple</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">to</span> <span class="attr">uri</span>=<span class="string">&quot;direct:sendIndividualRequest&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">split</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">route</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">camelContext</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The final implementation that I‚Äôll cover for this section is the <code>org.apache.camel.util.toolbox.XsltAggregationStrategy</code>. It allows you to provide an XSLT that will be used to merge the original and new exchanges together. A great use case for this is when you want to <a href="http://camel.apache.org/content-enricher.html">Enrich</a> an XML request with some extra data retrieved from a backend.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;xsltEnrichmentStrategy&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.apache.camel.util.toolbox.XsltAggregationStrategy&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">value</span>=<span class="string">&quot;/META-INF/xslt/EnrichIndexHtml.xsl&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">camelContext</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://activemq.apache.org/camel/schema/spring&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">route</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">from</span> <span class="attr">uri</span>=<span class="string">&quot;direct:acceptRequest&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">to</span> <span class="attr">uri</span>=<span class="string">&quot;language:constant:classpath:/META-INF/html/index.html&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">enrich</span> <span class="attr">strategyRef</span>=<span class="string">&quot;xsltEnrichmentStrategy&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">constant</span>&gt;</span>direct:fetchCds<span class="tag">&lt;/<span class="name">constant</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">enrich</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">route</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">camelContext</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Since this example is a little more complex, it requires more than just a code snippet to explain. So I‚Äôve put together an example application and thrown it up on GitHub. Take a look‚Ä¶ <a href="https://github.com/joshdreagan/camel-xslt-enricher">https://github.com/joshdreagan/camel-xslt-enricher</a></p><p>It‚Äôs amazing how many use cases these ‚Äúcanned‚Äù aggregation strategies cover. But what if I they‚Äôre not quite exactly what you need?</p><h2 id="Semi-Custom"><a href="#Semi-Custom" class="headerlink" title="Semi-Custom"></a>Semi-Custom</h2><p>In this section, we‚Äôll discuss what I call ‚Äúsemi-custom‚Äù strategies. Basically, they‚Äôre base/utility classes that make it easy for you to implement a custom strategy with very little Java code.</p><p>The first class we‚Äôll talk about is the <code>org.apache.camel.processor.aggregate.AbstractListAggregationStrategy</code>. Similar to the grouping implementations mentioned above, the end result of this strategy is a list of items. The difference is that you have total control over what data gets placed in said list as well as where you pull it from. Here‚Äôs a very simple example implementation:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.camel.examples;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.camel.Exchange;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.processor.aggregate.AbstractListAggregationStrategy;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleListAggregationStrategy</span> <span class="keyword">extends</span> <span class="title">AbstractListAggregationStrategy</span>&lt;<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getValue</span><span class="params">(Exchange exchange)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> exchange.getIn().getHeader(<span class="string">&quot;MyAwesomeHeader&quot;</span>, String.class);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>If you need even more control over the aggregation, you can use the <code>org.apache.camel.util.toolbox.FlexibleAggregationStrategy</code>. The FlexibleAggregationStrategy is a fluent strategy builder that lets you define fairly complex aggregation strategy implementations using a very concise syntax. If you‚Äôre using the Java DSL to define your Camel routes (or are using any Java based bean wiring mechanism), you can just use the fluent builder directly. However, if you‚Äôre using it from the Spring DSL (using Spring‚Äôs XML bean definitions) it might be easier to wrapper it in a simple Java implementation. See below for an example:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.camel.examples;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.camel.Exchange;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.model.language.SimpleExpression;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.processor.aggregate.AggregationStrategy;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.util.toolbox.AggregationStrategies;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CorrelationIdAggregationStrategy</span> <span class="keyword">implements</span> <span class="title">AggregationStrategy</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> AggregationStrategy delegate;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">FluentAggregationStrategy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    delegate = AggregationStrategies.flexible()</span><br><span class="line">            .storeInHeader(<span class="string">&quot;MyCorrelationID&quot;</span>)</span><br><span class="line">            .pick(<span class="keyword">new</span> SimpleExpression(<span class="string">&quot;$&#123;body&#125;&quot;</span>))</span><br><span class="line">    ;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Exchange <span class="title">aggregate</span><span class="params">(Exchange oldExchange, Exchange newExchange)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> delegate.aggregate(oldExchange, newExchange);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>You could then use your implementation like this:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;uuidEnrichmentStrategy&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.apache.camel.examples.CorrelationIdAggregationStrategy&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">camelContext</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://activemq.apache.org/camel/schema/spring&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">route</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">from</span> <span class="attr">uri</span>=<span class="string">&quot;direct:acceptRequest&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">enrich</span> <span class="attr">strategyRef</span>=<span class="string">&quot;uuidEnrichmentStrategy&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">constant</span>&gt;</span>direct:fetchUuid<span class="tag">&lt;/<span class="name">constant</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">enrich</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">route</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">route</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">from</span> <span class="attr">uri</span>=<span class="string">&quot;direct:fetchUuid&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">beanType</span>=<span class="string">&quot;java.util.UUID&quot;</span> <span class="attr">method</span>=<span class="string">&quot;randomUUID&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">convertBodyTo</span> <span class="attr">type</span>=<span class="string">&quot;java.lang.String&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">route</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">camelContext</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Pretty powerful stuff! But what if you‚Äôre feeling even more imaginative?</p><h2 id="Custom"><a href="#Custom" class="headerlink" title="Custom"></a>Custom</h2><p>The last type of strategy that I‚Äôll talk about is a ‚Äúcompletely custom‚Äù implementation. This basically just means that you will implement the <code>org.apache.camel.processor.aggregate.AggregationStrategy</code> interface directly without using any helper base classes (which might restrict you in some ways). Because of this direct implementation, you are free to do literally anything you want.</p><p>One example that I whipped up for a customer a while back is what I called the ‚Äúsemi-streaming aggregation strategy‚Äù.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.camel.examples;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Comparator;</span><br><span class="line"><span class="keyword">import</span> java.util.Objects;</span><br><span class="line"><span class="keyword">import</span> java.util.SortedSet;</span><br><span class="line"><span class="keyword">import</span> java.util.TreeSet;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.CamelContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.CamelContextAware;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.Exchange;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.Message;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.Processor;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.RuntimeCamelException;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.processor.aggregate.AggregateProcessor;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.processor.aggregate.AggregationStrategy;</span><br><span class="line"><span class="keyword">import</span> org.apache.camel.util.ExchangeHelper;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.InitializingBean;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SemiStreamingAggregationStrategy</span> <span class="keyword">implements</span> <span class="title">AggregationStrategy</span>, <span class="title">CamelContextAware</span>, <span class="title">InitializingBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = LoggerFactory.getLogger(SemiStreamingAggregationStrategy.class);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LAST_PROCESSED_INDEX = <span class="string">&quot;CamelAggregatorLastProcessedIndex&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String aggregateProcessorId;</span><br><span class="line">  <span class="keyword">private</span> CamelContext camelContext;</span><br><span class="line">  <span class="keyword">private</span> String sequenceIdHeaderName;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Lazily initialized.</span></span><br><span class="line">  <span class="keyword">private</span> AggregateProcessor _aggregateProcessor;</span><br><span class="line">  <span class="keyword">private</span> Comparator&lt;Message&gt; _messageComparator;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getAggregateProcessorId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> aggregateProcessorId;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAggregateProcessorId</span><span class="params">(String aggregateProcessorId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.aggregateProcessorId = aggregateProcessorId;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCamelContext</span><span class="params">(CamelContext camelContext)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.camelContext = camelContext;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> CamelContext <span class="title">getCamelContext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> camelContext;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getSequenceIdHeaderName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> sequenceIdHeaderName;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSequenceIdHeaderName</span><span class="params">(String sequenceIdHeaderName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.sequenceIdHeaderName = sequenceIdHeaderName;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> AggregateProcessor <span class="title">_aggregateProcessor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (_aggregateProcessor == <span class="keyword">null</span>) &#123;</span><br><span class="line">      _aggregateProcessor = camelContext.getProcessor(aggregateProcessorId, AggregateProcessor.class);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> _aggregateProcessor;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> Comparator&lt;Message&gt; <span class="title">_messageComparator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (_messageComparator == <span class="keyword">null</span>) &#123;</span><br><span class="line">      _messageComparator = (Message t, Message t1) -&gt; t.getHeader(sequenceIdHeaderName, Comparable.class).compareTo(t1.getHeader(sequenceIdHeaderName, Comparable.class));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> _messageComparator;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterPropertiesSet</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Objects.requireNonNull(aggregateProcessorId, <span class="string">&quot;The aggregateProcessorId property must not be null.&quot;</span>);</span><br><span class="line">    Objects.requireNonNull(camelContext, <span class="string">&quot;The camelContext property must not be null.&quot;</span>);</span><br><span class="line">    Objects.requireNonNull(sequenceIdHeaderName, <span class="string">&quot;The sequenceIdHeaderName property must not be null.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Exchange <span class="title">aggregate</span><span class="params">(Exchange oldExchange, Exchange newExchange)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Exchange aggregateExchange = initializeAggregateExchange(oldExchange, newExchange);</span><br><span class="line">    log.info(String.format(<span class="string">&quot;Pending messages: [%s] messages&quot;</span>, aggregateExchange.getIn().getBody(SortedSet.class).size()));</span><br><span class="line"></span><br><span class="line">    appendMessage(aggregateExchange, newExchange.getIn());</span><br><span class="line"></span><br><span class="line">    findAndEmitSequencedMessages(aggregateExchange);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> aggregateExchange;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> Exchange <span class="title">initializeAggregateExchange</span><span class="params">(Exchange oldExchange, Exchange newExchange)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Exchange aggregateExchange;</span><br><span class="line">    <span class="keyword">if</span> (oldExchange == <span class="keyword">null</span>) &#123;</span><br><span class="line">      aggregateExchange = ExchangeHelper.copyExchangeAndSetCamelContext(newExchange, camelContext);</span><br><span class="line">      SortedSet&lt;Message&gt; pendingMessages = <span class="keyword">new</span> TreeSet&lt;&gt;(_messageComparator());</span><br><span class="line">      aggregateExchange.getIn().setBody(pendingMessages);</span><br><span class="line">      aggregateExchange.setProperty(LAST_PROCESSED_INDEX, -<span class="number">1L</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      aggregateExchange = oldExchange;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> aggregateExchange;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">appendMessage</span><span class="params">(Exchange aggregateExchange, Message message)</span> </span>&#123;</span><br><span class="line">    log.info(String.format(<span class="string">&quot;Adding message: index [%s], body [%s]&quot;</span>, message.getHeader(sequenceIdHeaderName), message.getBody()));</span><br><span class="line">    aggregateExchange.getIn().getBody(SortedSet.class).add(message);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">findAndEmitSequencedMessages</span><span class="params">(Exchange aggregateExchange)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    SortedSet&lt;Message&gt; pendingMessages = aggregateExchange.getIn().getBody(SortedSet.class);</span><br><span class="line">    Long lastProcessedIndex = aggregateExchange.getProperty(LAST_PROCESSED_INDEX, Long.class);</span><br><span class="line"></span><br><span class="line">    Message currentMessage;</span><br><span class="line">    Long currentMessageIndex;</span><br><span class="line">    SortedSet&lt;Message&gt; messagesToBeEmitted = <span class="keyword">new</span> TreeSet&lt;&gt;(_messageComparator());</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      currentMessage = pendingMessages.first();</span><br><span class="line">      currentMessageIndex = currentMessage.getHeader(sequenceIdHeaderName, Long.class);</span><br><span class="line">      <span class="keyword">if</span> (currentMessageIndex == lastProcessedIndex + <span class="number">1</span>) &#123;</span><br><span class="line">        messagesToBeEmitted.add(currentMessage);</span><br><span class="line">        pendingMessages.remove(currentMessage);</span><br><span class="line">        lastProcessedIndex = currentMessageIndex;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (!pendingMessages.isEmpty());</span><br><span class="line">    <span class="keyword">if</span> (!messagesToBeEmitted.isEmpty()) &#123;</span><br><span class="line">      log.info(String.format(<span class="string">&quot;Messages to be emitted: [%s] messages&quot;</span>, messagesToBeEmitted.size()));</span><br><span class="line">      aggregateExchange.setProperty(LAST_PROCESSED_INDEX, lastProcessedIndex);</span><br><span class="line">      aggregateExchange.getIn().setBody(pendingMessages);</span><br><span class="line">      Exchange exchangeToBeEmitted = ExchangeHelper.copyExchangeAndSetCamelContext(aggregateExchange, camelContext);</span><br><span class="line">      exchangeToBeEmitted.getIn().setBody(messagesToBeEmitted);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (Processor processor : _aggregateProcessor().next()) &#123;</span><br><span class="line">          processor.process(exchangeToBeEmitted);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeCamelException(e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Here‚Äôs a link to the full source for your perusal: [<a href="https://github.com/joshdreagan/camel-streaming-aggregation">https://github.com/joshdreagan/camel-streaming-aggregation</a>]. In this implementation, I was asked to do ordering aggregation of incoming messages. But as the messages came in, if the next sequential block was completed, the customer wanted those messages to be emitted at that time instead of waiting for the entire batch to complete. So, for example, if I got messages [1,3,5], those messages would be aggregated and stored in the aggregation repository. But then, when message [2] came in, messages [1,2,3] would be emitted/processed (while message [5] would remain in the repository). Finally, when message [4] came in, messages [4,5] would be emitted/processed. That‚Äôs about as custom as they come!</p><p>Hopefully this helps highlight some of the power and flexibility of Camel. Like I said at the beginning of this post, your imagination is the limit (or rather your use case). Enjoy!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;One of the many (many many many) extension points inside &lt;a href=&quot;http://camel.apache.org/&quot;&gt;Apache Camel&lt;/a&gt; is the &lt;code&gt;org.apache.camel.processor.aggregate.AggregationStrategy&lt;/code&gt;. These are used in everything from &lt;a href=&quot;http://camel.apache.org/content-enricher.html&quot;&gt;Content Enrichers&lt;/a&gt; to &lt;a href=&quot;http://camel.apache.org/splitter.html&quot;&gt;Splitters&lt;/a&gt; to &lt;a href=&quot;http://camel.apache.org/aggregator2.html&quot;&gt;Aggregators&lt;/a&gt; and more. Since their use is so prevalent, I figured that I‚Äôd dedicate a whole blog post just for them. So here goes‚Ä¶</summary>
    
    
    
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
  </entry>
  
  <entry>
    <title>Camel CXFRS Contract First</title>
    <link href="https://blog.joshdreagan.com/2018/03/02/camel_cxfrs_contract_first/"/>
    <id>https://blog.joshdreagan.com/2018/03/02/camel_cxfrs_contract_first/</id>
    <published>2018-03-02T07:00:51.000Z</published>
    <updated>2021-01-14T22:53:28.848Z</updated>
    
    <content type="html"><![CDATA[<p>I‚Äôve recently had a rash of customers who want to do contract driven REST development. That is, they want to define the contract for their service up front, and then generate their interfaces and models. And like all subjects, if I get asked about it enough times, I‚Äôll write it down in a blog. So here goes‚Ä¶<a id="more"></a></p><p>First, why would someone want to generate code from their contract? Well‚Ä¶ we certainly don‚Äôt want to have to keep code and contract in sync manually. That would be extremely error prone (and would repeat the same mistakes we made in the early days of SOAP/WSDL). So that leaves two options: Either we generate the contract from the code (ie, code-first), or we generate the code from the contract (ie, contract-first). If we choose to go the code-first route, what we usually do is add some annotations (or add additional metadata via some language/library specific means), deploy the code to a running server, and then pull the contract by hitting (HTTP GET‚Äôing) a special url. This seems all fine and good since it gives us a contract that is exposed for clients to consume. What more do we need right? As it turns out though, many organizations don‚Äôt do development this way. In fact, many of them will want to develop their contract well before implementation takes place. Often times, that contract is even developed by a separate team. So in these cases, we need to go contract-first. Which means that we have to figure out a way to generate the code‚Ä¶</p><p>Now that we‚Äôre through all of that ‚Äúintro‚Äù business, let‚Äôs talk about how one might actually accomplish this. There are many competing specs for defining REST contracts (ie, WADL, RAML, API Blueprint, ‚Ä¶), but the most popular (and the one I‚Äôll be targeting for this post) seems to be Swagger/OpenAPI. If you check out <a href="https://swagger.io/swagger-codegen/">Swagger‚Äôs website</a>, you‚Äôll see that they‚Äôve implemented some tooling to do this code generation. What‚Äôs more, the tooling is actually pretty pluggable and can be used to generate implementation/model files for <a href="https://generator.swagger.io/api/gen/servers">many different languages</a>. It doesn‚Äôt have the best documentation, and can be a bit buggy at times. But luckily it‚Äôs open source. So we can just read through <a href="https://github.com/swagger-api/swagger-codegen">the code</a> to figure out how it works. And after all, code is really the best documentation‚Ä¶ ;) Here‚Äôs a snippet of what the plugin configuration might look like:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.swagger<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>swagger-codegen-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;swagger-codegen-maven-plugin.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">id</span>&gt;</span>generate-sources<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>generate<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">inputSpec</span>&gt;</span>src/main/swagger/api.json<span class="tag">&lt;/<span class="name">inputSpec</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">language</span>&gt;</span>jaxrs-cxf<span class="tag">&lt;/<span class="name">language</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">generateSupportingFiles</span>&gt;</span>false<span class="tag">&lt;/<span class="name">generateSupportingFiles</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">modelPackage</span>&gt;</span>org.apache.camel.examples.model<span class="tag">&lt;/<span class="name">modelPackage</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">apiPackage</span>&gt;</span>org.apache.camel.examples.api<span class="tag">&lt;/<span class="name">apiPackage</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">output</span>&gt;</span>$&#123;project.build.directory&#125;/generated-sources<span class="tag">&lt;/<span class="name">output</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">generateApiTests</span>&gt;</span>false<span class="tag">&lt;/<span class="name">generateApiTests</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">configOptions</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">sourceFolder</span>&gt;</span>swagger<span class="tag">&lt;/<span class="name">sourceFolder</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">implFolder</span>&gt;</span>swagger<span class="tag">&lt;/<span class="name">implFolder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">configOptions</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Once we have the plugin properly configured, it will bind to the <code>generate-sources</code> lifecycle phase of our Maven build. Which means that the code it outputs will be on our classpath, and all we need to do is create our implementation. Here‚Äôs a snippet of how you might do just that using <a href="http://camel.apache.org/">Apache Camel</a> (the most awesome framework available!):</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from(<span class="string">&quot;cxfrs:/camel?resourceClasses=org.apache.camel.examples.api.MyServiceApi&quot;</span>)</span><br><span class="line">  .routingSlip(simple(<span class="string">&quot;direct:$&#123;headers[operationName]&#125;&quot;</span>))</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">from(<span class="string">&quot;direct:myServiceOperation&quot;</span>)</span><br><span class="line">  .log(<span class="string">&quot;This is where you should fill in your method implementations...&quot;</span>)</span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>If you want to see what a full project looks like, I‚Äôve created an example that uses the above tooling to generate the JAXRS/CXF annotated Java interfaces/model files from a real API JSON file that I downloaded from Swagger‚Äôs website. It then uses those generated files to create an implementation in Camel, and runs it on a <a href="https://projects.spring.io/spring-boot/">Spring Boot</a> container. Give it a look here: <a href="https://github.com/joshdreagan/camel-swagger-contract-first">https://github.com/joshdreagan/camel-swagger-contract-first</a>.</p><p>So now that we know how to do contract-first REST development (and even have an example), we can just copy/paste any time we want to start a new project. But can we do better? I think so‚Ä¶ As it turns out, Maven has a baked-in mechanism for creating templates to generate new projects. They‚Äôre called Maven Archetypes. Usually, you just create an archetype project as defined by <a href="https://maven.apache.org/archetype/maven-archetype-plugin/">the docs</a>. The archetype project contains a fairly simple descriptor XML, and a bunch of <a href="http://velocity.apache.org/">Velocity</a> templates for each of the files you want to be included in your generated project. This allows you to do simple property expansion (ie, <code>groupId</code>, <code>artifactId</code>, <code>package</code>, ‚Ä¶), conditionals, and even some looping inside of your template files. Once you build/install the archetype, you can crank out new projects by simply executing a command like this:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ mvn archetype:generate -DarchetypeCatalog&#x3D;local \</span><br><span class="line">                         -DarchetypeGroupId&#x3D;org.apache.camel.archetypes \</span><br><span class="line">                         -DarchetypeArtifactId&#x3D;my-custom-archetype \</span><br><span class="line">                         -DarchetypeVersion&#x3D;1.0.0-SNAPSHOT \</span><br><span class="line">                         -DgroupId&#x3D;com.mycompany \</span><br><span class="line">                         -DartifactId&#x3D;myproject \</span><br><span class="line">                         -Dversion&#x3D;1.0.0-SNAPSHOT</span><br></pre></td></tr></table></figure><p>However, if you looked at the example project I gave you above, you‚Äôd notice that some of the files need values that are parsed from the Swagger API doc. So Velocity templates alone won‚Äôt cut it‚Ä¶ We could just leave those values blank (or put in some sort of placeholder), and then have the user fill them in after the project generation. But once again, we can do better‚Ä¶ There is a little known (and horribly under-documented) feature that we can take advantage of to automate things. If you look under the <a href="https://maven.apache.org/archetype/maven-archetype-plugin/advanced-usage.html">‚ÄúAdvanced Usage‚Äù</a> section of the archetype plugin docs, you will see a reference to a ‚ÄúPost-generation script‚Äù (toward the bottom of the page). Basically, you can just include a <a href="http://groovy-lang.org/">Groovy</a> script named <code>archetype-post-generate.groovy</code> inside the <code>src/main/resources/META-INF/</code> folder, and its contents will be executed during project generation (after the Velocity templates have been applied, and the files copied into their destinations). And because Groovy is super awesome and incredibly powerful, we can use it do pretty much anything we want. For instance, parsing up a JSON file and using its values to replace extra placeholders in our project files‚Ä¶ Neat! Here‚Äôs an example archetype project to get you started: <a href="https://github.com/joshdreagan/camel-archetype-spring-boot-cxfrs-contract-first">https://github.com/joshdreagan/camel-archetype-spring-boot-cxfrs-contract-first</a>. Enjoy!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;I‚Äôve recently had a rash of customers who want to do contract driven REST development. That is, they want to define the contract for their service up front, and then generate their interfaces and models. And like all subjects, if I get asked about it enough times, I‚Äôll write it down in a blog. So here goes‚Ä¶</summary>
    
    
    
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="cxf" scheme="https://blog.joshdreagan.com/tags/cxf/"/>
    
  </entry>
  
  <entry>
    <title>Upgrading AMQ 6 to AMQ 7</title>
    <link href="https://blog.joshdreagan.com/2017/12/01/upgrading_amq_6_to_amq_7/"/>
    <id>https://blog.joshdreagan.com/2017/12/01/upgrading_amq_6_to_amq_7/</id>
    <published>2017-12-01T22:30:03.000Z</published>
    <updated>2021-01-14T22:53:29.036Z</updated>
    
    <content type="html"><![CDATA[<p>So <a href="https://developers.redhat.com/products/amq/overview/">Red Hat AMQ 7</a> has been out for a while now, and there have already been a lot of customers who are understandably eager to upgrade to the latest and greatest version. Many of them have been reaching out and asking for help/instructions on how to migrate. So far I‚Äôve been replying that I already blogged about that here: <a href="/2016/08/22/decommissioning_jboss_a-mq_brokers/" title="Decommissioning JBoss A-MQ brokers">Decommissioning JBoss A-MQ brokers</a>. But that reply has been met with some confusion. So I figured I‚Äôd write up a more concrete set of instructions.<a id="more"></a></p><p>Let‚Äôs start by stating the problem: ‚ÄúI have a current, production system that is utilizing AMQ 6 and I‚Äôd like to upgrade it to AMQ 7 with as little downtime as possible‚Äù. Well‚Ä¶ such things do require a bit of planning, but it‚Äôs not as difficult as it might seem. The easiest way to upgrade any app is <em>usually</em> to do a rolling upgrade. I emphasize ‚Äú<em>usually</em>‚Äú because every customer has a slightly different case, architecture, requirements, or other wrenches that can make things more difficult. But for the purpose of this blog, let‚Äôs focus on the most typical case.</p><p>For the first step, let‚Äôs walk through upgrading the brokers. First, we‚Äôll need to install AMQ 7 and create a broker instance. No need to enumerate the steps here since that‚Äôs already been covered in the docs: [<a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_amq/7.0/html/using_amq_broker/">https://access.redhat.com/documentation/en-us/red_hat_jboss_amq/7.0/html/using_amq_broker/</a>]. For the purpose of this post, we‚Äôll assume that you plan to match your existing setup (ie, if you currently have a master/slave pair, you will install a new AMQ 7 master/slave pair). If you‚Äôre installing to new hardware, you can go ahead and start the newly created broker instance(s). Otherwise, we‚Äôll have to shut down the existing AMQ 6 broker before starting the AMQ 7 broker. Yes‚Ä¶ you could modify the ports and bring it up alongside your AMQ 6 broker, but you risk causing a contention for resources if you do so. So best not to tempt fate‚Ä¶</p><p>Next, let‚Äôs talk about the clients. One of the awesome features in AMQ 7 is that is supports all of the same protocols that AMQ 6 did (in addition to a couple more). This means that your existing clients (with their existing client libraries) can seamlessly connect to the new AMQ 7 brokers. All you‚Äôll need to do is give the clients the new broker URL and they can immediately begin producing/consuming. And you don‚Äôt even need to do that if you installed to the same hardware and bound to the same port. In fact, if your clients are using the ‚Äúfailover‚Äù protocol (and you didn‚Äôt update the host/port), they will automatically switch over as soon as you take down the AMQ 6 broker and bring the AMQ 7 broker online. Neat! <img style="display: inline; height: 15px;" src="/2017/12/01/upgrading_amq_6_to_amq_7/banana_dance.gif"/> It‚Äôs worth noting that this will not be the case forever. Eventually, the OpenWire format (and potentially other formats) will be deprecated and removed from support. But that is a long ways away. So you‚Äôll have plenty of time to go back through and update all of your client applications with the newer client libraries as time/budget permits.</p><p>But what about those in-flight messages? The messages that had been accepted by the old AMQ 6 instance, but had not yet been delivered to a consumer client. Well, that is exactly what I wrote <a href="/2016/08/22/decommissioning_jboss_a-mq_brokers/" title="my previous blog post">my previous blog post</a> about. Those messages cannot be lost. So we need to ‚Äúdrain‚Äù them from the old AMQ 6 KahaDB store and send them to the new AMQ 7 broker. Luckily, due to the fact that the AMQ 7 broker can still speak OpenWire, you can use the exact same drainer code that I provided in that blog: [<a href="https://github.com/joshdreagan/activemq-drainer">https://github.com/joshdreagan/activemq-drainer</a>]. Super neat! <img style="display: inline; height: 15px;" src="/2017/12/01/upgrading_amq_6_to_amq_7/carlton_dance.gif"/></p><p>That‚Äôs it! Rinse and repeat for each broker instance/pair. You can do it all at once, or in a ‚Äúrolling‚Äù fashion. Up to you‚Ä¶</p><p>So to summarize, here are the high-level steps that you will perform:</p><ul><li>Install the new AMQ 7 broker/instance.</li><li>Stop the AMQ 6 broker.</li><li>Start the AMQ 7 broker.</li><li>Update your clients with the new broker URL (only necessary if you installed to new hardware or otherwise changed the host/port).</li><li>Drain the messages from the AMQ 6 KahaDB to the new AMQ 7 broker.</li><li>Eventually plan on upgrading your client libraries.</li><li>Optionally delete the old AMQ 6 installation once you‚Äôre satisfied that the upgrade has completed successfully.</li></ul><p>Did I cover every possible use case, permutation, and complication? No‚Ä¶ But this should be a good starting point. And if you need more guidance, well‚Ä¶ that‚Äôs what we have <a href="https://www.redhat.com/en/services/consulting">Red Hat Consulting</a> for.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;So &lt;a href=&quot;https://developers.redhat.com/products/amq/overview/&quot;&gt;Red Hat AMQ 7&lt;/a&gt; has been out for a while now, and there have already been a lot of customers who are understandably eager to upgrade to the latest and greatest version. Many of them have been reaching out and asking for help/instructions on how to migrate. So far I‚Äôve been replying that I already blogged about that here: &lt;a href=&quot;/2016/08/22/decommissioning_jboss_a-mq_brokers/&quot; title=&quot;Decommissioning JBoss A-MQ brokers&quot;&gt;Decommissioning JBoss A-MQ brokers&lt;/a&gt;. But that reply has been met with some confusion. So I figured I‚Äôd write up a more concrete set of instructions.</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="artemis" scheme="https://blog.joshdreagan.com/tags/artemis/"/>
    
  </entry>
  
  <entry>
    <title>Bridging Apache Artemis</title>
    <link href="https://blog.joshdreagan.com/2017/08/16/bridging_apache_artemis/"/>
    <id>https://blog.joshdreagan.com/2017/08/16/bridging_apache_artemis/</id>
    <published>2017-08-16T20:18:37.000Z</published>
    <updated>2021-01-14T22:53:28.807Z</updated>
    
    <content type="html"><![CDATA[<p>In a perfect world, every project would be a greenfield project and you could pick and choose the latest/greatest broker every time. And of course, if given the choice you‚Äôd pick <a href="https://activemq.apache.org/artemis/">Apache Artemis</a>‚Ä¶ ;) But in the real world, it is much more common that customers will have a very large existing codebase and will have to transition to the latest/greatest over some much longer period of time. And during that period, it‚Äôs helpful to be able to set up some sort of bridge between your brokers so that your old and new code can still communicate.<a id="more"></a></p><p>Before we get started though, there are a few things to clear up‚Ä¶ The term ‚Äúbridge‚Äù can mean may things. Artemis has something called a ‚Äú<a href="https://activemq.apache.org/artemis/docs/latest/core-bridges.html">Core Bridge</a>‚Äú. Core bridges do <strong>not</strong> use the JMS API, and are used only for bridging Artemis instances together (either explicitly, or implicitly when using cluster connections). While useful, Core bridges are not the focus of this post. Instead, we‚Äôre going to talk about how you might bridge Artemis to another JMS broker (ie, <a href="https://www.ibm.com/software/products/en/ibm-mq">IBM MQ</a>).</p><p>There is a baked in JMS bridge implementation in the Artemis codebase that you can use if you‚Äôd like. You can check out the docs on it here: [<a href="https://activemq.apache.org/artemis/docs/latest/jms-bridge.html">https://activemq.apache.org/artemis/docs/latest/jms-bridge.html</a>]. It‚Äôs pretty basic, but functional if you don‚Äôt require any kind of transformations or other flexibility. To use it, simply instantiate an instance of <code>org.apache.activemq.artemis.jms.bridge.JMSBridge</code>, and pass it the required arguments (ie, source/destination <code>org.apache.activemq.artemis.jms.bridge.ConnectionFactoryFactory</code> instances, source/destination <code>org.apache.activemq.artemis.jms.bridge.DestinationFactory</code> instances, source/destination credentials, ‚Ä¶). Once you have your instance, you can call <code>start()</code> on it to begin consuming/producing messages. There‚Äôs even an example included in the distribution: [<a href="https://github.com/apache/activemq-artemis/tree/master/examples/features/standard/jms-bridge">jms-bridge</a>]. Seems pretty straightforward right? Well‚Ä¶ maybe not. If you‚Äôre running Artemis standalone (like most people), you don‚Äôt really have a good way to load extra code. That is, there‚Äôs no ‚Äúhot deploy‚Äù folder where you can just drop a jar file with this config in it and have it automatically startup and shutdown with the broker. There has been some effort to create a plugin framework in the newer versions, but a quick look at the code showed that it still doesn‚Äôt provide hooks into start/stop or other broker lifecycle events. So what do we do?</p><p>As it turns out, there is an embedded <a href="http://www.eclipse.org/jetty/">Jetty</a> instance that serves the web admin console. And it already starts/stops with the server. So we can just piggyback on that to bootstrap our code. But if I‚Äôm going through all of this effort to bootstrap some code, I might as well use something with a bit more power (ie, <a href="http://camel.apache.org/">Apache Camel</a>). That way, if I have any need to perform message transformations, set unique headers for idempotent consumption, wiretap audit logs, or do anything else outside of simply copying messages, I can do so. Sounds simple enough, but how do I actually do it?</p><p>First, you‚Äôll need to create a WAR containing all of your dependencies as well as your Spring XML defined Camel routes. We‚Äôll refer to this as <code>jms-bridge.war</code>‚Ä¶ In the Camel routes, you‚Äôll place your actual JMS bridge definitions (as many as you need). In the <code>WEB-INF/web.xml</code>, you‚Äôll boostrap the Spring ApplicationContext using the <code>org.springframework.web.context.ContextLoaderListener</code> class. This is a pretty standard way to bootstrap a Spring application into a servlet container.</p><p>Second, you‚Äôll copy <code>jms-bridge.war</code> file into the <code>$ARTEMIS_HOME/web</code> folder.</p><p>Finally, you‚Äôll add a definition to the <code>$ARTEMIS_INSTANCE/etc/bootstrap.xml</code> file as shown below:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">broker</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://activemq.org/schema&quot;</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="tag">&lt;<span class="name">web</span> <span class="attr">bind</span>=<span class="string">&quot;http://localhost:8161&quot;</span> <span class="attr">path</span>=<span class="string">&quot;web&quot;</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="tag">&lt;<span class="name">app</span> <span class="attr">url</span>=<span class="string">&quot;jms-bridge&quot;</span> <span class="attr">war</span>=<span class="string">&quot;jms-bridge.war&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">web</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">broker</span>&gt;</span></span><br></pre></td></tr></table></figure><p><em>Notice the use of <code>$ARTEMIS_HOME</code> and <code>$ARTEMIS_INSTANCE</code> in the second and third steps‚Ä¶ <code>$ARTEMIS_HOME</code> refers to the location that you unzipped the Artemis distribution. <code>$ARTEMIS_INSTANCE</code> refers to the directory of your broker instance (created with the ‚Äú<code>artemis create ...</code>‚Äú command.</em></p><p>Now when you start the broker instance, it will load up and start the Camel routes and begin bridging. Pretty cool! But we bundled up all of our dependencies inside our WAR file (ie, all of the IBM MQ JMS client libs). And we also bundled our Camel routes definition inside the WAR as well. And since the WAR file sits in the <code>$ARTEMIS_HOME/web</code> directory, its configurations apply to any and all of the instances that we create/run on that machine. Not to mention the fact that every change to my Camel routes will require a build/deploy/restart. All of this kind of sucks and we can do better‚Ä¶</p><p>If you dig into the code a bit more, you‚Äôll see that the ‚Äúmain‚Äù that spins up the Artemis broker will actually add several directories, JARs, &amp; ZIPs to the classpath. Specifically, it will add the <code>$ARTEMIS_HOME/etc</code> &amp; <code>$ARTEMIS_INSTANCE/etc</code> directories. It will then scan through the <code>$ARTEMIS_HOME/lib</code> &amp; <code>$ARTEMIS_INSTANCE/lib</code> directories, and add any JARs or ZIPs that it finds to the classpath (sorted by name). So that means that we can take all of our use-case specific stuff (ie, all of the IBM MQ JMS client libs) and put them in the <code>$ARTEMIS_INSTANCE/lib</code> folder. It also means that we can take the Camel routes configuration, and put it in the <code>$ARTEMIS_INSTANCE/etc</code> directory. Now we have a completely generic WAR that we deploy in the <code>$ARTEMIS_HOME/lib</code> directory. That WAR can be activated on an instance defined basis as needed. And each instance can have the dependencies and configuration that it requires completely independent of other instances. Additionally, I have the added benefit of being able to edit the Camel routes configuration and apply my changes with only a restart (ie, no re-build/re-deploy required). Neat! Want to see what it looks like? Take a look at this sample project: [<a href="https://github.com/joshdreagan/artemis-jms-bridge">https://github.com/joshdreagan/artemis-jms-bridge</a>].</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;In a perfect world, every project would be a greenfield project and you could pick and choose the latest/greatest broker every time. And of course, if given the choice you‚Äôd pick &lt;a href=&quot;https://activemq.apache.org/artemis/&quot;&gt;Apache Artemis&lt;/a&gt;‚Ä¶ ;) But in the real world, it is much more common that customers will have a very large existing codebase and will have to transition to the latest/greatest over some much longer period of time. And during that period, it‚Äôs helpful to be able to set up some sort of bridge between your brokers so that your old and new code can still communicate.</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="artemis" scheme="https://blog.joshdreagan.com/tags/artemis/"/>
    
  </entry>
  
  <entry>
    <title>Transactions and Alternatives With Camel</title>
    <link href="https://blog.joshdreagan.com/2017/08/14/transactions_and_alternatives_with_camel/"/>
    <id>https://blog.joshdreagan.com/2017/08/14/transactions_and_alternatives_with_camel/</id>
    <published>2017-08-14T15:54:38.000Z</published>
    <updated>2021-01-14T22:53:29.034Z</updated>
    
    <content type="html"><![CDATA[<p>There are loads of use cases which require ‚Äúall or nothing‚Äù processing. And there are a bunch of different strategies for accomplishing said result. Luckily for me, they‚Äôve already been covered many times in tons of different blogs/books/articles. So for this post I‚Äôm just going to concentrate on a few of the strategies, and more specifically, how to do them with <a href="http://camel.apache.org/">Apache Camel</a>.<a id="more"></a></p><h2 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h2><p>The first (and most obvious) solution that I‚Äôd like to cover, is transactions. Usually, when people need to do a bunch of tasks in an atomic fashion, they simply use a transaction. This can be either a local transaction, or an XA one. Basically, you get to pawn off all of the complication onto a transaction manager and keep your application code clean. So it‚Äôs a great option if you‚Äôre using resources that can be transacted (ie, a relational database, or a JMS broker).</p><p>If you‚Äôre only using a single resource, you can do a local transaction. Which is a nice balance of simplicity and speed. For instance, consuming from a queue, enriching with some extra data, and then producing to another queue on the same broker. The only thing you have to be cautious of is that you maintain a single thread throughout your processing. This really only gets tricky if you do something like a <a href="https://camel.apache.org/components/latest/eips/split-eip.html">Splitter EIP</a> and turn on the <code>parallelProcessing</code> option. If you need an example of configuring a local transaction, you can just take a look at the docs [<a href="https://camel.apache.org/components/latest/eips/transactional-client.html">https://camel.apache.org/components/latest/eips/transactional-client.html</a>].</p><p>However, if you are using multiple resources, you will need to use an XA transaction. For instance, consuming from a queue, and inserting into a database. XA transaction managers are usually provided and configured by your container. If you‚Äôre using <a href="https://developers.redhat.com/products/fuse/overview/">Red Hat JBoss Fuse on Karaf</a>, you‚Äôll likely use <a href="http://aries.apache.org/">Aries</a>. If you‚Äôre on <a href="https://developers.redhat.com/products/eap/overview/">Red Hat JBoss EAP</a>, you‚Äôll use <a href="http://narayana.io/">Narayana</a> (formerly JBoss TM). <a href="https://projects.spring.io/spring-boot/">Spring Boot</a> provides no transaction manager out-of-the-box. Instead, it has hooks to auto-configure various TM‚Äôs based on which one you‚Äôve added as a dependency. In case you‚Äôre curious and would like an example of Camel + XA + Spring Boot, take a look here [<a href="https://github.com/joshdreagan/camel-spring-boot-xa">https://github.com/joshdreagan/camel-spring-boot-xa</a>].</p><p>Using an XA transaction manager does increase complexity a bit (at least from a configuration perspective), and comes with a handful of requirements and caveats:</p><p>The first requirement, is that you will (obviously) need to run and configure some sort of XA capable transaction manager. There are several options available (as outlined above). And because they all implement JTA, you can swap them out with no changes to your code. So you can shop around and find the one that works best.</p><p>Second, due to the requirement of a 2-phase commit, it will be significantly slower. This is usually a huge sticking point for a lot of people as they don‚Äôt want to (or can‚Äôt afford to) pay that performance penalty. Unfortunately, there is little that can be done about it. Or more accurately, I have never seen an XA transaction manager implementation that maintains the speed and simplicity of a non-XA one.</p><p>The third, and often overlooked, requirement is that you will need some sort of persistence. This is because, in the case of a crash, the recovery manager will attempt to pick up where things left off. And in order to survive a crash, we need persistence‚Ä¶</p><p>It‚Äôs worth noting that this third requirement (persistence) makes HA a bit of a pain. As mentioned above, transaction managers will run some sort of recovery thread in the background so that they can (as the name would suggest) recover transactions that were not yet complete at the time of a crash. But they all (or at least all of the implementations I know of) can only have a single instance of the tx and recovery manager per object store (or more specifically, per tx manager id). So that means that, if I wanted to scale out my application (to make up for the added slowness of XA), each server would likely have its own persistent store. Most people don‚Äôt even notice when they‚Äôre using a server like <a href="http://wildfly.org/">JBoss WildFly</a> because each instance will (by default) write its logs to a subfolder of its installation. This can be (in my opinion) <strong>very</strong> dangerous because most people are unaware that that directory should be sitting on some sort of resilient storage. If, however, you‚Äôre running on a platform like <a href="https://www.openshift.com/">OpenShift</a>, you will be immediately aware because all instances will share the same storage mount and configuration, and will simply fail to work properly. You <em>could</em> use subfolders for each pod instance, and then create a separate recovery pod that would run independent of your application and would spin up recovery managers for each downed instance. In fact, I actually had an implementation working at one point. But it was quite clunky, and after a quick conversation with Hiram Chirino at one of our meetups, I concluded that he was working on a <strong>way</strong> more elegant solution using <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">Stateful Sets</a>. So for now, if you want to run XA transactions on OpenShift, I would either limit my app to a single instance (ie, no scaling), or wait a bit for Hiram‚Äôs version.</p><h2 id="Idempotent-Consumer"><a href="#Idempotent-Consumer" class="headerlink" title="Idempotent Consumer"></a>Idempotent Consumer</h2><p>So what if I can‚Äôt (or don‚Äôt want to) use XA transactions? Perhaps I value speed over application simplicity‚Ä¶ Perhaps I‚Äôm not dealing with ‚Äútransactable‚Äù resources‚Ä¶ Perhaps I‚Äôm running on OpenShift and can‚Äôt wait on Hiram‚Ä¶ ;) No matter what the reason, it‚Äôd be nice to have some other options. Luckily, as mentioned at the beginning of the post, there are oodles of options. So lets talk about one of the more popular ones‚Ä¶ idempotent consumer.</p><p>With the <a href="http://www.enterpriseintegrationpatterns.com/patterns/messaging/IdempotentReceiver.html">Idempotent Consumer EIP</a>, you give up on trying to do things atomically, and instead favor eventual consistency. In other words, I write my application in such a way that retries will not hurt anything. So if I have a failure, I can just keep retrying until I eventually succeed all the way through.</p><p>To give a concrete example‚Ä¶ Let‚Äôs say that I wanted to read a file from an input directory, unmarshal/validate the contents, insert it as a record into a DB, and also write it out to a file in an output directory (perhaps in parallel). In this example, only the DB write can participate in a transaction. Both the consumption of and the production of files cannot. So local (or even XA) transactions are not an option. But if I put a simple check before writing the DB and also before writing the file, I can retry as many time as I‚Äôd like with no negative side-effects. To be very specific, if I was successful in writing to the DB, but failed on writing the file (maybe because the filesystem was temporarily full), I can just re-ingest the same file. The DB check will ensure that I don‚Äôt try that step again. So I‚Äôll basically skip it and then try the file write again. Hopefully this time it succeeds‚Ä¶</p><p>There are a couple of ways that I can go about implementing this with Camel. One way would be to guard each step using the <a href="https://camel.apache.org/components/latest/eips/idempotentConsumer-eip.html">Idempotent Consumer EIP</a>. With this EIP, I select a unique id (or rather, an expression to retrieve a unique id) for each message. When that message is received, its unique id will checked against an <code>org.apache.camel.spi.IdempotentRepository</code> (of which there are many implementations to choose from). If it already exists, it will simply be skipped. If not, it will be added and then passed on to the processor. Now, I can ingest/retry my data as many times as I want and be <em>relatively</em> certain that each step will only be performed once. If you want an example of this pattern, take a look here: [<a href="https://github.com/joshdreagan/camel-idempotent-consumer">https://github.com/joshdreagan/camel-idempotent-consumer</a>].</p><p>This pattern works great for most cases. It‚Äôs easy to implement, and maintains pretty good performance. But sometimes it just isn‚Äôt flexible or robust enough. More specifically, what do I do if I don‚Äôt have a unique message id to key off of? Also, what happens if I have a system failure after adding something to the idempotent repository, but before performing my actual processing? Or what if I have an error during my processing, but suffer a system failure before I can remove the message id from my repository? Basically, I have situations where my idempotent repository could be out-of-sync with my actual processing. If I‚Äôm using the JDBC based implementation to guard a DB insert, I could use a local transaction to make sure both of those steps occur atomically. But that doesn‚Äôt really help with my file writing use case. The margin for error is pretty small, and might be acceptable. But what if it‚Äôs not? Luckily for us, Camel usually has more than one way to solve a problem‚Ä¶</p><p>The Idempotent Consumer EIP is really just a specialized version of the <a href="https://camel.apache.org/components/latest/eips/filter-eip.html">Message Filter EIP</a>. The biggest difference, is that its expression will return a boolean dictating whether or not it skips or processes the message. So instead of just matching an id, I can perform any steps I‚Äôd like to determine if a message has already been processed before. Which solves my first issue‚Ä¶ Using my example above, I would guard my DB insert with one filter check, and then my file write with another filter check. The DB filter check could query the DB to see if my message had already been inserted, and then skip processing if it had. My file writer check could similarly check to see if the destination file had already been written, and then skip processing if it had. It‚Äôs a tiny bit more complicated to use, but since I‚Äôm not maintaining a separate idempotent repository, I don‚Äôt have any chance of getting out-of-sync. So that solves my system failure issues‚Ä¶ If you want an example of what this might look like, take a look at this example: [<a href="https://github.com/joshdreagan/camel-filter-consumer">https://github.com/joshdreagan/camel-filter-consumer</a>].</p><p>As I said at the beginning of this post, there are several ways to tackle this issue. Of which, I‚Äôve only covered a few. And in doing so, I used some fairly contrived use cases. But hopefully it‚Äôs still worthwhile, and at a bare minimum maybe someone will find the code examples useful‚Ä¶</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;There are loads of use cases which require ‚Äúall or nothing‚Äù processing. And there are a bunch of different strategies for accomplishing said result. Luckily for me, they‚Äôve already been covered many times in tons of different blogs/books/articles. So for this post I‚Äôm just going to concentrate on a few of the strategies, and more specifically, how to do them with &lt;a href=&quot;http://camel.apache.org/&quot;&gt;Apache Camel&lt;/a&gt;.</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="spring-boot" scheme="https://blog.joshdreagan.com/tags/spring-boot/"/>
    
    <category term="artemis" scheme="https://blog.joshdreagan.com/tags/artemis/"/>
    
    <category term="karaf" scheme="https://blog.joshdreagan.com/tags/karaf/"/>
    
    <category term="openshift" scheme="https://blog.joshdreagan.com/tags/openshift/"/>
    
    <category term="jboss" scheme="https://blog.joshdreagan.com/tags/jboss/"/>
    
    <category term="wildfly" scheme="https://blog.joshdreagan.com/tags/wildfly/"/>
    
    <category term="narayana" scheme="https://blog.joshdreagan.com/tags/narayana/"/>
    
  </entry>
  
  <entry>
    <title>Scaling JBoss A-MQ on OpenShift</title>
    <link href="https://blog.joshdreagan.com/2017/03/25/scaling_jboss_a-mq_on_openshift/"/>
    <id>https://blog.joshdreagan.com/2017/03/25/scaling_jboss_a-mq_on_openshift/</id>
    <published>2017-03-25T22:56:02.000Z</published>
    <updated>2021-01-14T22:53:29.014Z</updated>
    
    <content type="html"><![CDATA[<p>I frequently get asked by customers if it‚Äôs possible to run <a href="https://developers.redhat.com/products/amq/overview/">Red Hat JBoss A-MQ</a> on <a href="https://developers.redhat.com/products/openshift/overview/">Red Hat OpenShift</a>, and while the answer has been ‚Äúyes‚Äù for quite a while now, it has always been followed by a few caveats. In particular, the issue of scaling‚Ä¶<a id="more"></a></p><p>But before we get into the issue of scaling, let‚Äôs talk a little about how the <a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_middleware_for_openshift/3/html-single/red_hat_jboss_a-mq_for_openshift/">official image template</a> works. Basically, it can operate in three different modes (as of this blog date).</p><p>The first, is persistent with no scaling. This is the equivalent of a single master/slave setup. Only, there is no need for an actual ‚Äúslave‚Äù instance. If the master goes down, OpenShift will detect it and will spin up a new instance on the same or another node. And since the new instance/pod will have the same <a href="https://kubernetes.io/docs/user-guide/persistent-volumes/#persistentvolumeclaims">PersistentVolumeClaim</a>, the broker will come online and see all of its in-flight messages exactly as they were. If I were to attempt to scale-up the instance in this mode, I would basically just spin up a bunch of passive ‚Äúslaves‚Äù since they‚Äôll all try to mount the same PersistentVolumeClaim/KahaDB, and will be unable to get the file-lock (and will resort to polling it until they can). And as described above, the slaves serve no real purpose because OpenShift is already monitoring and will bring up a new instance if needed. But what if I want to scale? What if I want to have many active instances sharing the load?</p><p>That brings us to the next mode. Which is non-persistent with scaling. In this mode, all of the instances share the same <a href="https://kubernetes.io/docs/user-guide/services/">Service</a>, but have no <a href="https://kubernetes.io/docs/user-guide/persistent-volumes">PersistentVolume</a> attached. That means that clients (both producers and consumers) can be distributed across all of the instances. And, since each of the instances is networked together, the messages will find their way to a valid consumer. The instances will be automatically network together in a mesh configuration, and discover eachother using the same Kubernetes Service abstraction that the clients can use. So theoretically, I can scale this up as large as I need to handle my client load. But as I stated above, there is no PersistentVolume attached. Which means that my in-flight messages could potentially be lost if the owning broker goes down. So what if I want it all? What if I need the ability to scale-up, but also need persistence?</p><p>In that case, we would use the third mode. Which is persistent with scaling. In this mode, all of the brokers are networked together (using the same Kubernetes Service discovery mechanism as above), but they all also mount the same PersistentVolumeClaim. So how do they have separate KahaDB‚Äôs (and prevent all trying to lock the same one)? It‚Äôs actually quite simple‚Ä¶ In this mode, they will all mount the same volume, but will use subdirectories inside that mount. So within the mount, you will get a bunch of directories called ‚Äúsplit-1‚Äù, ‚Äúsplit-2‚Äù, ‚Ä¶ and so on. If you want to see exactly how this works, you can open up a remote shell to one of the pods (ie, <code>oc rsh &lt;POD_NAME&gt;</code>) and take a look at the A-MQ start script. It just loops through (starting at 1) each of the directories until it finds one that it can get a file-lock on. Once it does, it starts up a broker instance and uses that sub-directory to store its KahaDB. It‚Äôs worth noting here that, since all of the instances will share the same actual PersistentVolume (and it‚Äôs underlying filesystem), you will need to use a distributed filesystem (ie, <a href="https://www.gluster.org/">GlusterFS</a>) with ReadWriteMany access so you don‚Äôt hit a storage performance bottleneck. Now I can run A-MQ on OpenShift and scale-up as much as I want (or as much as I have resources for anyway).</p><p>So what‚Äôs the ‚Äúscaling problem‚Äù I mentioned earlier? Well‚Ä¶ if I want to scale-up, I‚Äôll probably also want to scale-down at some point. And if I scale down, I now have KahaDB‚Äôs sitting in ‚Äúsplit-x‚Äù folders that could potentially have in-flight messages. And those messages likely can‚Äôt wait until I scale back up and happen to get an instance that mounts that particular ‚Äúsplit‚Äù directory. So really, I need to drain those messages out of that stale KahaDB and push them to one of my remaining active brokers. So how might I go about that?</p><p>One solution might be to use a broker plugin that (on shutdown) will automatically drain messages off to other brokers. This could work, but would probably be problematic. First, you would have to make sure that all of your <a href="http://activemq.apache.org/configuring-version-5-transports.html">ActiveMQ TransportConnectors</a> are shutdown before you start draining the messages. If you fail to do this, you could potentially be accepting new messages from clients and might never finish actually draining. The second (and probably more important problem) is that you don‚Äôt have an infinite amount of time to finish your work. When Kubernetes schedules a pod for shutdown, it does give a max time for it to complete its graceful shutdown. But if you exceed this timeout, it will forcefully shut down. So exactly how much time do you need to drain off all of your messages? It depends‚Ä¶ It depends on how many in-flight messages you have stored in that KahaDB. It depends on how fast you can send those messages (maybe they‚Äôre large messages). It depends on how much space you have available on the other brokers (because of <a href="http://activemq.apache.org/producer-flow-control.html">Producer Flow Control</a>). The point is, there is no valid number for ‚Äúshutdown timeout‚Äù. You need as much time as it takes. So what do we do?</p><p>Luckily for you, I‚Äôm sure you‚Äôve already read my previous blog on <a href="/2016/08/22/decommissioning_jboss_a-mq_brokers/" title="Decommissioning JBoss A-MQ brokers">Decommissioning JBoss A-MQ brokers</a>. And in there, you‚Äôve already seen my final proposed solution (and code example) for draining those messages. So really, all we have to do is make that code work on OpenShift. Here‚Äôs a first cut at it [<a href="https://github.com/joshdreagan/activemq-pv-monitor">https://github.com/joshdreagan/activemq-pv-monitor</a>]. In this example, I use the <a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_middleware_for_openshift/3/html-single/red_hat_jboss_fuse_integration_services_2.0_for_openshift/">FIS 2.0</a> tools to create a simple <a href="https://developers.redhat.com/products/fuse/overview/">Red Hat JBoss Fuse</a> app that will monitor the A-MQ ‚Äúsplit-x‚Äù directories. If it finds a KahaDB that it‚Äôs able to get a file-lock on, it will drain its messages to another available broker (which it discovers using the same Kubernetes Service discovery mechanism described above). And since it‚Äôs a separate Pod, it can run for as long as it needs to. So no need to worry about pesky timeouts. The example could use some more error handling and various other QA, but it should be a good starting point.</p><p>So now we can scale-up, we can scale-down, and if we‚Äôre feeling lazy, we can even auto-scale. Cool beans! As always, hopefully you find this useful. And if so, buy me a beer this year at <a href="https://www.redhat.com/en/summit/2017">Red Hat Summit</a>. :)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;I frequently get asked by customers if it‚Äôs possible to run &lt;a href=&quot;https://developers.redhat.com/products/amq/overview/&quot;&gt;Red Hat JBoss A-MQ&lt;/a&gt; on &lt;a href=&quot;https://developers.redhat.com/products/openshift/overview/&quot;&gt;Red Hat OpenShift&lt;/a&gt;, and while the answer has been ‚Äúyes‚Äù for quite a while now, it has always been followed by a few caveats. In particular, the issue of scaling‚Ä¶</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="spring-boot" scheme="https://blog.joshdreagan.com/tags/spring-boot/"/>
    
    <category term="openshift" scheme="https://blog.joshdreagan.com/tags/openshift/"/>
    
  </entry>
  
  <entry>
    <title>ActiveMQ HA Performance Comparison</title>
    <link href="https://blog.joshdreagan.com/2017/03/15/activemq_ha_performance_comparison/"/>
    <id>https://blog.joshdreagan.com/2017/03/15/activemq_ha_performance_comparison/</id>
    <published>2017-03-15T20:07:01.000Z</published>
    <updated>2021-01-14T22:53:28.780Z</updated>
    
    <content type="html"><![CDATA[<p>A while back, I wrote a blog post on <a href="/2016/07/28/ha_deployments_with_fuse/" title="HA Deployments With Fuse">HA Deployments With Fuse</a>. Surprisingly, it received a lot of interest. In particular, the JMS section. Apparently, there are tons of people trying to solve the cross-dc HA problem‚Ä¶ Not surprisingly, everyone claims to have the highest possible failure requirements and asked me what I meant by ‚Äúprepare to make some serious performance tradeoffs‚Äù. So I figured I‚Äôd give some concrete numbers for comparison.<a id="more"></a></p><p><em>Before we get started though, here are some very important disclaimers: First, I did absolutely no tweaking of options or performance tuning. I just unzipped the <a href="https://developers.redhat.com/products/amq">Red Hat JBoss A-MQ</a> distro, uncommented a user, and started it up. For the DRBD tests, I only changed the path where it stores the KahaDB to point to the replicated filesystem mount. Similarly, I just did a standard <a href="http://drbd.org/">DRBD</a> installation by following their getting started docs. I did not tweak or otherwise optimize the synchronization protocols in any way. Second, I used an ‚Äòm4.xlarge‚Äô <a href="https://aws.amazon.com/ec2/instance-types/">EC2 instance type</a> and attached a standard SSD <a href="https://aws.amazon.com/ebs/details/">EBS volume type</a>. So more of a mid-level machine with average (or below) networking and storage performance.</em></p><p><strong>Given the above conditions, you should not take these numbers as a performance metric. You could likely get much greater performance if you tweaked some of the network settings and used more performant machine. These numbers are only meant to serve as a comparison of local storage vs replicated storage.</strong></p><p>Now that I‚Äôve got the ‚Äúdisclaimers‚Äù out of the way, let me run down what I actually did‚Ä¶</p><p>First, I wanted to run a baseline (since this is not about performance numbers directly, but rather comparison). So I created an ‚Äòm4.xlarge‚Äô instance used to host my broker. We‚Äôll call it ‚Äúbroker 1‚Äù. I also created a second ‚Äòm4.xlarge‚Äô instance in the same availability zone and region to host my client (both producer and consumer). We‚Äôll call it ‚Äúclient‚Äù. Next, I installed <a href="https://developers.redhat.com/products/amq">Red Hat JBoss A-MQ 6.3</a> on ‚Äúbroker 1‚Äù. I also created a Maven project for my <a href="http://activemq.apache.org/activemq-performance-module-users-manual.html">ActiveMQ Perf Maven Plugin</a> on ‚Äúclient‚Äù. I then ran a client instance with 5 threads for the producer, and another instance with 5 threads for the consumer. <em>Note: Both clients were run from the same ‚Äúclient‚Äù EC2 machine.</em> I then repeated the test using 25 threads, and again using 50 threads. I tried to go above 50 threads, but the performance started to degrade. Likely due to a network or storage bottleneck for the machine/storage types I chose. All the numbers for these runs can be found in the table below in the ‚ÄúBaseline‚Äù row.</p><p>Once I had my baseline, I spun up another ‚Äòm4.xlarge‚Äô instance in the same region, but on another availability zone. We‚Äôll call this one ‚Äúbroker 2‚Äù I also created and attached an EBS volume (using a standard SSD) to both of my ‚Äúbroker‚Äù instances (‚Äúbroker 1‚Äù and ‚Äúbroker 2‚Äù). I installed DRBD on the instances and configured it to replicate synchronously (using <a href="https://www.linbit.com/drbd-user-guide/users-guide-drbd-8-4/#s-replication-protocols">Protocol C</a>) from ‚Äúbroker 1‚Äù to ‚Äúbroker 2‚Äù. Once I brought them online and the initial sync was done, I ran the same tests as above and captured the numbers. The numbers can be found in the table below in the ‚ÄúDRBD (across availability zones)‚Äù row. As you can see from the results, we do get a performance drop (because we have to write the data twice), but it‚Äôs not too bad since we‚Äôre not having to replicate across a WAN yet.</p><p>Finally, I terminated the ‚Äúbroker 2‚Äù instance and recreated it in another region. So now, the ‚Äúbroker 1‚Äù and ‚Äúclient‚Äù instances were in the ‚ÄúUS West (Oregon)‚Äù region. And the ‚Äúbroker 2‚Äù instance was in the ‚ÄúUS East (N. Virginia)‚Äù region. I reconnected DRBD to replicate from ‚Äúbroker 1‚Äù to ‚Äúbroker 2‚Äù and waited for the initial sync to complete (this took a while). Once that was done, I re-ran the same tests and captured the output again. It can be found in the table below in the ‚ÄúDRBD (across regions)‚Äù row.</p><p>Now we see the ‚Äúperformance tradeoffs‚Äù I was talking about‚Ä¶ In my tests, it was between 1-2 orders of magnitude slower than local storage. So I will repeat my statement from my previous blog‚Ä¶ ‚ÄúYou will not be processing large sets of data while synchronously replicating across a WAN.‚Äù</p><hr/><p><strong>Performance Results</strong></p><table><thead><tr><th></th><th align="right">5 Threads</th><th align="right">25 Threads</th><th align="right">50 Threads</th></tr></thead><tbody><tr><td>Baseline</td><td align="right">2229 tps</td><td align="right">9456 tps</td><td align="right">12524 tps</td></tr><tr><td>DRBD (across availability zones)</td><td align="right">1636 tps</td><td align="right">7068 tps</td><td align="right">9133 tps</td></tr><tr><td>DRBD (across regions)</td><td align="right">26 tps</td><td align="right">129 tps</td><td align="right">256 tps</td></tr></tbody></table><hr/><p>For reference, here are the links to the actual <a href="http://activemq.apache.org/activemq-performance-module-users-manual.html">ActiveMQ Perf Maven Plugin</a> run outputs:</p><p><strong>5 Threads</strong></p><ul><li><a href="/2017/03/15/activemq_ha_performance_comparison/5/baseline/producer.txt" title="Baseline Producer">Baseline Producer</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/5/baseline/consumer.txt" title="Baseline Consumer">Baseline Consumer</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/5/drbd/producer-drbd.txt" title="DRBD Producer (across availability zones)">DRBD Producer (across availability zones)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/5/drbd/consumer-drbd.txt" title="DRBD Consumer (across availability zones)">DRBD Consumer (across availability zones)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/5/drbd/producer-drbd-x-region.txt" title="DRBD Producer (across regions)">DRBD Producer (across regions)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/5/drbd/consumer-drbd-x-region.txt" title="DRBD Consumer (across regions)">DRBD Consumer (across regions)</a></li></ul><p><strong>25 Threads</strong></p><ul><li><a href="/2017/03/15/activemq_ha_performance_comparison/25/baseline/producer.txt" title="Baseline Producer">Baseline Producer</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/25/baseline/consumer.txt" title="Baseline Consumer">Baseline Consumer</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/25/drbd/producer-drbd.txt" title="DRBD Producer (across availability zones)">DRBD Producer (across availability zones)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/25/drbd/consumer-drbd.txt" title="DRBD Consumer (across availability zones)">DRBD Consumer (across availability zones)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/25/drbd/producer-drbd-x-region.txt" title="DRBD Producer (across regions)">DRBD Producer (across regions)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/25/drbd/consumer-drbd-x-region.txt" title="DRBD Consumer (across regions)">DRBD Consumer (across regions)</a></li></ul><p><strong>50 Threads</strong></p><ul><li><a href="/2017/03/15/activemq_ha_performance_comparison/50/baseline/producer.txt" title="Baseline Producer">Baseline Producer</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/50/baseline/consumer.txt" title="Baseline Consumer">Baseline Consumer</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/50/drbd/producer-drbd.txt" title="DRBD Producer (across availability zones)">DRBD Producer (across availability zones)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/50/drbd/consumer-drbd.txt" title="DRBD Consumer (across availability zones)">DRBD Consumer (across availability zones)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/50/drbd/producer-drbd-x-region.txt" title="DRBD Producer (across regions)">DRBD Producer (across regions)</a></li><li><a href="/2017/03/15/activemq_ha_performance_comparison/50/drbd/consumer-drbd-x-region.txt" title="DRBD Consumer (across regions)">DRBD Consumer (across regions)</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;A while back, I wrote a blog post on &lt;a href=&quot;/2016/07/28/ha_deployments_with_fuse/&quot; title=&quot;HA Deployments With Fuse&quot;&gt;HA Deployments With Fuse&lt;/a&gt;. Surprisingly, it received a lot of interest. In particular, the JMS section. Apparently, there are tons of people trying to solve the cross-dc HA problem‚Ä¶ Not surprisingly, everyone claims to have the highest possible failure requirements and asked me what I meant by ‚Äúprepare to make some serious performance tradeoffs‚Äù. So I figured I‚Äôd give some concrete numbers for comparison.</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
  </entry>
  
  <entry>
    <title>Faster File Consumption With Camel</title>
    <link href="https://blog.joshdreagan.com/2017/01/05/faster_file_consumption_with_camel/"/>
    <id>https://blog.joshdreagan.com/2017/01/05/faster_file_consumption_with_camel/</id>
    <published>2017-01-05T20:38:21.000Z</published>
    <updated>2021-01-14T22:53:28.963Z</updated>
    
    <content type="html"><![CDATA[<p>One of the most frequently requested use cases that I encounter out in the field is to ingest file-based data (batch or otherwise), and then validate, transform, process, store‚Ä¶ it. Luckily, <a href="http://camel.apache.org/">Apache Camel‚Äôs</a> <a href="http://camel.apache.org/file2.html">File</a> and <a href="http://camel.apache.org/ftp.html">FTP</a> components make this extremely easy. So much so, that it requires very little thought to get up and running. And if you‚Äôre consuming small numbers of larger batch files, perhaps the defaults are good enough and you don‚Äôt need to put much though into it. If, however, you‚Äôre consuming large numbers of smaller files and you want to get the highest possible performance, there are a few configurations that you might want to consider.<a id="more"></a></p><p>When writing a file poller, one of the most commonly overlooked requirements is that you need some sort of mechanism to determine when the writer is done writing. If you grab a file before it‚Äôs complete, you‚Äôll end up truncating it and ending up with garbage data. Unfortunately, how you would make that determination on one filesystem does not necessarily work on all filesystems. In addition, the different strategies will have different performance characteristics and usually end up being your biggest bottleneck (outside of the actual processing of the data). Luckily, Camel provides you with several strategies out-of-the-box and even allows you to create your own if none of them meet your needs. So how to choose‚Ä¶</p><p>First, let‚Äôs cover the absolute fastest, most generic solution. If you control the process writing the file as well as the process reading the file, you can use a ‚Äútemp file‚Äù strategy. That is, I can have my writer write a file with some sort of temporary name (ie, appending an ‚Äú.inprogress‚Äù extension), and then atomically move it to its final name when the write is complete (ie, remove the ‚Äú.inprogress‚Äù extension). I can then easily have my consumer filter out the temporary files and only consume files that are complete. Camel can do all of this work for you. So no need to panic over writing a bunch of extra code. Simply set the appropriate options on the producer (ie, <code>tempFileName</code>) and the consumer (ie, <code>exclude</code> or <code>antExclude</code>) and call it a day. :)</p><p>Another similar solution is to use the ‚Äúdone file‚Äù strategy. In this strategy, you will write the file, and when it is complete you will write out an additional file with the same name and some ‚Äúmarker‚Äù extension (ie, ‚Äú.done‚Äù). You will then instruct your consumer to only pick up files if it finds their corresponding ‚Äúdone‚Äù file. Again, Camel makes this a simple matter of configuration. Just set the <code>doneFileName</code> option on the producer and the <code>doneFileName</code> option on the consumer. To me, this seems a bit more clunky than the previous solution, but the end result is the same.</p><p>Both of the previous strategies are extremely fast and will work on pretty much any filesystem. However, as previously stated, they require you to have control over the producer and consumer sides. So what if you only control the consumer? Well‚Ä¶ you could use one of the <code>readLock</code> options. Unfortunately, most of the available <code>readLock</code> options are more concerned with making sure no other consumers pick up the same file than they are with making sure the writer is done writing. And since we have <a href="https://github.com/joshdreagan/clustered-file-consumer">other ways to make sure other consumers don‚Äôt step on our toes</a>, we‚Äôll just concentrate on the options that help us with the latter issue.</p><p>The most robust option that‚Äôs available out-of-the-box is the ‚Äúchanged‚Äù strategy. Basically, the way it works is that the consumer will grab a file and check its last-modified timestamp. It will then continue to check the last-modified timestamp (at the configured <code>readLockCheckInterval</code>) until it determines that the file has stopped changing (ie, the previous poll‚Äôs last-modified matches the current one). Once it has determined that the file is no longer changing, it will consume it and pass it to the rest of the route for processing. This strategy is an excellent option because it works pretty much anywhere (ie, local filesystem, FTP, SFTP, ‚Ä¶), and is configurable enough to handle the case of ‚Äúslow writers‚Äù (by tweaking/increasing the <code>readLockCheckInterval</code> option). And if you‚Äôre getting small numbers of larger files, it‚Äôs probably fast enough. But if you‚Äôre trying to consume large numbers of smaller files, you will quickly see the bottleneck‚Ä¶ The current implementation will loop through each file and (for each file) check the timestamp. It will continue to loop and check the timestamp on that one file until it either detects that it has stopped changing, or it hits its timeout (configured via the <code>readLockTimeout</code> option). It will not move on to the next file until one of those conditions is satisified. Which means that, if I have lots of producers writing files, those files could all be stuck waiting to be consumed because of a single slow producer. In practice, I‚Äôve actually seen this happen and it‚Äôs leads to a very bad situation where the polling itself starts to take too long (<em>at the filesystem level and outside of the control of Camel</em>) because of the sheer number of files in a directory. Once this starts to happen, it really just starts a snowball effect. So it‚Äôs difficult to recover from and usually requires manual intervention. So what do we do?</p><p>Well‚Ä¶ Luckily, Camel is awesome enough that it allows us to extend it whenever it‚Äôs out-of-the-box options don‚Äôt meet our needs. Suck on <strong>that</strong> competition! :) Specifically, in the previous scenario, we actually solved the problem by creating our own custom version of the ‚Äúchanged‚Äù strategy. Only, in our version, we didn‚Äôt pause and repeat checks on a single file. Instead, we looped through the files and (for each file) checked its stats. We then added those stats to a cache and moved on to the next file. On each subsequent poll, we would check the file‚Äôs stats against the cached ones to determine if it had stopped changing (for at least the <code>readLockCheckInterval</code> amount of time). This allowed us to continue processing any files that were ready without having to wait behind a single one that wasn‚Äôt. In practice, we were able to use this strategy to consume very large numbers of files with only a single server. Take a look at the sample source code if you‚Äôd like to give it a try: <a href="https://github.com/joshdreagan/camel-fastfile">https://github.com/joshdreagan/camel-fastfile</a>.</p><p><em>Worth noting that this is a recreation of the original work (as best as I could remember) that I did with my awesome colleague <a href="https://www.linkedin.com/in/scottvancamp">Scott Van Camp</a> whose awesome coding skills are only rivaled by his awesome beard growing skills. So he gets to share in the credit/blame‚Ä¶ :)</em></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;One of the most frequently requested use cases that I encounter out in the field is to ingest file-based data (batch or otherwise), and then validate, transform, process, store‚Ä¶ it. Luckily, &lt;a href=&quot;http://camel.apache.org/&quot;&gt;Apache Camel‚Äôs&lt;/a&gt; &lt;a href=&quot;http://camel.apache.org/file2.html&quot;&gt;File&lt;/a&gt; and &lt;a href=&quot;http://camel.apache.org/ftp.html&quot;&gt;FTP&lt;/a&gt; components make this extremely easy. So much so, that it requires very little thought to get up and running. And if you‚Äôre consuming small numbers of larger batch files, perhaps the defaults are good enough and you don‚Äôt need to put much though into it. If, however, you‚Äôre consuming large numbers of smaller files and you want to get the highest possible performance, there are a few configurations that you might want to consider.</summary>
    
    
    
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
  </entry>
  
  <entry>
    <title>Calling Native Code With Camel</title>
    <link href="https://blog.joshdreagan.com/2016/11/21/calling_native_code_with_camel/"/>
    <id>https://blog.joshdreagan.com/2016/11/21/calling_native_code_with_camel/</id>
    <published>2016-11-22T02:06:03.000Z</published>
    <updated>2021-01-14T22:53:28.809Z</updated>
    
    <content type="html"><![CDATA[<p>Usually when a customer has some legacy/native code that they need to invoke from <a href="http://camel.apache.org/">Camel</a> (or any Java program really), I recommend that they expose it via SOAP, REST, or some other standardized remote invocation mechanism. Then they can just call it with the appropriate <a href="http://camel.apache.org/cxf.html">Camel Component</a>. While I still think that this is best option, I recently had a customer ask if Camel had the ability to call native code directly. So I figured what the heck‚Ä¶ might as well blog about it‚Ä¶<a id="more"></a></p><p>Native code can be written in many languages (obviously‚Ä¶). And unfortunately, the mechanisms that you would use to invoke the compiled binaries (<code>.dll</code>‚Äòs or <code>.so</code>‚Äòs) are not always the same. In this blog post, I‚Äôm going to cover what I think are the most common (or at least the most commonly requested) native languages and how to invoke them.</p><h2 id="C"><a href="#C" class="headerlink" title="C"></a>C</h2><p>Of the languages that I‚Äôll cover in this post, calling C libaries is definitely the easiest. Once I have my compiled library (<code>.dll</code> or <code>.so</code>), I can just call it using <a href="http://docs.oracle.com/javase/8/docs/technotes/guides/jni/">JNI</a> or <a href="https://github.com/java-native-access/jna">JNA</a>.</p><p>Of the two, I prefer JNA since it doesn‚Äôt require me to generate any code using <code>javah</code> or really have much knowledge of the C code itself. All I need to do is create a Java interface that extends <code>com.sun.jna.Library</code> and that matches the signature of the C library (or more specifically its methods). Then I can create a proxy instance automatically using the <code>com.sun.jna.Native#loadLibrary(java.lang.String, java.lang.Class)</code> method (passing the name of your library and the interface class).</p><p><em>Note: You don‚Äôt give the full path or name of the library. The name is automatically wrapped with the platform-specific parts and the path is looked up via a <a href="https://github.com/java-native-access/jna/blob/master/www/GettingStarted.md">variety of mechanisms</a> (ie, the <code>jna.library.path</code> system property).</em></p><p>Once I have a proxy object, I can invoke methods on it like I would with any Java Bean in Camel using the <a href="https://camel.apache.org/bean.html">Bean Component</a>.</p><p>Fairly straighforward right? Take a look at this project (specifically the ‚Äúcamel-native-c‚Äù module) if you‚Äôd like to see it all working: <a href="https://github.com/joshdreagan/camel-native">https://github.com/joshdreagan/camel-native</a>.</p><h2 id="C-1"><a href="#C-1" class="headerlink" title="C++"></a>C++</h2><p>Invoking C++ code is slightly more involved than C code, but is still pretty simple. The options (ie, JNI or JNA) are the same, and for the most part the code is the same.</p><p>If you choose to use JNA (which I did), you still need to define an interface that matches the method signatures of the C++ library (and implements <code>com.sun.jna.Library</code>). And you still need to load the library and create the proxy object using the <code>com.sun.jna.Native</code> class. The differences/complications come from this thing called <a href="https://en.wikipedia.org/wiki/Name_mangling">Name Mangling</a>.</p><p>Name mangling is something that C++ compilers do to account for namespaces and overloaded methods and such. Most compilers do specify exactly how they perform the mangling, but unfortunately none of them do it the same. That is, the Windows C++ compiler will mangle the names differently than the GNU C++ compiler. At any rate, the end result is that my C++ method will not have the same name in its compiled form as it did in its source form. For example, if I had a method called <code>add</code> in my source, the GNU compiler might turn it into something like <code>_ZN10Calculator3addEii</code> (depending on the namespace and method signature of course) <em>(see note below)</em>. That means that when I try to invoke the method on my <code>com.sun.jna.Library</code> interface, I won‚Äôt have the right name (and will get an exception).</p><p>So how do I get around all this name mangling tomfoolery? Well, luckily, JNA allows us to provide a custom <code>com.sun.jna.FunctionMapper</code>. That means I can tell JNA that, when I call a function named <code>add</code>, it really needs to call a funtion named <code>_ZN10Calculator3addEii</code> in the underlying native library. Neat!</p><p>One more oddity to handle‚Ä¶ For whatever reason, the name mangling also adds an extra argument to the method signature. But once again, JNA has a mechanism to fix it. We can create a custom <code>com.sun.jna.InvocationMapper</code> to intercept the invocation and add a <code>null</code> argument to the beginning of the arg list.</p><p>That‚Äôs it! Now I can invoke it using the <a href="https://camel.apache.org/bean.html">Bean Component</a> just like I did in the C example.</p><p>Like I said‚Ä¶ slightly more involved, but still pretty simple. To see it all in action, take a look at this project (specifically the ‚Äúcamel-native-cpp‚Äù module): <a href="https://github.com/joshdreagan/camel-native">https://github.com/joshdreagan/camel-native</a>.</p><p><em>Note: You can use the <code>nm</code> tool on Linux to find the mangled names (ie, <code>nm -D libc-calculator.so</code>).</em></p><h2 id="C-35"><a href="#C-35" class="headerlink" title="C&#35;"></a>C&#35;</h2><p>C# (or any .NET code) is probably the most complicated case. On Windows, .NET DLLs are not the same format as a truely native DLL. This is because they aren‚Äôt really native code. They‚Äôre what Microsoft calls <a href="https://en.wikipedia.org/wiki/Managed_code">Managed Code</a>. Managed code is code that must be run in a virtual machine. Think Java and its JVM, but more Microsofty‚Ä¶ So it can‚Äôt be invoked directly (or at least not without loading a virtual machine). That means that using JNI or JNA directly are out. So what do I do? Well, there are a few options.</p><p>If my .NET DLL exposed a <a href="https://en.wikipedia.org/wiki/Component_Object_Model">COM</a> interface, I could write a C++ wrapper that calls the .NET DLL through COM. Then I could follow the above instructions for invoking C++ code. But what if my library didn‚Äôt expose a COM interface? In my experience, most don‚Äôt. And even if it did, that seems like a lot of effort, and I‚Äôm quite lazy‚Ä¶</p><p>I could perhaps use a paid tool like <a href="https://www.javonet.com/">javOnet</a> or <a href="http://jnbridge.com/">JNBridge</a>. Both seem simple enough to use and are probaly pretty stable. But they both cost a lot of money, and I‚Äôm quite cheap‚Ä¶</p><p>So what‚Äôs left? I went with a project called <a href="http://jni4net.com/">jni4net</a>. It does all the work for me (no writing wrapper code), and the price is right (free!). Plus, it‚Äôs the only one of the options I found that was open source (and I like open source! :)). Now for the bad news‚Ä¶ It‚Äôs not the most full-featured or simplest tool in the world. That‚Äôs ok though. My cheapness typically wins out over my laziness. So here goes‚Ä¶</p><p>First we need to generate and build the wrapper code. Sadly, the tool has a few steps to its build (making scripting a little complex), but it‚Äôs not too bad. You have to run the <code>proxygen.exe</code> command line tool (located in the <code>bin</code> directory of the distribution) and point it at your .NET DLL to generate the Java and C# wrapper code. This process also generates a <code>build.cmd</code> file that must then be used to actually build the code into a DLL library and its respective JAR file. This obviously doesn‚Äôt really mesh well with the way most Java builds are written. But with a bit of cleverness/ugliness, we can make it work.</p><p>Now that we have some generated/compiled wrapper code, we need to initialize what jni4net calls the ‚Äúbridge‚Äù and register the assemblies. <strong>This must be done at startup before any of the generated code/methods are used.</strong> A simple ‚Äúinitializer‚Äù class that calls the <code>net.sf.jni4net.Bridge#init()</code> and <code>net.sf.jni4net.Bridge#LoadAndRegisterAssemblyFrom(java.io.File)</code> methods will do the trick.</p><p>Once this is done, we can invoke the generated wrapper class methods using the <a href="https://camel.apache.org/bean.html">Bean Component</a> just like in the previous examples.</p><p>All done right? Not quite‚Ä¶ If you tried to this yourself, you probably noticed that there are all kinds of exceptions that occur when you actually try to run your project. This stems from a bit of quirkiness with the way that jni4net finds and loads the DLLs and JARs. As it turns out, the tool is quite opinionated about where its libraries live (making running in production potentially tricky). What do I mean? In order to run, the location of the jni4net JAR files (both generated and the ones that come with the distribution) must live in the same directory as your DLL files (both generated and the .NET one you‚Äôre trying to make use of). A quick look at <a href="https://github.com/jni4net/jni4net/blob/master/jni4net.j/src/main/java/net/sf/jni4net/CLRLoader.java">the code</a> showed that this is because it uses a combination of path and naming conventions to figure out the locations of the supporting libs. Unfortunately, this is currently hard-coded. :( Fortunately, this is an open source project! So anyone with a bit of free time could fix this and submit a pull request. :)</p><p>All in all it‚Äôs a bit cumbersome, but works. And that‚Äôs what really matters right? For an actual running example, take a look at this project (specifically the ‚Äúcamel-native-csharp‚Äù module): <a href="https://github.com/joshdreagan/camel-native">https://github.com/joshdreagan/camel-native</a>.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Usually when a customer has some legacy/native code that they need to invoke from &lt;a href=&quot;http://camel.apache.org/&quot;&gt;Camel&lt;/a&gt; (or any Java program really), I recommend that they expose it via SOAP, REST, or some other standardized remote invocation mechanism. Then they can just call it with the appropriate &lt;a href=&quot;http://camel.apache.org/cxf.html&quot;&gt;Camel Component&lt;/a&gt;. While I still think that this is best option, I recently had a customer ask if Camel had the ability to call native code directly. So I figured what the heck‚Ä¶ might as well blog about it‚Ä¶</summary>
    
    
    
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
  </entry>
  
  <entry>
    <title>Smart LoadBalancing With Camel</title>
    <link href="https://blog.joshdreagan.com/2016/10/10/smart_loadbalancing_with_camel/"/>
    <id>https://blog.joshdreagan.com/2016/10/10/smart_loadbalancing_with_camel/</id>
    <published>2016-10-10T21:29:41.000Z</published>
    <updated>2021-01-14T22:53:29.018Z</updated>
    
    <content type="html"><![CDATA[<p>LoadBalancing is a fairly well-known concept these days. There are a ton of existing strategies out there (ie, RoundRobin, Random, Sticky, Weighted, ‚Ä¶), and there a ton of existing implementations that have been built using both hardware and software (ie, Apache HTTPD, HAProxy, f5, Layer7, ‚Ä¶). So why create another one? Well‚Ä¶ although it‚Äôs not likely to be very useful, I thought it might be neat to see if I could make one that utilized CPU load (or any metric) to do more intelligent routing.<a id="more"></a></p><p>Luckily, like many things in <a href="http://camel.apache.org/">Camel</a>, this is a fairly simple task. I just have to create my own <code>org.apache.camel.processor.loadbalancer.LoadBalancer</code> implementation, and I can make it do pretty much anything I want. For instance, <a href="http://joshdreagan.github.io/2015/12/04/custom_camel_loadbalancer_with_infinispan/">I might implement one to do dynamic discovery using Infinispan</a> (shameless self-promotion :)). But I digress‚Ä¶</p><p>So let‚Äôs break down the wish list: I want to be able to use the strategy for more than just HTTP. I‚Äôd like to be able to use any available metric. And I need the collection of said metric to occur asynchronously in the background (so I don‚Äôt slow down my routing).</p><p><img src="smart-lb.png" alt="Smart LoadBalancer"></p><p>Take a look at the source code <a href="https://github.com/joshdreagan/camel-smart-loadbalancer">https://github.com/joshdreagan/camel-smart-loadbalancer</a> to see how I did it. In my example, I load balanced HTTP calls and used JMX to collect CPU utilization. But you could just as easily use the exact same implementation to monitor <a href="http://activemq.apache.org/">ActiveMQ</a> queue depth (or queue % full) and load balance between brokers. Or maybe monitor filesystem space and load balance FTP endpoints.</p><p>Like I said in the intro, this is probably not terribly useful in a real-world environment since the metrics will likely change at a faster rate than you would reasonably poll. But at the very least, hopefully someone will find it interesting. And maybe‚Ä¶ just maybe‚Ä¶ it will get Christian Posta to read my blog. :)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;LoadBalancing is a fairly well-known concept these days. There are a ton of existing strategies out there (ie, RoundRobin, Random, Sticky, Weighted, ‚Ä¶), and there a ton of existing implementations that have been built using both hardware and software (ie, Apache HTTPD, HAProxy, f5, Layer7, ‚Ä¶). So why create another one? Well‚Ä¶ although it‚Äôs not likely to be very useful, I thought it might be neat to see if I could make one that utilized CPU load (or any metric) to do more intelligent routing.</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
  </entry>
  
  <entry>
    <title>Decommissioning JBoss A-MQ Brokers</title>
    <link href="https://blog.joshdreagan.com/2016/08/22/decommissioning_jboss_a-mq_brokers/"/>
    <id>https://blog.joshdreagan.com/2016/08/22/decommissioning_jboss_a-mq_brokers/</id>
    <published>2016-08-22T19:04:26.000Z</published>
    <updated>2021-01-14T22:53:28.909Z</updated>
    
    <content type="html"><![CDATA[<p>There are many reasons why someone might need to decommision a <a href="https://www.redhat.com/en/technologies/jboss-middleware/amq">JBoss A-MQ</a> broker. Perhaps you are taking a server down for maintenance. Maybe you‚Äôre trying to do an upgrade. Or maybe you‚Äôve scaled up during a peak period and now need to scale back down. In any case, you likely don‚Äôt want the messages that are persisted in that store to be stuck until you bring things back online. And in the case that you don‚Äôt plan to bring things back online, you certainly don‚Äôt want them to be lost. So what do you do?</p><a id="more"></a><p>One strategy that I see a lot of people employ is to stop all the producers, and then wait until all the messages get processed by the consumers. This works fine for a lot of customers. And if you‚Äôre currently doing it this way (and it‚Äôs working), don‚Äôt worry. You‚Äôre certainly not doing anything wrong. However, this requires a lot of coordination and planning.</p><p>It requires coordination and planning because A-MQ (at the broker level) doesn‚Äôt really have the ability to stop the production of messages without also stopping the consumption of messages. This is due to the fact that the default configuration (which is what most people will use) only opens one transport connector (listener) that will service both producers and consumers. You can disconnect individual clients, but if they decide to reconnect there‚Äôs nothing that‚Äôs going to stop them. Most people control this on the application side. They just shut down all of their producer applications (or at least the initial ingress ones) and wait for the consumers to fully process the existing messages. Like I said, there‚Äôs nothing wrong with this approach if it‚Äôs working for you. But I‚Äôve effectively shut my entire system down even if I‚Äôm only decommissioning a single broker. What if I can‚Äôt have that much downtime?</p><p>Maybe I could get creative with my clustering and partition my load (ie, multiple network of brokers that are separated from eachother). Then I‚Äôd only affect a single partition of my cluster at a time. My producer clients could failover and reconnect to another partition during this downtime so it would seem as if I‚Äôm still operational. Then I could swap them back if desired when I‚Äôm done. Definitely a step in the right direction, but I‚Äôm still taking down a whole partition of brokers just to decommision one.</p><p>Another option would be to open two separate transport connectors (listeners) and have producers connect to one and consumers to the other. I‚Äôve complicated my client code a bit, but maybe that‚Äôs ok. It‚Äôs not <em>too</em> bad after all‚Ä¶ And now I have the ability to shut down the producer transport connector separately from the consumer transport connector at a single broker level, thus ensuring that no more messages will be produced to my broker while still allowing them to be consumed. But what if I have a <a href="http://activemq.apache.org/networks-of-brokers.html">network of brokers</a> setup? I‚Äôll need to also disable my network connector so that messages don‚Äôt get forwarded to me. Ok‚Ä¶ we‚Äôre getting better‚Ä¶ One outstanding problem is that I now have to rely on the locally connected consumers to successfully process all of my messages. How long will I need to wait? How many consumers are even connected to my broker?</p><p>This brings us to the final solution (and best in my opinion). I can take advantage of the fact that ActiveMQ is really just a very flexible set of libraries and I can create a ‚Äúmessage drainer‚Äù application to purge my persistent store. What do I mean? Well, first I would create a simple Java app that will spin up an embedded broker. I can point that embedded broker at a KahaDB persistent store. Then I can start consuming messages from it (like I would from any broker) and send them off to another broker. And since my embedded broker is local (ie., inside my JVM), I can just connect to it using the <a href="http://activemq.apache.org/vm-transport-reference.html">VM transport</a>. So I don‚Äôt even have to worry about remote clients. They can‚Äôt even see my broker. They will simply <a href="http://activemq.apache.org/failover-transport-reference.html">failover</a> to another active broker as soon as I take mine down and have no knowledge that I‚Äôm even connected and draining the messages.</p><p>Neat! Now I don‚Äôt have to worry about coordinating my applications, separating my transport connectors, bringing down brokers unnecessarily, ‚Ä¶ I can simply bring down the broker that I wish to decommission. Then just run my ‚Äúmessage drainer‚Äù application, point it to the KahaDB of my downed broker, and give it the url of an active broker that I‚Äôd like to send my messages off to. Once I‚Äôve finished draining the messages, I can get rid of my broker and it‚Äôs persistent store. Or if I was just doing maintenance, I can bring the broker back online and it will see its store with no messages. So no need to worry about dupicates. This solution is simple, requires no unnecessary downtime, and can be used in any situation from performing maintenance to down-scaling. Here‚Äôs some sample source code to get you started: <a href="https://github.com/joshdreagan/activemq-drainer">https://github.com/joshdreagan/activemq-drainer</a>. Enjoy!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;There are many reasons why someone might need to decommision a &lt;a href=&quot;https://www.redhat.com/en/technologies/jboss-middleware/amq&quot;&gt;JBoss A-MQ&lt;/a&gt; broker. Perhaps you are taking a server down for maintenance. Maybe you‚Äôre trying to do an upgrade. Or maybe you‚Äôve scaled up during a peak period and now need to scale back down. In any case, you likely don‚Äôt want the messages that are persisted in that store to be stuck until you bring things back online. And in the case that you don‚Äôt plan to bring things back online, you certainly don‚Äôt want them to be lost. So what do you do?&lt;/p&gt;</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
  </entry>
  
  <entry>
    <title>HA Deployments With Fuse</title>
    <link href="https://blog.joshdreagan.com/2016/07/28/ha_deployments_with_fuse/"/>
    <id>https://blog.joshdreagan.com/2016/07/28/ha_deployments_with_fuse/</id>
    <published>2016-07-29T03:34:04.000Z</published>
    <updated>2021-01-14T22:53:29.001Z</updated>
    
    <content type="html"><![CDATA[<p>When out and about, I often get the question: ‚ÄúHow do I setup HA (high availability) with <a href="http://developers.redhat.com/products/fuse/overview/">Red Hat‚Äôs JBoss Fuse</a>?‚Äù. People ask this question and they expect a simple, straightforward answer. And why shouldn‚Äôt they? The question is simple enough right? I could ask the same question about something like <a href="http://tomcat.apache.org/">Tomcat</a> and get a well documented answer involving little more than a loadbalancer. Unfortunately, the answer for Fuse is a bit more involved and usually starts with the annoying response of ‚Äúit depends‚Äù.</p><a id="more"></a><p>So let‚Äôs expand on that a bit‚Ä¶ Considering my previous example of Tomcat (which is just a Servlet container), what protocol does it speak? Easy! It only talks 1 protocol‚Ä¶ HTTP. But what protocol does Fuse speak? Well‚Ä¶ since it‚Äôs an integration framework, the answer is several. It may be consuming from a REST service and placing the contents in files. Or maybe it‚Äôs accepting HL7 messages over TCP and dumping them onto JMS queues. And the way that you‚Äôd make a REST service HA is very different from the way that you‚Äôd make a file consumer HA (which is very different from the way you‚Äôd make a JMS broker HA, ‚Ä¶). So you can see that while the answer of ‚Äúit depends‚Äù might be a bit annoying, it is actually the most accurate answer I could give.</p><p>As of this writing, the <a href="http://camel.apache.org/components.html">Camel Components</a> page lists 240 different components. And there‚Äôs no way I‚Äôm going to cover all of those in a blog post. So lets just focus on the one‚Äôs I run into most often.</p><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><p>Many of the available Camel components speak HTTP. Among those would be <a href="http://camel.apache.org/cxfrs.html">CXFRS</a> for REST services, <a href="http://camel.apache.org/cxf.html">CXF</a> for SOAP services, and <a href="http://camel.apache.org/jetty.html">Jetty</a> or <a href="http://camel.apache.org/servlet.html">Servlet</a> for low level HTTP services. And because HTTP is so prolific, it is probably the most easily understood HA scenario we‚Äôll cover.</p><p>With HTTP, there are two modes that we need to talk about (stateless, &amp; stateful).</p><p>Of the two, stateless is the most common and definitely the most recommended approach. It scales well, requires no coordination in a cluster, and is extremely easy to set up. You simply run however many instances you‚Äôd like of your service. The instances don‚Äôt have to know about eachother, and can be co-located or can be spread across datacenters. Once you have your services stood up, you simply place a loadbalancer (ie, <a href="https://httpd.apache.org/">Apache HTTPd</a>, <a href="https://www.nginx.com/">NGINX</a>, <a href="http://www.haproxy.org/">HAProxy</a>, ‚Ä¶) in front of them. There are even strategies that can be used to make the loadbalancers themselves HA (ie, hosting multiple instances with their own class A DNS records). So if any instance of your service goes down, the loadbalancer will simply redirect traffic to one of the other available instances. The client will send in his next request and have no idea that he isn‚Äôt talking to the same instance. Honestly, this topic has been covered so much that I don‚Äôt need to go into great detail about it. But here‚Äôs a very generic picture:</p><p><img src="http_stateless.png" alt="HTTP Stateless"></p><p>Stateful HTTP apps have fallen out of favor over the last decade or so. Which is a good thing in my opinion! They usually require some sort of session replication and/or coordination among the cluster. So now all of your instances need to know about eachother (limiting our ability to scale). And every time an object/value is placed in the session, it must be replicated to the other members (causing quite a bit of overhead that compounds as the cluster grows). We can mitigate some of these problems by being creative with our architecture. For instance, instead of having every member in the cluster connected in a mesh configuration we can split our servers into multiple meshes and do ‚Äústicky‚Äù loadbalancing to them. But it‚Äôs all a lot of hassle that you shouldn‚Äôt deal with if you can find a way to make your apps stateless instead. Once again, this is a topic that has been covered many times on the internet. The only thing specific to Fuse (and the only thing I‚Äôll elaborate on in this blog) is setting up session replication for the Karaf container.</p><p>For the most part, if you‚Äôre running Camel on any JavaEE app server (and tying to its Servlet container), it will have its own mechanism for session replication. Most of the time, this is completely hidden away from you, and you get it for ‚Äúfree‚Äù just by setting up your servers in a cluster configuration. For instance, <a href="http://developers.redhat.com/products/eap/overview/">JBoss EAP</a> uses an internal <a href="http://infinispan.org/">Infinispan</a> cache to store its session data. If you run your EAP instances in ‚Äúdomain‚Äù mode, they will automatically be clustered and will replicate sessions accordingly. While you can override the cache settings and tweak them to fit your needs, you usually don‚Äôt have to mess with it. However, if you are running on a Karaf container, you‚Äôll have to do a bit more of the setup yourself. This is because Karaf doesn‚Äôt assume that you‚Äôre using sessions, or even that you‚Äôre using Servlets. And if you do decide to use Servlets, it doesn‚Äôt assume which Servlet container you‚Äôll use (ie, Tomcat, Jetty, ‚Ä¶). So when you use any of the HTTP based components that I listed above on Karaf, they will (by default) fire up an embedded Jetty container. Luckily, Jetty is pluggable enough that it allows you to swap out its session management implementation. So you could, for instance, setup and configure Jetty to use an Infinispan cluster. Take a look at the <a href="http://www.eclipse.org/jetty/documentation/jetty-9/index.html#session-management">Jetty Docs</a> for more details. In any case, the mechanism by which a session is handled is transparent to your application. So it‚Äôs really more of a configuration detail. And just to stay consistent, here‚Äôs another generic picture:</p><p><img src="http_stateful.png" alt="HTTP Stateful"></p><h2 id="HL7-MLLP"><a href="#HL7-MLLP" class="headerlink" title="HL7/MLLP"></a>HL7/MLLP</h2><p>HL7/MLLP is a TCP based protocol for the healthcare industry. Digging in a bit more, HL7 (Health Level Seven) is the definition of the format of the message (which can be text or XML based), and MLLP (Minimal Lower Layer Protocol) just defines a couple of bytes that wrap the message so we know where to start/stop when reading it in. Support for HL7v2 is provided via the <a href="http://camel.apache.org/hl7.html">HL7</a> component in conjunction with a TCP transport component for doing the actual socket handling (ie, <a href="http://camel.apache.org/mina2.html">Mina</a>, or <a href="http://camel.apache.org/netty4.html">Netty</a>). There is some work being done on an <a href="http://camel.apache.org/mllp.html">MLLP</a> component that will make it a bit simpler to work with, but as of this writing it‚Äôs still a bit early.</p><p>All of that said, regardless of the transport component that you choose, or whether you‚Äôre working with HL7v2 (text) or HL7v3 (XML), the interaction is stateless. That is to say that a client sends in a request message and synchronously receives an ‚Äúack/nack‚Äù response. That is the entire transaction. Any other interaction is a separate message/ack and is handled independently. So no server-side coordination is required by the message acceptors (see ‚Äú<em>Note</em>‚Äú below). And because no server-side coordination is required, you can just use any available TCP loadbalancer (similar to what we did with stateless HTTP above).</p><p><em>Note: You may have a requirement to resequence the messages and process them in order. In which case, you can take a look at my previous blog: <a href="/2016/05/27/ordered_messaging_with_activemq_and_camel/" title="Ordered Messaging With ActiveMQ &amp; Camel">Ordered Messaging With ActiveMQ &amp; Camel</a>.</em></p><p>Here‚Äôs a sample NGINX loadbalancer configuration that I used for a recent engagement:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">events &#123;</span><br><span class="line">  worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line">stream &#123;</span><br><span class="line">  server &#123;</span><br><span class="line">    listen 7000;</span><br><span class="line">    proxy_pass tcp_backend;</span><br><span class="line">  &#125;</span><br><span class="line">  upstream tcp_backend &#123;</span><br><span class="line">    server instance-1.local:7000;</span><br><span class="line">    server instance-2.local:7000;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And here‚Äôs a (really simple) sample architecture:</p><p><img src="hl7_mllp.png" alt="HL7/MLLP"></p><h2 id="File-FTP"><a href="#File-FTP" class="headerlink" title="File/FTP"></a>File/FTP</h2><p>When consuming files using the <a href="http://camel.apache.org/file2.html">File</a> or <a href="http://camel.apache.org/ftp.html">FTP</a> components, there are a couple of different strategies that you can use for an HA setup: active/passive, and active/active.</p><p>In an active/passive configuration, you will have a single (master) instance polling for files. All of the other instances (slaves) will be waiting on some kind of lock. The slave instances will not begin polling for files until they detect that the master is no longer alive and well. In this way, we make sure that multiple JVMs running the same file poller config aren‚Äôt stepping on eachother‚Äôs toes while trying to consume the files. So how do we setup this active/passive coordination? If you‚Äôre using <a href="http://fabric8.io/">Fabric8</a> <strong>v1.x</strong> to cluster your <a href="http://karaf.apache.org/">Karaf</a> instances, you can just use the <a href="http://fabric8.io/gitbook/camelEndpointMaster.html">Master</a> component. It exploits the fact that a Fabric cluster uses a <a href="https://zookeeper.apache.org/">ZooKeeper</a> ensemble internally and uses it as a locking mechanism. Nice and simple! But what if you‚Äôre not running in a Fabric cluster? You could stand up your own ZooKeeper ensemble‚Ä¶ But that adds a bit of overhead that you might not be ok with if you‚Äôre not using it for anything else. Does that mean that you‚Äôre out of luck? Heck no! Camel rocks! We can just create our own custom <a href="http://camel.apache.org/routepolicy.html">RoutePolicy</a> to do the same thing. Here‚Äôs an example that I threw together for a customer recently: <a href="https://github.com/joshdreagan/camel-singleton-policy">https://github.com/joshdreagan/camel-singleton-policy</a>.</p><p><img src="file_active-passive.png" alt="File Active/Passive"></p><p>Often times, you won‚Äôt need the highest possible performance when polling for files. That‚Äôs because the most common use case is that I receive a few files for batch processing <em>maybe</em> once a day. So I can probably handle the actual polling/processing on a single instance. And in that case, the active/passive configuration would be perfectly fine. But what if I‚Äôm not receiving batch files once a day? What if I‚Äôm processing satellite perturbation data (<strong>TONS</strong> of tiny files) coming in 24/7 in a neverending stream? Maybe now I want to take advantage of my entire cluster to poll/process in an active/active configuration. That way I can scale it up‚Ä¶ Luckily, Camel makes this extremely easy. Because, again, Camel rocks! If you look at the available options for the file component, you‚Äôll notice that it basically has an <a href="http://camel.apache.org/idempotent-consumer.html">Idempotent Consumer</a> pattern baked right in (take a look at the <code>inProgressRepository</code> option). What‚Äôs more, it‚Äôs extremely flexible. It just needs any implementation of <code>org.apache.camel.spi.IdempotentRepository</code>. And there are already several implementations canned and ready to go. So you can use anything from Infinispan to a relational DB to coordinate your consumers. Here‚Äôs some sample code that uses Infinispan: <a href="https://github.com/joshdreagan/clustered-file-consumer">https://github.com/joshdreagan/clustered-file-consumer</a>. Feel free to plagiarize!</p><p><img src="file_active-active.png" alt="File Active/Active"></p><h2 id="JMS-ActiveMQ"><a href="#JMS-ActiveMQ" class="headerlink" title="JMS (ActiveMQ)"></a>JMS (ActiveMQ)</h2><p>JMS (<a href="http://activemq.apache.org/">ActiveMQ</a>) is definitely the most difficult HA scenario that I‚Äôll cover. Which is why I procrastinated and saved it until the end. Well‚Ä¶ sort of‚Ä¶ When talking about JMS on Fuse, you have to specify whether you mean from a client‚Äôs perspective, or from the broker‚Äôs perspective.</p><p>HA from the client‚Äôs perspective is actually quite simple. You just use the <a href="http://activemq.apache.org/failover-transport-reference.html">Failover</a> transport when creating your <code>javax.jms.ConnectionFactory</code> and the failover is handled for you. If a broker goes down, the client libraries will transparently reconnect to the next broker (whether it‚Äôs a slave, or another master) and keep on chugging with little more than a blip in performance. But let‚Äôs spend a little time and talk about the more complex case of making the broker itself HA.</p><p>When we say ‚Äúmake the broker HA‚Äù, what we really mean is ‚Äúmake the in-flight data that the broker is storing HA‚Äù. Because of the nature of messaging and it‚Äôs typical use case/requirements, this almost always ends up being a trade-off for performance vs reliability. So first let‚Äôs cover the easiest, best performing solution.</p><p>In a <a href="http://activemq.apache.org/masterslave.html">Master/Slave</a> (active/passive) architecture, two or more brokers point to the same physical data store (typically <a href="http://activemq.apache.org/kahadb.html">KahaDB</a>). Because the store can only be written to by one instance at a time, we must use some form of locking (similar to what we talked about in the File/FTP section). The lock implementation that ActiveMQ uses is pluggable. So you can specify your own custom ones. But there are defaults for each of the <a href="http://activemq.apache.org/persistence.html">persistence adapters</a> and I rarely see customers override them.</p><p>Let me give a concrete example‚Ä¶ When setting up ActiveMQ as a master/slave pair (<em>non-Fabric managed</em>) and using KahaDB, you would likely place the KahaDB storage directory on a shared filesystem (ie, NFSv4). Unless you customized the configuration, ActiveMQ would default to using an actual ‚Äúlock‚Äù file. When the instances came up, they would both attempt to acquire a filesystem-level lock on that file. Whoever got there first would become master, would open up the KahaDB for read/write, and would open up any listeners to begin accepting client connections. Any other instances would fail to get the lock and would begin try-polling until they got it. And until then, they would not read/write the KahaDB, or accept client connections. So they‚Äôre passive‚Ä¶</p><p><img src="activemq_master-slave.png" alt="ActiveMQ Master/Slave"></p><p>This is the simplest setup, but does have some caveats. First, we‚Äôll need to setup a shared filesystem that both instances can see. This will likely be something like an NFSv4 share. And because we need an actual filesystem-level lock, we must use a filesystem that supports them (<em>which is why I used the example of NFSv4 above and not NFSv3</em>). You‚Äôll probably also want to make the storage that hosts your NFS shares HA as well. So you‚Äôll likely use a SAN or some hardware appliance that provides this functionality. <em>If you do so, make sure that any data duplication/backup that occurs is <strong>fully synchronous</strong> and that filesystem-level locks are preserved during a failover!</em> Looking at you EMC‚Ä¶ Next, because of the shared storage, high throughput, and file locking requirements, the master/slave instances must live in the same datacenter. I‚Äôve seen many clients try to skirt this requirement and it always ends badly. However, if set up correctly this provides nearly immediate failover of in-flight messages within a datacenter as well as high message throughput. So if this satisfies your requirements, stop here.</p><p>So what if I have a requirement for HA across datacenters? Ok‚Ä¶ let‚Äôs negotiate a little more. The simplest &amp; fastest solution is to use the master/slave setup outlined above, but also have a warm site setup in another DC. If you experience a full DC outage, you can manually migrate the storage hosting your KahaDB to the backup DC, configure an ActiveMQ instance to point to it, and bring it online. It doesn‚Äôt care where the KahaDB came from, or if it was previously owned by another instance. It will simply read in any messages that are currently stored and begin processing/delivering them to consumers. <em>If you do this, make sure to remember not to mount the storage up to the primary again when it comes back online or you will end up with duplicate messages.</em> Alternately, you can just wait until the downed DC comes back online. As long as there is no storage loss, all of your messages are safe and will be processed. So it really comes down to the SLA (Service-Level Agreement) that you must support, how likely you think a full DC outage is to occur, and how much manual interaction you‚Äôre ok with if it does.</p><p><img src="activemq_cross-dc.png" alt="ActiveMQ Cross-DC"></p><p>Well, what if I have to protect against a <em>real</em> DC outage? This is affectionately known in the defense industry as ‚Äúthe smoking-hole scenario‚Äù. That is to say, what if I can‚Äôt be guaranteed that I‚Äôll be able to migrate storage during an outage because my DC is not simply <em>down</em>, but rather <em>destroyed</em>? Well first things first‚Ä¶ Prepare to make some serious performance tradeoffs. <em>I cannot stress this enough! You will not be processing large sets of data while synchronously replicating across a WAN.</em></p><p>One solution that I‚Äôve seen customers use is to replicate the storage using some sort of block-level disk replication software. <a href="https://www.drbd.org/">DRBD</a> works well enough in this situation because it gives you a little bit of flexibility over performance vs absolute reliability (look at modes B or C in their docs (<strong>not A</strong>)). Basically, every write at the filesystem level is a blocking call. That call usually returns as soon as the data has been physically written to the disk. In the case of a block-level replication solution, that blocking call will not return until the data has been written to both the primary and the backup disks. Because this all occurs at the filesystem level, it is completely out of ActiveMQ‚Äôs hands. It just thinks it‚Äôs been given really slow storage. One thing to note here is that you would not set up an ActiveMQ Master/Slave pair using this technology because the filesystem-level locks would not replicate. So you would do the manual failover to the warm site as described above. The difference is that you won‚Äôt have to migrate the storage as it‚Äôs already been replicated safely to the backup DC.</p><p><img src="activemq_cross-dc_drbd.png" alt="ActiveMQ Cross-DC DRBD"></p><p>The second set of solutions that I‚Äôve seen are a decent tick faster (still not blazing though), but add a bit complication to the clients. They‚Äôre both based on some variation of fanout/multicast. The basic gist of it is that the producer clients will send a copy of every message to a broker on both DCs. This isn‚Äôt that bad for the producers since the <a href="http://activemq.apache.org/fanout-transport-reference.html">Fanout</a> transport handles all of the work for them. In fact, you can even toss in ActiveMQ‚Äôs <a href="http://activemq.apache.org/the-proxy-connector.html">Proxy Connector</a> and the producer clients won‚Äôt have to change a bit.</p><p><img src="activemq_cross-dc_fanout.png" alt="ActiveMQ Cross-DC Fanout"></p><p>I know what you‚Äôre thinking‚Ä¶ That doesn‚Äôt sound too bad. Where‚Äôs all this ‚Äúcomplication‚Äù you were rambling on about? Don‚Äôt get too excited. We just haven‚Äôt gotten there yet. The added complication comes on the consumer/processing side. Basically, I now have duplicate messages that I‚Äôm processing. And I either have to prevent them using something like <a href="http://camel.apache.org/idempotent-consumer.html">Idempotent Consumers</a> or embrace them by adding complication to my code.</p><p>The idempotent consumer strategy looks attractive because Camel makes it extremely easy. I just have to set up some sort of shared <code>org.apache.camel.spi.IdempotentRepository</code> and add a few lines of Camel routing to my <a href="http://camel.apache.org/jms.html">JMS</a> consumers. Take a look at the <a href="https://github.com/joshdreagan/clustered-amq-examples">https://github.com/joshdreagan/clustered-amq-examples</a> example <em>(specifically the ‚Äúclustered-amq-examples-idempotent‚Äù module)</em> for more details. The problem is that I have to set up a repository that synchronously replicates its data across a WAN. So aren‚Äôt I back to the same exact problem I had before? Well‚Ä¶ not quite. Definitely similar though. I‚Äôll get a small performance boost since the producers are multicasting the message to both brokers in parallel (but blocking until they get back the configured minimum number of ‚Äúacks‚Äù). And the synchronous replication that I mentioned is only an idempotent key (ie, the <code>JMSMessageID</code>) and not the entire message itself. Also, all instances are active. So I‚Äôm getting a bit more loadbalancing for my consumer clients. And they can failover faster than if I had a warm site setup (since I don‚Äôt have to perform a manual failover). That being said, don‚Äôt expect the performance to be stellar.</p><p>But what if I want my performance to be stellar? I told you you can‚Äôt have it! But we can possibly get a tiny bit better. The second option that I mentioned is to embrace the duplicates. Let‚Äôs expand on that. If I multicast/fanout a copy of every message to both brokers, I‚Äôm going to take that hit. If I want a fully synchronous, total data backup, there‚Äôs just no getting around it. But I don‚Äôt necessarily have to have my consumers coordinate. What if I just went ahead and processed the duplicates? Would the world end? Let‚Äôs use a concrete example. Let‚Äôs pretend that my consumers were accepting messages and placing each one into a relational DB. And let‚Äôs say that I might have some REST service that, when invoked with some ID, returns a record for that ID from that relational DB. If I inserted both copies of the message, my REST service would return two records. That‚Äôs not ideal! But what if it didn‚Äôt? What if I just had my REST service run a ever-so-slightly more complicated query that just returned the first record it found? I don‚Äôt care which one. They‚Äôre both the same. Now I‚Äôm back to the result that I wanted. And I have a pretty robust system that can handle duplicate records (both intentional and unintentional). Not too shabby! Now since you‚Äôre never satisfied, you might be asking about all of that duplicated data taking up extra space. Well that‚Äôs easy enough to fix‚Ä¶ Simply have a ‚Äúcleanup‚Äù job that runs at some predifined interval and removes any duplicates that it finds. I don‚Äôt care when it runs, or which record it ends up removing. My application will always return the correct result. Take a look at the <a href="https://github.com/joshdreagan/clustered-amq-examples">https://github.com/joshdreagan/clustered-amq-examples</a> example <em>(specifically the ‚Äúclustered-amq-examples-dupsok‚Äù module)</em> for more details.</p><p>So now you see why I saved JMS (ActiveMQ) HA to the very end. It‚Äôs a complicated subject with lots of possible solutions. Hopefully, one of them meets your needs. If not, there is just no pleasing you‚Ä¶ Either way, this blog post has become way too wordy. So I‚Äôm calling it a day. :)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;When out and about, I often get the question: ‚ÄúHow do I setup HA (high availability) with &lt;a href=&quot;http://developers.redhat.com/products/fuse/overview/&quot;&gt;Red Hat‚Äôs JBoss Fuse&lt;/a&gt;?‚Äù. People ask this question and they expect a simple, straightforward answer. And why shouldn‚Äôt they? The question is simple enough right? I could ask the same question about something like &lt;a href=&quot;http://tomcat.apache.org/&quot;&gt;Tomcat&lt;/a&gt; and get a well documented answer involving little more than a loadbalancer. Unfortunately, the answer for Fuse is a bit more involved and usually starts with the annoying response of ‚Äúit depends‚Äù.&lt;/p&gt;</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="cxf" scheme="https://blog.joshdreagan.com/tags/cxf/"/>
    
    <category term="karaf" scheme="https://blog.joshdreagan.com/tags/karaf/"/>
    
    <category term="jboss" scheme="https://blog.joshdreagan.com/tags/jboss/"/>
    
    <category term="wildfly" scheme="https://blog.joshdreagan.com/tags/wildfly/"/>
    
    <category term="infinispan" scheme="https://blog.joshdreagan.com/tags/infinispan/"/>
    
    <category term="datagrid" scheme="https://blog.joshdreagan.com/tags/datagrid/"/>
    
  </entry>
  
  <entry>
    <title>Ordered Messaging With ActiveMQ &amp; Camel</title>
    <link href="https://blog.joshdreagan.com/2016/05/27/ordered_messaging_with_activemq_and_camel/"/>
    <id>https://blog.joshdreagan.com/2016/05/27/ordered_messaging_with_activemq_and_camel/</id>
    <published>2016-05-27T06:00:00.000Z</published>
    <updated>2021-01-14T22:53:29.007Z</updated>
    
    <content type="html"><![CDATA[<p>I‚Äôve been to several customers over the years who have a requirement to consume messages from a JMS queue in an ordered fashion. The discussions always go the same way‚Ä¶ It starts out as a simple design, but becomes really problematic when they get to the implementation phase. Turns out, it‚Äôs really not all that simple once you try to scale. In this blog post, we‚Äôll explore in a bit more detail and give some possible solutions.</p><a id="more"></a><blockquote><p>The sample code for this blog can be found at <a href="https://github.com/joshdreagan/ordered-activemq-consumer">https://github.com/joshdreagan/ordered-activemq-consumer</a>.</p></blockquote><h2 id="Typical-Architecture"><a href="#Typical-Architecture" class="headerlink" title="Typical Architecture"></a>Typical Architecture</h2><p>So the first thing that people do is to create some test code. They know that JMS queues preserve order. So the logic goes that, if I put messages on the queue in order, I should be able to pull them off in the same order. They end up with something that looks similar to the picture below.</p><p><img src="simple.png" alt="simple"></p><p>Run a test and you‚Äôll see that it does indeed work. Ship it! Well‚Ä¶ maybe not just yet‚Ä¶</p><h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><p>This architecture may work in a very simple use case, but it has some serious limitations.</p><p><img src="you_should_feel_bad.jpg" alt="You should feel bad..."></p><p>The first problem that you‚Äôll encounter is that this setup is really slow. It‚Äôs a given that, in order to process messages in order, the processing must occur in a single thread. However, I will likely have more than one group that could be processed independently. So in theory, I can have multiple producers sending sequences of messages. Take a look at the illustration below.</p><p><img src="multiple_producer.png" alt="Multiple producers"></p><p>Technically, everything still works. The single consumer will receive both sequences of messages and will process them in the order he receives them. So in the end, both groups will have their messages processed in order. But hopefully the flaw in this setup is obvious. As we scale up and add more and more producer groups, we are bottlenecked in performance by the single consumer. What happens when we try to scale the consumers?</p><p><img src="multiple_consumer.png" alt="Multiple consumers"></p><p>Things no longer work. Because the broker is going to loadbalance messages to the available consumers, we have no guarantee that the sequences of messages will be processed on the same thread. Which means we can‚Äôt guarantee order. And since we can‚Äôt add more consumers, there‚Äôs no sense in scaling out and adding more brokers either. Bummer‚Ä¶ :(</p><h2 id="Possible-Solutions"><a href="#Possible-Solutions" class="headerlink" title="Possible Solutions"></a>Possible Solutions</h2><p>So the question is‚Ä¶ How do we scale things out while maintaining our ability to process groups of messages in order? Well, one solution you might consider is <a href="http://activemq.apache.org/message-groups.html">ActiveMQ‚Äôs Message Groups</a>. Basically, it‚Äôs a really neat feature that allows you to do ‚Äústicky‚Äù loadbalancing of messages to the available consumers. If the producers include a <code>JMSXGroupID</code> header on the JMS message, the broker will check to see if there is a consumer available that has already received messages with that same <code>JMSXGroupID</code>. If one is available, it will deliver the message to it (and all subsequent messages as well as long as it remains available). If not (either because this is the first it has seen that <code>JMSXGroupID</code>, or because the previous consumer has gone away), it will pick a new one. Here‚Äôs how that might look:</p><p><img src="message_groups.png" alt="ActiveMQ Message Groups"></p><p>Problem solved right? Depends on if you only need to use a single broker. And if you want to use more than one, it depends on how strict you are about the message ordering. Most of the time, things works fine. And if ‚Äúmost of the time‚Äù is good enough for your requirements, then this is definitely the simplest solution. So go with it.</p><p>But let‚Äôs go ahead and discuss the corner case where it doesn‚Äôt work out so well. There are 2 things to be aware of: First, when a message is received by a broker, it is persisted in that broker‚Äôs store and exists only on that broker. Second, if a consumer goes away for any reason (ie, network blip, restart, ‚Ä¶) the broker will pick a new recipient and start sending the messages to it instead. So let‚Äôs assume that I have a network of brokers setup (because I like to scale). And if I have a network of brokers setup, I‚Äôll probably use some form of failover (because I like to be HA for my clients). So in this setup, what happens if we send a message to a broker, but the broker is taken down before it can deliver it. The producers would failover and keep sending messages to the next available broker. That broker would pick a consumer and continue delivering messages to it with no knowledge that the failed broker was still holding on to some messages. Now I‚Äôm back to getting my messages out of order. Here‚Äôs what that might look like:</p><p><img src="multiple_brokers__message_groups.png" alt="ActiveMQ Message Groups in a cluster"></p><p>Furthermore, what if I don‚Äôt have control over the producers? If I don‚Äôt control them, I might not be able to enforce that they set a <code>JMSXGroupID</code> header. So how might I go about solving this conundrum? I‚Äôm glad you asked. :)</p><p>One solution would be to use some Camel magic. <a href="http://camel.apache.org/">Because Camel is awesome!</a> If I use Camel as a consumer, I can have it pipe the messages into an <a href="http://camel.apache.org/aggregator2.html">aggregator</a> that can just store them up in a list. Once I‚Äôve received all of them, I can then send them to a <a href="http://camel.apache.org/splitter.html">splitter</a> to get them back to individual messages, and then send those individual messages through a <a href="http://camel.apache.org/resequencer.html">resequencer</a> (and finally to my desired destination). My messages for each group/sequence will be processed in a single thread (assuming I don‚Äôt enable any parallel processing) and will be emitted in order. EIPs for the win! The nice thing about this solution is that I don‚Äôt have to worry about those stuck messages. As soon as the failed broker comes back online (or its slave takes over), I will receive that stuck message. And until it does, all of my other messages for that group/sequence will sit patiently and wait inside my aggregation repository. Another thing to note is that I don‚Äôt have to complete my aggregation based on some fixed number. I have all kinds of flexibility for my criteria. Take a look at the <a href="http://camel.apache.org/aggregator2.html">Camel docs</a> for more info. Here‚Äôs a nice picture:</p><p><img src="multiple_brokers__camel.png" alt="Camel in a cluster"></p><p>So what‚Äôs the catch? Well‚Ä¶ technically all of the aggregation repository implementations that exist so far can‚Äôt work in a cluster or even with multiple threads. There has been some work to handle optimistic locking, but if you give it a try (or dig through the code if you don‚Äôt believe me) you‚Äôll find that they only handle the case of 2 threads trying to do the initial insert at the same time. They still have an issue where 2 threads might be attempting to update the repository at the same time and could squash eachother‚Äôs changes. Luckily, Camel lets us write our own <code>org.apache.camel.spi.AggregationRepository</code> implementations. Did I mention that Camel rocks!? Take a look at the example code found here: <a href="https://github.com/joshdreagan/ordered-activemq-consumer">https://github.com/joshdreagan/ordered-activemq-consumer</a>.</p><p>Basically, I just copied most of the code from the existing <code>org.apache.camel.processor.aggregate.jdbc.JdbcAggregationRepository</code> implementation. But I added a <code>version</code> column to the underlying database tables and some logic to check and increment it (or throw an exception if it doesn‚Äôt match) on insert/update. I‚Äôm sure there‚Äôs a lot more that could be done to make it more robust (like have it implement <code>org.apache.camel.spi.RecoverableAggregationRepository</code> as well). But hey‚Ä¶ this is just an example. Do your own coding damnit!</p><p>I‚Äôm sure this isn‚Äôt an exhaustive list of every possible way to solve this problem. But it‚Äôs a least a couple‚Ä¶ And that should definitely be worth a glass of <a href="https://www.masterofmalt.com/whiskies/lagavulin/lagavulin-16-year-old-whisky/">good Scotch</a>. So if you see me at <a href="https://www.redhat.com/en/summit">Red Hat Summit</a>‚Ä¶ :)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;I‚Äôve been to several customers over the years who have a requirement to consume messages from a JMS queue in an ordered fashion. The discussions always go the same way‚Ä¶ It starts out as a simple design, but becomes really problematic when they get to the implementation phase. Turns out, it‚Äôs really not all that simple once you try to scale. In this blog post, we‚Äôll explore in a bit more detail and give some possible solutions.&lt;/p&gt;</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
  </entry>
  
  <entry>
    <title>AMQP Performance Testing With JBoss A-MQ</title>
    <link href="https://blog.joshdreagan.com/2016/02/02/amqp_performance_testing/"/>
    <id>https://blog.joshdreagan.com/2016/02/02/amqp_performance_testing/</id>
    <published>2016-02-02T07:00:00.000Z</published>
    <updated>2021-01-14T22:53:28.800Z</updated>
    
    <content type="html"><![CDATA[<p>I recently had a customer that wanted us to do some load testing of <a href="http://www.jboss.org/products/amq/overview/">Red Hat‚Äôs JBoss A-MQ</a> for them. In particular, this customer wanted the tests performed using the AMQP protocol instead of ActiveMQ‚Äôs native OpenWire. From previous engagements, I knew that there would be a performance difference. But after a quick look I didn‚Äôt see any blogs or posts on the subject. More specifically, I didn‚Äôt see any posts that detailed how to run the tests yourself so that you could get real numbers in your own environment. So I figured I‚Äôd write up some steps and post my results for future reference.</p><a id="more"></a><blockquote><p><strong>Please note that the purpose of this blog post is not to give you a number of msg/s to expect or tell you the absolute best way to tune your broker. The purpose of this post is to show you how to run the tests yourself and give you some very rough idea of the performance difference between the two protocols. All of my testing was done on my laptop using the default configurations. You will probably get wildly different performance in your environment and will likely need to tune the broker specific to your use case to get the best performance possible.</strong></p></blockquote><h2 id="Protocol-Basics"><a href="#Protocol-Basics" class="headerlink" title="Protocol Basics"></a>Protocol Basics</h2><p>Both <a href="https://www.amqp.org/">AMQP (Advanced Message Queuing Protocol)</a> and <a href="http://activemq.apache.org/openwire.html">OpenWire</a> are what we refer to as ‚Äúwire-level protocols‚Äù. They define how a client and broker will negotiate a connection, how they‚Äôll format messages, and how they‚Äôll communicate in general. ActiveMQ can speak many different wire-level protocols, but OpenWire and AMQP are supposed to be the fastest as they are both binary in nature. In both cases, you have multiple options as to what language your clients can be written in (ie, Java, .NET, C++, ‚Ä¶). It really doesn‚Äôt matter as long as they are communicating via the same wire-level protocol as the broker. In this case, I‚Äôll be using Java simply because of the availability of test tools.</p><h2 id="Test-Details"><a href="#Test-Details" class="headerlink" title="Test Details"></a>Test Details</h2><p>There are a ton of available test tools that you can use to drive traffic to your brokers. For this blog, I used the <a href="http://activemq.apache.org/activemq-performance-module-users-manual.html">ActiveMQ Perf Maven Plugin</a>. This is a great tool that comes with the ActiveMQ source code and allows you to run as both producers and consumers. It is easily configurable and gives you a ton of options to test various scenarios (ie, persistent/non-persistent, transacted/non-transacted, 1-n producer/consumer threads, ‚Ä¶). The only caveat to the tool is that it will load a connection factory that uses the OpenWire protocol. Luckily, it was written in such a way that we can extend it to use AMQP as well. To do that, we only need to create one class that knows how to load an AMQP connection factory. The source for the class is as follows:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.jboss.examples.amqp.spi;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.activemq.tool.spi.ReflectionSPIConnectionFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AMQPReflectionSPIConnectionFactory</span> <span class="keyword">extends</span> <span class="title">ReflectionSPIConnectionFactory</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getClassName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;org.apache.qpid.jms.JmsConnectionFactory&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then we just need to make sure that our custom class and the Qpid client libraries are on the Maven classpath.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>$&#123;project.groupId&#125;<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>$&#123;project.artifactId&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.activemq<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>activemq-amqp<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;activemq.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.qpid<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>qpid-jms-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;qpid.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The tricky part is that we need them on the classpath of the Maven plugin itself and not necessarily the classpath of the project. Take a look at the <a href="https://github.com/joshdreagan/amqp-perf-test/blob/master/pom.xml">pom.xml</a> file to see what I mean. The full code for this test can be found at <a href="https://github.com/joshdreagan/amqp-perf-test">https://github.com/joshdreagan/amqp-perf-test</a>. Feel free to just clone it down and use it directly.</p><p>If you take a look at the <a href="http://activemq.apache.org/activemq-performance-module-users-manual.html">plugin‚Äôs documentation</a>, you‚Äôll see several properties that can be set for the test as a whole, the consumer, the producer, and the connection factory. You can configure the properties using ‚Äú-Dkey=value‚Äù arguments on the command line, or via a .properties file (or some combination of the two). If you plan to run the test multiple times, it‚Äôs probably worth creating a .properties file. The only detail that I‚Äôll give here is that the connection factory properties are set via reflection and will be specific to the connection factory used. I mention this because we swap out the connection factory when we run the AMQP tests. To give a concrete example, when using the <code>org.apache.activemq.tool.spi.ActiveMQReflectionSPI</code> you will set the URI for the broker using <code>-Dfactory.brokerURL=tcp://localhost:61616</code>, but when using the <code>org.jboss.examples.amqp.spi.AMQPReflectionSPIConnectionFactory</code> you will set the URI for the broker using <code>-Dfactory.remoteURI=amqp://localhost:5672</code>. This is because the ‚Äúsetters‚Äù are named differently for the different connection factory implementations. The available options for the AMQP connection factory can be found in the <a href="https://qpid.apache.org/releases/qpid-jms-0.5.0/docs/index.html">Qpid docs</a>. All other options (ie, producer, consumers, &amp; test) should be the same and are found on the <a href="http://activemq.apache.org/activemq-performance-module-users-manual.html">plugin docs</a>.</p><h2 id="Test-Results"><a href="#Test-Results" class="headerlink" title="Test Results"></a>Test Results</h2><p>Here are some sample runs that I did. <em>Please note the disclaimer at the beginning of this blog post regarding performance results.</em></p><h3 id="Producer-OpenWire"><a href="#Producer-OpenWire" class="headerlink" title="Producer OpenWire"></a>Producer OpenWire</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">$&gt; mvn activemq-perf:producer -DsysTest.propsConfigFile&#x3D;src&#x2F;main&#x2F;resources&#x2F;tcp-producer.properties</span><br><span class="line">OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;2048m; support was removed in 8.0</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building ActiveMQ Perf: AMQP Perf Test 1.0.0-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- activemq-perf-maven-plugin:5.11.0:producer (default-cli) @ amqp-perf-test ---</span><br><span class="line">[INFO] Loading properties file: &#x2F;home&#x2F;jreagan&#x2F;Development&#x2F;Projects&#x2F;joshdreagan&#x2F;amqp-perf-test&#x2F;src&#x2F;main&#x2F;resources&#x2F;tcp-producer.properties</span><br><span class="line">[INFO] Created: org.apache.activemq.ActiveMQConnectionFactory using SPIConnectionFactory: org.apache.activemq.tool.spi.ActiveMQReflectionSPI</span><br><span class="line">[INFO] Sampling duration: 300000 ms, ramp up: 0 ms, ramp down: 0 ms</span><br><span class="line">[INFO] Creating queue: queue:&#x2F;&#x2F;TEST.FOO</span><br><span class="line">[INFO] Creating JMS Connection: Provider&#x3D;ActiveMQ-5.11.0, JMS Spec&#x3D;1.1</span><br><span class="line">[INFO] Creating  producer to: queue:&#x2F;&#x2F;TEST.FOO with non-persistent delivery.</span><br><span class="line">[INFO] Starting to publish 1024 byte(s) messages for 300000 ms</span><br><span class="line">[INFO] Finished sending</span><br><span class="line">[INFO] Client completed</span><br><span class="line">#########################################</span><br><span class="line">####    SYSTEM THROUGHPUT SUMMARY    ####</span><br><span class="line">#########################################</span><br><span class="line">System Total Throughput: 13347982</span><br><span class="line">System Total Clients: 1</span><br><span class="line">System Average Throughput: 44493.27333333333</span><br><span class="line">System Average Throughput Excluding Min&#x2F;Max: 44274.73333333333</span><br><span class="line">System Average Client Throughput: 44493.27333333333</span><br><span class="line">System Average Client Throughput Excluding Min&#x2F;Max: 44274.73333333333</span><br><span class="line">Min Client Throughput Per Sample: clientName&#x3D;JmsProducer0, value&#x3D;0</span><br><span class="line">Max Client Throughput Per Sample: clientName&#x3D;JmsProducer0, value&#x3D;65562</span><br><span class="line">Min Client Total Throughput: clientName&#x3D;JmsProducer0, value&#x3D;13347982</span><br><span class="line">Max Client Total Throughput: clientName&#x3D;JmsProducer0, value&#x3D;13347982</span><br><span class="line">Min Average Client Throughput: clientName&#x3D;JmsProducer0, value&#x3D;44493.27333333333</span><br><span class="line">Max Average Client Throughput: clientName&#x3D;JmsProducer0, value&#x3D;44493.27333333333</span><br><span class="line">Min Average Client Throughput Excluding Min&#x2F;Max: clientName&#x3D;JmsProducer0, value&#x3D;44274.73333333333</span><br><span class="line">Max Average Client Throughput Excluding Min&#x2F;Max: clientName&#x3D;JmsProducer0, value&#x3D;44274.73333333333</span><br><span class="line">[INFO] Created performance report: &#x2F;home&#x2F;jreagan&#x2F;Development&#x2F;Projects&#x2F;joshdreagan&#x2F;amqp-perf-test&#x2F;.&#x2F;target&#x2F;JmsProducer_numClients1_numDests1_all.xml</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 05:10 min</span><br><span class="line">[INFO] Finished at: 2016-02-02T11:46:30-07:00</span><br><span class="line">[INFO] Final Memory: 8M&#x2F;235M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><h3 id="Consumer-OpenWire"><a href="#Consumer-OpenWire" class="headerlink" title="Consumer OpenWire"></a>Consumer OpenWire</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">$&gt; mvn activemq-perf:consumer -DsysTest.propsConfigFile&#x3D;src&#x2F;main&#x2F;resources&#x2F;tcp-consumer.properties</span><br><span class="line">OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;2048m; support was removed in 8.0</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building ActiveMQ Perf: AMQP Perf Test 1.0.0-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- activemq-perf-maven-plugin:5.11.0:consumer (default-cli) @ amqp-perf-test ---</span><br><span class="line">[INFO] Loading properties file: &#x2F;home&#x2F;jreagan&#x2F;Development&#x2F;Projects&#x2F;joshdreagan&#x2F;amqp-perf-test&#x2F;src&#x2F;main&#x2F;resources&#x2F;tcp-consumer.properties</span><br><span class="line">[INFO] Created: org.apache.activemq.ActiveMQConnectionFactory using SPIConnectionFactory: org.apache.activemq.tool.spi.ActiveMQReflectionSPI</span><br><span class="line">[INFO] Sampling duration: 300000 ms, ramp up: 0 ms, ramp down: 0 ms</span><br><span class="line">[INFO] Creating queue: queue:&#x2F;&#x2F;TEST.FOO</span><br><span class="line">[INFO] Creating JMS Connection: Provider&#x3D;ActiveMQ-5.11.0, JMS Spec&#x3D;1.1</span><br><span class="line">[INFO] Creating non-durable consumer to: queue:&#x2F;&#x2F;TEST.FOO</span><br><span class="line">[INFO] Starting to asynchronously receive messages for 300000 ms...</span><br><span class="line">[INFO] Client completed</span><br><span class="line">#########################################</span><br><span class="line">####    SYSTEM THROUGHPUT SUMMARY    ####</span><br><span class="line">#########################################</span><br><span class="line">System Total Throughput: 13287310</span><br><span class="line">System Total Clients: 1</span><br><span class="line">System Average Throughput: 44291.03333333333</span><br><span class="line">System Average Throughput Excluding Min&#x2F;Max: 44074.76</span><br><span class="line">System Average Client Throughput: 44291.03333333333</span><br><span class="line">System Average Client Throughput Excluding Min&#x2F;Max: 44074.76</span><br><span class="line">Min Client Throughput Per Sample: clientName&#x3D;JmsConsumer0, value&#x3D;0</span><br><span class="line">Max Client Throughput Per Sample: clientName&#x3D;JmsConsumer0, value&#x3D;64882</span><br><span class="line">Min Client Total Throughput: clientName&#x3D;JmsConsumer0, value&#x3D;13287310</span><br><span class="line">Max Client Total Throughput: clientName&#x3D;JmsConsumer0, value&#x3D;13287310</span><br><span class="line">Min Average Client Throughput: clientName&#x3D;JmsConsumer0, value&#x3D;44291.03333333333</span><br><span class="line">Max Average Client Throughput: clientName&#x3D;JmsConsumer0, value&#x3D;44291.03333333333</span><br><span class="line">Min Average Client Throughput Excluding Min&#x2F;Max: clientName&#x3D;JmsConsumer0, value&#x3D;44074.76</span><br><span class="line">Max Average Client Throughput Excluding Min&#x2F;Max: clientName&#x3D;JmsConsumer0, value&#x3D;44074.76</span><br><span class="line">[INFO] Created performance report: &#x2F;home&#x2F;jreagan&#x2F;Development&#x2F;Projects&#x2F;joshdreagan&#x2F;amqp-perf-test&#x2F;.&#x2F;target&#x2F;JmsConsumer_numClients1_numDests1_equal.xml</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 05:00 min</span><br><span class="line">[INFO] Finished at: 2016-02-02T11:46:19-07:00</span><br><span class="line">[INFO] Final Memory: 7M&#x2F;220M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><h3 id="Producer-AMQP"><a href="#Producer-AMQP" class="headerlink" title="Producer AMQP"></a>Producer AMQP</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">$&gt; mvn activemq-perf:producer -DsysTest.propsConfigFile&#x3D;src&#x2F;main&#x2F;resources&#x2F;amqp-producer.properties</span><br><span class="line">OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;2048m; support was removed in 8.0</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building ActiveMQ Perf: AMQP Perf Test 1.0.0-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- activemq-perf-maven-plugin:5.11.0:producer (default-cli) @ amqp-perf-test ---</span><br><span class="line">[INFO] Loading properties file: &#x2F;home&#x2F;jreagan&#x2F;Development&#x2F;Projects&#x2F;joshdreagan&#x2F;amqp-perf-test&#x2F;src&#x2F;main&#x2F;resources&#x2F;amqp-producer.properties</span><br><span class="line">[INFO] Created: org.apache.qpid.jms.JmsConnectionFactory using SPIConnectionFactory: org.jboss.examples.amqp.spi.AMQPReflectionSPIConnectionFactory</span><br><span class="line">[INFO] Sampling duration: 300000 ms, ramp up: 0 ms, ramp down: 0 ms</span><br><span class="line">[INFO] Creating queue: queue:&#x2F;&#x2F;TEST.FOO</span><br><span class="line">[INFO] Best match for SASL auth was: SASL-PLAIN</span><br><span class="line">[INFO] Connection ID:bearkat-34938-1454439352850-0:2 connected to remote Broker: amqp:&#x2F;&#x2F;localhost:5672</span><br><span class="line">[INFO] Creating JMS Connection: Provider&#x3D;QpidJMS-0.5.0, JMS Spec&#x3D;1.1</span><br><span class="line">[INFO] Creating  producer to: TEST.FOO with non-persistent delivery.</span><br><span class="line">[INFO] Starting to publish 1024 byte(s) messages for 300000 ms</span><br><span class="line">[INFO] Finished sending</span><br><span class="line">[INFO] Client completed</span><br><span class="line">#########################################</span><br><span class="line">####    SYSTEM THROUGHPUT SUMMARY    ####</span><br><span class="line">#########################################</span><br><span class="line">System Total Throughput: 3600145</span><br><span class="line">System Total Clients: 1</span><br><span class="line">System Average Throughput: 12000.483333333334</span><br><span class="line">System Average Throughput Excluding Min&#x2F;Max: 11947.51</span><br><span class="line">System Average Client Throughput: 12000.483333333334</span><br><span class="line">System Average Client Throughput Excluding Min&#x2F;Max: 11947.51</span><br><span class="line">Min Client Throughput Per Sample: clientName&#x3D;JmsProducer0, value&#x3D;1800</span><br><span class="line">Max Client Throughput Per Sample: clientName&#x3D;JmsProducer0, value&#x3D;14092</span><br><span class="line">Min Client Total Throughput: clientName&#x3D;JmsProducer0, value&#x3D;3600145</span><br><span class="line">Max Client Total Throughput: clientName&#x3D;JmsProducer0, value&#x3D;3600145</span><br><span class="line">Min Average Client Throughput: clientName&#x3D;JmsProducer0, value&#x3D;12000.483333333334</span><br><span class="line">Max Average Client Throughput: clientName&#x3D;JmsProducer0, value&#x3D;12000.483333333334</span><br><span class="line">Min Average Client Throughput Excluding Min&#x2F;Max: clientName&#x3D;JmsProducer0, value&#x3D;11947.51</span><br><span class="line">Max Average Client Throughput Excluding Min&#x2F;Max: clientName&#x3D;JmsProducer0, value&#x3D;11947.51</span><br><span class="line">[INFO] Created performance report: &#x2F;home&#x2F;jreagan&#x2F;Development&#x2F;Projects&#x2F;joshdreagan&#x2F;amqp-perf-test&#x2F;.&#x2F;target&#x2F;JmsProducer_numClients1_numDests1_all.xml</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 05:00 min</span><br><span class="line">[INFO] Finished at: 2016-02-02T12:00:53-07:00</span><br><span class="line">[INFO] Final Memory: 10M&#x2F;128M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><h3 id="Consumer-AMQP"><a href="#Consumer-AMQP" class="headerlink" title="Consumer AMQP"></a>Consumer AMQP</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">$&gt; mvn activemq-perf:consumer -DsysTest.propsConfigFile&#x3D;src&#x2F;main&#x2F;resources&#x2F;amqp-consumer.properties</span><br><span class="line">OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;2048m; support was removed in 8.0</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building ActiveMQ Perf: AMQP Perf Test 1.0.0-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- activemq-perf-maven-plugin:5.11.0:consumer (default-cli) @ amqp-perf-test ---</span><br><span class="line">[INFO] Loading properties file: &#x2F;home&#x2F;jreagan&#x2F;Development&#x2F;Projects&#x2F;joshdreagan&#x2F;amqp-perf-test&#x2F;src&#x2F;main&#x2F;resources&#x2F;amqp-consumer.properties</span><br><span class="line">[INFO] Created: org.apache.qpid.jms.JmsConnectionFactory using SPIConnectionFactory: org.jboss.examples.amqp.spi.AMQPReflectionSPIConnectionFactory</span><br><span class="line">[INFO] Sampling duration: 300000 ms, ramp up: 0 ms, ramp down: 0 ms</span><br><span class="line">[INFO] Creating queue: queue:&#x2F;&#x2F;TEST.FOO</span><br><span class="line">[INFO] Best match for SASL auth was: SASL-PLAIN</span><br><span class="line">[INFO] Connection ID:bearkat-51184-1454439351110-0:2 connected to remote Broker: amqp:&#x2F;&#x2F;localhost:5672</span><br><span class="line">[INFO] Creating JMS Connection: Provider&#x3D;QpidJMS-0.5.0, JMS Spec&#x3D;1.1</span><br><span class="line">[INFO] Creating non-durable consumer to: TEST.FOO</span><br><span class="line">[INFO] Starting to asynchronously receive messages for 300000 ms...</span><br><span class="line">[INFO] Client completed</span><br><span class="line">#########################################</span><br><span class="line">####    SYSTEM THROUGHPUT SUMMARY    ####</span><br><span class="line">#########################################</span><br><span class="line">System Total Throughput: 3583507</span><br><span class="line">System Total Clients: 1</span><br><span class="line">System Average Throughput: 11945.023333333333</span><br><span class="line">System Average Throughput Excluding Min&#x2F;Max: 11899.69</span><br><span class="line">System Average Client Throughput: 11945.023333333333</span><br><span class="line">System Average Client Throughput Excluding Min&#x2F;Max: 11899.69</span><br><span class="line">Min Client Throughput Per Sample: clientName&#x3D;JmsConsumer0, value&#x3D;0</span><br><span class="line">Max Client Throughput Per Sample: clientName&#x3D;JmsConsumer0, value&#x3D;13600</span><br><span class="line">Min Client Total Throughput: clientName&#x3D;JmsConsumer0, value&#x3D;3583507</span><br><span class="line">Max Client Total Throughput: clientName&#x3D;JmsConsumer0, value&#x3D;3583507</span><br><span class="line">Min Average Client Throughput: clientName&#x3D;JmsConsumer0, value&#x3D;11945.023333333333</span><br><span class="line">Max Average Client Throughput: clientName&#x3D;JmsConsumer0, value&#x3D;11945.023333333333</span><br><span class="line">Min Average Client Throughput Excluding Min&#x2F;Max: clientName&#x3D;JmsConsumer0, value&#x3D;11899.69</span><br><span class="line">Max Average Client Throughput Excluding Min&#x2F;Max: clientName&#x3D;JmsConsumer0, value&#x3D;11899.69</span><br><span class="line">[INFO] Created performance report: &#x2F;home&#x2F;jreagan&#x2F;Development&#x2F;Projects&#x2F;joshdreagan&#x2F;amqp-perf-test&#x2F;.&#x2F;target&#x2F;JmsConsumer_numClients1_numDests1_equal.xml</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 05:01 min</span><br><span class="line">[INFO] Finished at: 2016-02-02T12:00:51-07:00</span><br><span class="line">[INFO] Final Memory: 12M&#x2F;243M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>That‚Äôs it! You can see that OpenWire is quite a bit faster in this case. But please don‚Äôt take my word for it‚Ä¶ clone the project, tweak some configurations, try scaling the producers/consumers/brokers, and run the test yourself to see what results you‚Äôll get.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;I recently had a customer that wanted us to do some load testing of &lt;a href=&quot;http://www.jboss.org/products/amq/overview/&quot;&gt;Red Hat‚Äôs JBoss A-MQ&lt;/a&gt; for them. In particular, this customer wanted the tests performed using the AMQP protocol instead of ActiveMQ‚Äôs native OpenWire. From previous engagements, I knew that there would be a performance difference. But after a quick look I didn‚Äôt see any blogs or posts on the subject. More specifically, I didn‚Äôt see any posts that detailed how to run the tests yourself so that you could get real numbers in your own environment. So I figured I‚Äôd write up some steps and post my results for future reference.&lt;/p&gt;</summary>
    
    
    
    
    <category term="activemq" scheme="https://blog.joshdreagan.com/tags/activemq/"/>
    
    <category term="amq" scheme="https://blog.joshdreagan.com/tags/amq/"/>
    
  </entry>
  
  <entry>
    <title>Custom Camel LoadBalancer With Infinispan</title>
    <link href="https://blog.joshdreagan.com/2015/12/04/custom_camel_loadbalancer_with_infinispan/"/>
    <id>https://blog.joshdreagan.com/2015/12/04/custom_camel_loadbalancer_with_infinispan/</id>
    <published>2015-12-04T07:00:00.000Z</published>
    <updated>2021-01-14T22:53:28.903Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Camel is a pretty full-featured EIP implementation framework. It has several existing strategies for load-balancing right out of the box. Round Robin, Random, Sticky, Weighted Round Robin, Weighted Random,‚Ä¶ the list goes on and on. But being that it‚Äôs a very well written and pluggable framework, it also gives you the ability to drop in your own custom strategies should you find that none of the existing ones meet your specific needs. So for this post, I created a custom Camel Load Balancer implementation utilizing an Infinispan cache to dynamically discover and load-balance between destination endpoints.</p><a id="more"></a><blockquote><p>The sample code for this post can be found at <a href="https://github.com/joshdreagan/infinispan-discovery">https://github.com/joshdreagan/infinispan-discovery</a></p></blockquote><h2 id="Why"><a href="#Why" class="headerlink" title="Why?"></a>Why?</h2><p>Why would I do such a thing? Well‚Ä¶ there‚Äôs a few good reasons.</p><p>First, all of the existing load-balancer strategies work on a static list. So if I know all of my endpoints ahead of time, no problem. I just code them into my Camel route. But what if my list of endpoints changes between environments? Maybe I could use properties. Well‚Ä¶ only if the number of endpoints is static. Which brings me to the next reason‚Ä¶</p><p>All of the existing load-balancer strategies are configured at startup. So what do I do if my list changes dynamically at runtime? Let‚Äôs say that I want to do service discovery and load-balance between the currently active/registered backend services. If you‚Äôre familiar with Camel, you might be thinking ‚ÄúWhy not just use the Camel Fabric Component? It does dynamic load-balancing and service discovery. Problem solved right?‚Äù. If all of my services are running in containers that are managed by Fabric8, that is a viable solution. But what if I want to discover some endpoints that are running on JBoss EAP instances. Or what if I‚Äôm not running a Fabric8 ensemble at all?</p><p>Finally, the most important reason‚Ä¶ Because I can. :)</p><h2 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h2><p>Creating a custom Camel Load Balancer implementation is fairly straight forward. You just create a class and implement the <code>LoadBalancer</code> interface. There‚Äôs even a base class (<code>LoadBalancerSupport</code>) that you can extend that will take care of some of the boilerplate coding for you. You then just fill in the details of how it picks the next endpoint from its internal list. Pretty simple right?</p><p>In my case, however, I‚Äôm not actually coming up with my own strategy for how to pick endpoints. I‚Äôm really just augmenting some existing strategy with a dynamic list of endpoints. So to be more specific, I‚Äôm not interested in implementing my own flavor of the Random, Round Robin, Sticky, ‚Ä¶ strategies. No need to reinvent that wheel. Instead, I just want to decorate those existing strategies and provide them with some additional capabilities. So I use the decorator pattern. That allows me to ignore all the tom-foolery of the load-balancing itself and concentrate on the portion that I really want. The dynamic service discovery.</p><p>Here‚Äôs my custom load-balancer class (or at least the important parts):</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.camel.processor.loadbalancer;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Import statements removed for brevity.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JCacheLoadBalancer</span> <span class="keyword">extends</span> <span class="title">ServiceSupport</span> <span class="keyword">implements</span> <span class="title">LoadBalancer</span>, <span class="title">CamelContextAware</span>, <span class="title">InitializingBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Logger log = LoggerFactory.getLogger(JCacheLoadBalancer.class);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> LoadBalancer DEFAULT_DELEGATE = <span class="keyword">new</span> RoundRobinLoadBalancer();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> Cache&lt;String, Set&lt;String&gt;&gt; registry;</span><br><span class="line">  <span class="keyword">private</span> String groupId;</span><br><span class="line">  <span class="keyword">private</span> LoadBalancer delegate;</span><br><span class="line">  <span class="keyword">private</span> UriPreProcessor uriPreProcessor;</span><br><span class="line">  <span class="keyword">private</span> Boolean throwExceptionIfEmpty;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> Map&lt;String, Processor&gt; processorMap;</span><br><span class="line">  <span class="keyword">private</span> CacheEntryListenerConfiguration&lt;String, Set&lt;String&gt;&gt; registryListenerConfiguration;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> CamelContext camelContext;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Getters and setters removed for brevity.</span></span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addProcessor</span><span class="params">(Processor processor)</span> </span>&#123;</span><br><span class="line">    delegate.addProcessor(processor);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeProcessor</span><span class="params">(Processor processor)</span> </span>&#123;</span><br><span class="line">    delegate.removeProcessor(processor);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Processor&gt; <span class="title">getProcessors</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> delegate.getProcessors();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">process</span><span class="params">(Exchange exchange, AsyncCallback callback)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ((getProcessors() == <span class="keyword">null</span> || getProcessors().isEmpty()) &amp;&amp; throwExceptionIfEmpty) &#123;</span><br><span class="line">      <span class="keyword">if</span> (throwExceptionIfEmpty) &#123;</span><br><span class="line">        exchange.setException(<span class="keyword">new</span> LoadBalancerUnavailableException(String.format(<span class="string">&quot;No URIs found for service &#x27;%s&#x27;.&quot;</span>, groupId)));</span><br><span class="line">      &#125;</span><br><span class="line">      callback.done(<span class="keyword">true</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> delegate.process(exchange, callback);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Exchange exchange)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ((getProcessors() == <span class="keyword">null</span> || getProcessors().isEmpty()) &amp;&amp; throwExceptionIfEmpty) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> LoadBalancerUnavailableException(String.format(<span class="string">&quot;No URIs found for service &#x27;%s&#x27;.&quot;</span>, groupId));</span><br><span class="line">    &#125;</span><br><span class="line">    delegate.process(exchange);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doStart</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (delegate == DEFAULT_DELEGATE) &#123;</span><br><span class="line">      ((Service) delegate).start();</span><br><span class="line">    &#125;</span><br><span class="line">    registry.registerCacheEntryListener(registryListenerConfiguration);</span><br><span class="line">    processUris(registry.get(groupId));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doStop</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    registry.deregisterCacheEntryListener(registryListenerConfiguration);</span><br><span class="line">    <span class="keyword">if</span> (delegate == DEFAULT_DELEGATE) &#123;</span><br><span class="line">      ((Service) delegate).stop();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterPropertiesSet</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Objects.requireNonNull(registry, <span class="string">&quot;The registry property must not be null.&quot;</span>);</span><br><span class="line">    Objects.requireNonNull(groupId, <span class="string">&quot;The groupId property must not be null.&quot;</span>);</span><br><span class="line">    Objects.requireNonNull(camelContext, <span class="string">&quot;The camelContext property must not be null.&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (delegate == <span class="keyword">null</span>) &#123;</span><br><span class="line">      delegate = DEFAULT_DELEGATE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (throwExceptionIfEmpty == <span class="keyword">null</span>) &#123;</span><br><span class="line">      throwExceptionIfEmpty = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    processorMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    registryListenerConfiguration = <span class="keyword">new</span> MutableCacheEntryListenerConfiguration&lt;&gt;(<span class="keyword">new</span> LookupCacheListenerFactory(), <span class="keyword">null</span>, <span class="keyword">false</span>, <span class="keyword">false</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processUris</span><span class="params">(Set&lt;String&gt; uris)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (uris == <span class="keyword">null</span>) &#123;</span><br><span class="line">      uris = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (String uri : processorMap.keySet()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!uris.contains(uri)) &#123;</span><br><span class="line">        log.info(String.format(<span class="string">&quot;Removing uri: %s&quot;</span>, uri));</span><br><span class="line">        Processor processor = processorMap.remove(uri);</span><br><span class="line">        removeProcessor(processor);</span><br><span class="line">        <span class="keyword">if</span> (processor <span class="keyword">instanceof</span> Producer) &#123;</span><br><span class="line">          camelContext.removeEndpoint(((Producer) processor).getEndpoint());</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (String uri : uris) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!processorMap.containsKey(uri)) &#123;</span><br><span class="line">        log.info(String.format(<span class="string">&quot;Adding uri: %s&quot;</span>, uri));</span><br><span class="line">        String processedUri = uri;</span><br><span class="line">        <span class="keyword">if</span> (uriPreProcessor != <span class="keyword">null</span>) &#123;</span><br><span class="line">          processedUri = uriPreProcessor.process(uri);</span><br><span class="line">        &#125;</span><br><span class="line">        Processor processor = camelContext.getEndpoint(processedUri).createProducer();</span><br><span class="line">        processorMap.put(uri, processor);</span><br><span class="line">        addProcessor(processor);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">LookupCacheListener</span> <span class="keyword">implements</span> <span class="title">CacheEntryCreatedListener</span>&lt;<span class="title">String</span>, <span class="title">Set</span>&lt;<span class="title">String</span>&gt;&gt;,</span></span><br><span class="line"><span class="class">          <span class="title">CacheEntryUpdatedListener</span>&lt;<span class="title">String</span>, <span class="title">Set</span>&lt;<span class="title">String</span>&gt;&gt;,</span></span><br><span class="line"><span class="class">          <span class="title">CacheEntryRemovedListener</span>&lt;<span class="title">String</span>, <span class="title">Set</span>&lt;<span class="title">String</span>&gt;&gt;,</span></span><br><span class="line"><span class="class">          <span class="title">CacheEntryExpiredListener</span>&lt;<span class="title">String</span>, <span class="title">Set</span>&lt;<span class="title">String</span>&gt;&gt;,</span></span><br><span class="line"><span class="class">          <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// All listener methods removed for brevity. They just delegate to the onEvent method anyway.</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onEvent</span><span class="params">(Iterable&lt;CacheEntryEvent&lt;? extends String, ? extends Set&lt;String&gt;&gt;&gt; events)</span> <span class="keyword">throws</span> CacheEntryListenerException </span>&#123;</span><br><span class="line">      <span class="keyword">for</span> (CacheEntryEvent&lt;? extends String, ? extends Set&lt;String&gt;&gt; event : events) &#123;</span><br><span class="line">        log.debug(String.format(<span class="string">&quot;Got a cache event: %s&quot;</span>, event));</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          processUris(event.getValue());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> CacheEntryListenerException(e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">LookupCacheListenerFactory</span> <span class="keyword">implements</span> <span class="title">Factory</span>&lt;<span class="title">LookupCacheListener</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LookupCacheListener <span class="title">create</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> LookupCacheListener();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>You can see that it‚Äôs just delegating most of the methods (ie, the <code>addProcessor</code>, <code>getProcessor</code>, and <code>removeProcessor</code> methods) to whatever existing implementation that it‚Äôs decorating. The actual methods that do the load-balancing (ie, the <code>process</code> methods) do a little bit of work, but end up just delegating as well. So I didn‚Äôt actually have to do any algorithm work and I still get to use all the existing strategies. Pretty neat!</p><p>In addition to a delegate <code>LoadBalancer</code> implementation, this class expects that you will give it a fully-configured jCache instance. In my example, I used Infinispan. But I could have just as easily used any other spec compliant implementation. Here‚Äôs my Infinispan configuration:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">infinispan</span> <span class="attr">xmlns</span>=<span class="string">&quot;...&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">jgroups</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">stack-file</span> <span class="attr">name</span>=<span class="string">&quot;external-file&quot;</span> <span class="attr">path</span>=<span class="string">&quot;default-configs/default-jgroups-tcp.xml&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">jgroups</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">cache-container</span> <span class="attr">default-cache</span>=<span class="string">&quot;default&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">local-cache</span> <span class="attr">name</span>=<span class="string">&quot;registry-cache&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">transport</span> <span class="attr">cluster</span>=<span class="string">&quot;registry-cluster&quot;</span> <span class="attr">stack</span>=<span class="string">&quot;external-file&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replicated-cache</span> <span class="attr">name</span>=<span class="string">&quot;registry-cache&quot;</span> <span class="attr">mode</span>=<span class="string">&quot;SYNC&quot;</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">cache-container</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">infinispan</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Now let‚Äôs get to the part that‚Äôs actually doing some work. The <code>LookupCacheListener</code> class just implements the various <code>CacheListener</code> interfaces from the jCache API. If it gets any events on the cache entry containing our endpoints, it simply updates the delegate‚Äôs internal list of processors. So as services come and go they can register their URIs in the cache, our listener will be notified, and our list of available load-balancer endpoints will be updated.</p><p>The final piece to discuss for this load-balancer implementation is the <code>UriPreProcessor</code>. This is an interface that I created to allow an implementation to customize the URI in some way before adding it to the list. The idea is that other services that are registering themselves might not know that they‚Äôre going to be invoked from a Camel endpoint. So they likely won‚Äôt add options like <code>bridgeEndpoint=true</code> to the URI. An implementation of this interface would allow you to add such options on their behalf. Here‚Äôs the interface itself:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.camel.processor.loadbalancer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UriPreProcessor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">process</span><span class="params">(String uri)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And here‚Äôs a sample implementation that adds the options:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.jboss.poc.greeter.camel;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Import statements removed for brevity.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GreeterServiceUriPreProcessor</span> <span class="keyword">implements</span> <span class="title">UriPreProcessor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">process</span><span class="params">(String uri)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Map&lt;String, Object&gt; options = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    options.put(<span class="string">&quot;bridgeEndpoint&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">return</span> URISupport.appendParametersToURI(uri, options);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now all that‚Äôs left is to actually use it in my Camel routes. To do so, I declare it just like any other bean. Then I use the <code>custom</code> element in my <code>loadBalance</code> to <code>ref</code> it. Looks something like this:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">&quot;...&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;cachingProvider&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">class</span>=<span class="string">&quot;javax.cache.Caching&quot;</span> <span class="attr">factory-method</span>=<span class="string">&quot;getCachingProvider&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;cacheManager&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">factory-bean</span>=<span class="string">&quot;cachingProvider&quot;</span> <span class="attr">factory-method</span>=<span class="string">&quot;getCacheManager&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">value</span>=<span class="string">&quot;META-INF/infinispan/infinispan-clustered.xml&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">constructor-arg</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">&quot;org.springframework.util.ClassUtils&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">factory-method</span>=<span class="string">&quot;getDefaultClassLoader&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">constructor-arg</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;registryCache&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">factory-bean</span>=<span class="string">&quot;cacheManager&quot;</span> <span class="attr">factory-method</span>=<span class="string">&quot;getCache&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">value</span>=<span class="string">&quot;registry-cache&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;jCacheLoadBalancer&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">class</span>=<span class="string">&quot;org.apache.camel.processor.loadbalancer.JCacheLoadBalancer&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">init-method</span>=<span class="string">&quot;start&quot;</span> <span class="attr">destroy-method</span>=<span class="string">&quot;stop&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;registry&quot;</span> <span class="attr">ref</span>=<span class="string">&quot;registryCache&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;groupId&quot;</span></span></span><br><span class="line"><span class="tag">              <span class="attr">value</span>=<span class="string">&quot;/services/soap-http/&#123;http://poc.jboss.org/greeter&#125;GreeterService&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;delegate&quot;</span> <span class="attr">ref</span>=<span class="string">&quot;randomLoadBalancer&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;uriPreProcessor&quot;</span> <span class="attr">ref</span>=<span class="string">&quot;greeterServiceUriPreProcessor&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;greeterServiceUriPreProcessor&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">class</span>=<span class="string">&quot;org.jboss.poc.greeter.camel.GreeterServiceUriPreProcessor&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;randomLoadBalancer&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">class</span>=<span class="string">&quot;org.apache.camel.processor.loadbalancer.RandomLoadBalancer&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">camelContext</span> <span class="attr">id</span>=<span class="string">&quot;greeterGateway&quot;</span></span></span><br><span class="line"><span class="tag">                <span class="attr">trace</span>=<span class="string">&quot;false&quot;</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://camel.apache.org/schema/spring&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">route</span> <span class="attr">id</span>=<span class="string">&quot;proxyRoute&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">from</span> <span class="attr">uri</span>=<span class="string">&quot;jetty:http://localhost:9000/gateway/GreeterService?matchOnUriPrefix=true<span class="symbol">&amp;amp;</span>bridgeEndpoint=true&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">onException</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exception</span>&gt;</span>org.apache.camel.processor.loadbalancer.LoadBalancerUnavailableException<span class="tag">&lt;/<span class="name">exception</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">handled</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">constant</span>&gt;</span>true<span class="tag">&lt;/<span class="name">constant</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">handled</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">setHeader</span> <span class="attr">headerName</span>=<span class="string">&quot;CamelHttpResponseCode&quot;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">constant</span>&gt;</span>404<span class="tag">&lt;/<span class="name">constant</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">setHeader</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">setBody</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">constant</span>&gt;</span>NOT FOUND<span class="tag">&lt;/<span class="name">constant</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">setBody</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">onException</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">loadBalance</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">custom</span> <span class="attr">ref</span>=<span class="string">&quot;jCacheLoadBalancer&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">loadBalance</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">route</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">camelContext</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure><p>That‚Äôs it for the Camel side of things. Now let‚Äôs discuss how to get some services registered.</p><p>In my example, I just created a simple JAX-WS service in JBoss WildFly. Here‚Äôs the code so you can see how simple it is:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.jboss.poc.greeter.impl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Import statements removed for brevity.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@WebService(endpointInterface = &quot;org.jboss.poc.greeter.Greeter&quot;,</span></span><br><span class="line"><span class="meta">            serviceName = &quot;GreeterService&quot;,</span></span><br><span class="line"><span class="meta">            portName = &quot;GreeterServicePort&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EnglishGreeter</span> <span class="keyword">implements</span> <span class="title">Greeter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getGreeting</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    String greeting = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      greeting = String.format(<span class="string">&quot;Hello %s from %s!&quot;</span>, name, InetAddress.getLocalHost().getHostAddress());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      greeting = String.format(<span class="string">&quot;Hello %s! I was unable to find my IP :(...&quot;</span>, name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> greeting;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>For this service, I created a <code>ServletContextListener</code> to register/unregister it‚Äôs URI to/from the jCache.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.jboss.poc.greeter.impl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Import statements removed for brevity.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@WebListener()</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GreeterServiceRegistrar</span> <span class="keyword">implements</span> <span class="title">ServletContextListener</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String SERVICE_NAMESPACE = <span class="string">&quot;http://poc.jboss.org/greeter&quot;</span>;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String SERVICE_NAME = <span class="string">&quot;GreeterService&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String REGISTRY_CACHE_NAME = <span class="string">&quot;registry-cache&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Logger log = LoggerFactory.getLogger(GreeterServiceRegistrar.class);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Inject</span></span><br><span class="line">  <span class="keyword">private</span> DefaultCacheManager cacheManager;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextInitialized</span><span class="params">(ServletContextEvent sce)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> String key = getServiceKey();</span><br><span class="line">    <span class="keyword">final</span> String uri = getServiceURI(sce);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cacheManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">      log.info(String.format(<span class="string">&quot;Registering service: &#123;&#x27;%s&#x27;: &#x27;%s&#x27;&#125;&quot;</span>, key, uri));</span><br><span class="line"></span><br><span class="line">      Cache&lt;String, Set&lt;String&gt;&gt; cache = cacheManager.getCache(REGISTRY_CACHE_NAME);</span><br><span class="line">      Set&lt;String&gt; uris = cache.getOrDefault(key, <span class="keyword">new</span> HashSet&lt;String&gt;());</span><br><span class="line">      uris.add(uri);</span><br><span class="line">      cache.put(key, uris);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      log.warn(String.format(<span class="string">&quot;Unable to register service: &#123;&#x27;%s&#x27;: &#x27;%s&#x27;&#125;. CacheManager is null.&quot;</span>, key, uri));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextDestroyed</span><span class="params">(ServletContextEvent sce)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> String key = getServiceKey();</span><br><span class="line">    <span class="keyword">final</span> String uri = getServiceURI(sce);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cacheManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">      log.info(String.format(<span class="string">&quot;Unregistering service: &#123;&#x27;%s&#x27;: &#x27;%s&#x27;&#125;&quot;</span>, key, uri));</span><br><span class="line">      Cache&lt;String, Set&lt;String&gt;&gt; cache = cacheManager.getCache(REGISTRY_CACHE_NAME);</span><br><span class="line">      Set&lt;String&gt; uris = cache.getOrDefault(key, <span class="keyword">new</span> HashSet&lt;String&gt;());</span><br><span class="line">      uris.remove(uri);</span><br><span class="line">      cache.put(key, uris);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      log.warn(String.format(<span class="string">&quot;Unable to unregister service: &#123;&#x27;%s&#x27;: &#x27;%s&#x27;&#125;. CacheManager is null.&quot;</span>, key, uri));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> String <span class="title">getServiceKey</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Contents removed for brevity. Method forms and returns the cache key where we&#x27;ll store our URIs.</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> String <span class="title">getServiceURI</span><span class="params">(ServletContextEvent sce)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Contents removed for brevity. Method grabs the current IP and port that the server is bound to and forms a URI.</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>So now when my <code>ServletContext</code> is started, my JAX-WS service URI will be registered. And when it is stopped, my URI will be removed. Since I configured my Infinispan cache the same on both the JBoss WildFly and Camel sides, the local cache instances are connected and will receive events and updates.</p><p>That‚Äôs it! If you want to give it a go, check out the full source code at <a href="https://github.com/joshdreagan/infinispan-discovery">https://github.com/joshdreagan/infinispan-discovery</a>. Hopefully it‚Äôs useful‚Ä¶</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Apache Camel is a pretty full-featured EIP implementation framework. It has several existing strategies for load-balancing right out of the box. Round Robin, Random, Sticky, Weighted Round Robin, Weighted Random,‚Ä¶ the list goes on and on. But being that it‚Äôs a very well written and pluggable framework, it also gives you the ability to drop in your own custom strategies should you find that none of the existing ones meet your specific needs. So for this post, I created a custom Camel Load Balancer implementation utilizing an Infinispan cache to dynamically discover and load-balance between destination endpoints.&lt;/p&gt;</summary>
    
    
    
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="jboss" scheme="https://blog.joshdreagan.com/tags/jboss/"/>
    
    <category term="wildfly" scheme="https://blog.joshdreagan.com/tags/wildfly/"/>
    
    <category term="infinispan" scheme="https://blog.joshdreagan.com/tags/infinispan/"/>
    
    <category term="datagrid" scheme="https://blog.joshdreagan.com/tags/datagrid/"/>
    
  </entry>
  
  <entry>
    <title>Correcting Malformed Data With Fuse+BPMS</title>
    <link href="https://blog.joshdreagan.com/2015/10/30/correcting_data_with_fuse_and_bpms/"/>
    <id>https://blog.joshdreagan.com/2015/10/30/correcting_data_with_fuse_and_bpms/</id>
    <published>2015-10-30T06:00:00.000Z</published>
    <updated>2021-01-14T22:53:28.901Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Problem"><a href="#The-Problem" class="headerlink" title="The Problem"></a>The Problem</h2><p>In many environments, it is common to ingest data as a batch process. This is usually accomplished by polling a directory (or FTP server) for files. The issue is that polling for files is a one-way communication. So if you get a file that you can‚Äôt parse (or one that is invalid for any other reason), you have no way of communicating that back to the original sender. How do you handle the error? You likely can‚Äôt just drop the data on the floor. That really only leaves one option and that is to correct the data and re-ingest it.</p><a id="more"></a><h2 id="The-Solution"><a href="#The-Solution" class="headerlink" title="The Solution"></a>The Solution</h2><p>So we need to manually correct the data. We could create our own state machine to walk through the steps for correction. But we‚Äôd need to create a task queue, handle locking/timeouts, and create some UIs to allow the users to pull up the data and fix it. Also, we‚Äôll probably want to restrict access to some group (like ‚Äúanalyst‚Äù), and since the task will likely be long-running we‚Äôll want to create a set of UIs that allow operators to view the current state. All of this requires a significant amount of effort to complete (and is quite difficult to get right).</p><p>Or‚Ä¶ we could just use BPMS which already does all of that for us.</p><p>Take a look at the <a href="https://github.com/joshdreagan/mdfu">Malformed Data Fixer-Upper</a> project on GitHub. Follow the instructions in the <a href="https://github.com/joshdreagan/mdfu/blob/master/README.md">README.md</a> file to get it up and running.</p><p>This example is a bit contrived, but it illustrates the general pattern that you might follow. Basically, Fuse is used to poll for files and validate them. If they are found to be invalid, Fuse will invoke a jBPM process with a <em>Human Task</em> node. Once a human corrects the data, it will be passed back to Fuse to be validated/processed again. The interaction between Fuse and BPMS is done via SOAP/HTTP. So BPMS hosts a web service and Fuse hosts a callback web service. The following diagram shows the interaction in more detail (including what data is passed).</p><p><img src="async.png" alt="figure-1.1"></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;The-Problem&quot;&gt;&lt;a href=&quot;#The-Problem&quot; class=&quot;headerlink&quot; title=&quot;The Problem&quot;&gt;&lt;/a&gt;The Problem&lt;/h2&gt;&lt;p&gt;In many environments, it is common to ingest data as a batch process. This is usually accomplished by polling a directory (or FTP server) for files. The issue is that polling for files is a one-way communication. So if you get a file that you can‚Äôt parse (or one that is invalid for any other reason), you have no way of communicating that back to the original sender. How do you handle the error? You likely can‚Äôt just drop the data on the floor. That really only leaves one option and that is to correct the data and re-ingest it.&lt;/p&gt;</summary>
    
    
    
    
    <category term="fuse" scheme="https://blog.joshdreagan.com/tags/fuse/"/>
    
    <category term="camel" scheme="https://blog.joshdreagan.com/tags/camel/"/>
    
    <category term="cxf" scheme="https://blog.joshdreagan.com/tags/cxf/"/>
    
    <category term="karaf" scheme="https://blog.joshdreagan.com/tags/karaf/"/>
    
    <category term="jbpm" scheme="https://blog.joshdreagan.com/tags/jbpm/"/>
    
    <category term="bpms" scheme="https://blog.joshdreagan.com/tags/bpms/"/>
    
    <category term="jboss" scheme="https://blog.joshdreagan.com/tags/jboss/"/>
    
    <category term="wildfly" scheme="https://blog.joshdreagan.com/tags/wildfly/"/>
    
  </entry>
  
</feed>
